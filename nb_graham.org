Author:  Joe Graham
E-mail:  joe.w.graham@gmail.com
Project: Embedded Ensemble Encoding (EEE) Theory
Drive:   https://drive.google.com/drive/folders/0Bx7OIVIgY3AVU2pKQ21EdFVPVDA

* 2019-01-10 -- Cleaning up and organizing

In progress
-----------
Uninstall Anaconda
Reinstall Anaconda (Python 2 and 3)
Uninstall NEURON
Install latest NEURON
Install Visual Studio Code
Run Sergio's EEE network sim
Summarize current network model
Prepare for discussion with EEE team
Meeting 10am Eastern to discuss network

** Anaconda

*** Uninstalling 

https://docs.anaconda.com/anaconda/install/uninstall/

anaconda-clean doesn't install properly:

	graham-mac% conda install anaconda-clean
	Fatal Python error: initfsencoding: unable to load the file system codec
	  File "/Users/graham/anaconda/lib/python2.7/encodings/__init__.py", line 123
	    raise CodecRegistryError,\
	                            ^
	SyntaxError: invalid syntax

	Current thread 0x0000000111f705c0 (most recent call first):
	Abort
	Fatal Python error: initfsencoding: unable to load the file system codec
	  File "/Users/graham/anaconda/lib/python2.7/encodings/__init__.py", line 123
	    raise CodecRegistryError,\
	                            ^
	SyntaxError: invalid syntax

	Current thread 0x0000000107f365c0 (most recent call first):
	Abort
	graham-mac% 

Seems like it may already be installed.  Just going to run it:

	graham-mac% anaconda-clean
	Delete .anaconda? (Y or N): y
	Delete .bash_profile? (Y or N): n
	Delete .bash_profile-anaconda.bak? (Y or N): n
	Delete .cache? (Y or N): n
	Delete .conda? (Y or N): y
	Delete .condarc? (Y or N): y
	Delete .config? (Y or N): n
	Delete .continuum? (Y or N): y
	Delete .ipynb_checkpoints? (Y or N): y
	Delete .ipython? (Y or N): y
	Delete .jupyter? (Y or N): y
	Delete .matplotlib? (Y or N): y
	graham-mac% 

Now to delete old anaconda dirs:

	/anaconda3
	/Users/graham/anaconda

*** Reinstalling Anaconda

**** To install Python 2 and 3:

http://docs.anaconda.com/anaconda/install/mac-os/#macos-graphical-install
https://conda.io/docs/user-guide/tasks/manage-python.html

Installing Anaconda3, comes with Visual Studio

Having a problem with: "conda search python" and "ipython". 
Switching Terminal to Bash.  Now it works fine.

So far I only have Python 3 installed.  Will try to run network sims in 
Python 3 before bothering with installing 2.7

*** To use Python 2 and 3:

https://docs.anaconda.com/anaconda/user-guide/tasks/switch-environment/

Going to try with just Python 3 for now.

** NEURON

Uninstalling and reinstalling NEURON.

Moving /Applications/NEURON-7.5 to the Desktop (will delete once everything
is working

Getting latest copy of NEURON
https://www.neuron.yale.edu/neuron/download

Running gui installer.  Seems to have worked: can run programs from Finder,
but not from command line.

Looking at path:
	graham$ echo $PATH
	/Users/graham/anaconda3/bin:/usr/site/nrniv/local/python/anaconda3/bin:/Library/Frameworks/Python.framework/Versions/3.6/bin:/Library/Frameworks/Python.framework/Versions/3.6/bin:/anaconda3/bin:/Library/Frameworks/Python.framework/Versions/3.6/bin:/Users/graham/anaconda/bin:/Applications/NEURON-7.4/nrn/x86_64/bin://anaconda/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/texbin:/opt/X11/bin

Okay, my new NEURON is in NEURON-7.6, not NEURON-7.4
Need to update my PATH

https://hathaway.cc/2008/06/how-to-edit-your-path-environment-variables-on-mac/

Editing .bash_profile, changing all 7.4 to 7.6

Now NEURON commands run from command line.


** EEE Network Sims

*** Updating repo:
https://github.com/Neurosim-lab/EEE_network

	graham$ git clone https://github.com/Neurosim-lab/EEE_network.git
	graham$ cd EEE_network/mod/
	graham$ nrnivmodl

Looks good except for ghk.inc:

	Translating NMDAeee.mod into NMDAeee.c
	"/Applications/NEURON-7.6/nrn/x86_64/bin/nocmodl" PlateauConductance
	Couldn't open: ghk.inc
	Couldn't open ghk.inc
	make: *** [NMDAeee.lo] Error 1

Looks like there is no ghk.inc in the mod dir...

	graham$ git clone https://github.com/Neurosim-lab/EEE_network.git
	graham$ cd EEE_network/mod/
	graham$ cp /usr/site/nrniv/local/mod/ghk.inc ./ghk.inc
	graham$ nrnivmodl

Now it seems to have worked fine.  
Will add ghk.inc to the git repo.

But first, I notice I need to merge Salvador's improvements from his
'simplify' branch to the Master... done.

Starting over.

	graham$ rm -rf EEE_network/
	graham$ git clone https://github.com/Neurosim-lab/EEE_network.git
	graham$ cd EEE_network/mod/
	graham$ nrnivmodl

Still has the ghk.inc problem.  Will add to repo.

	graham$ cd ~
	graham$ rm -rf EEE_network/
	graham$ git clone https://github.com/Neurosim-lab/EEE_network.git
	graham$ cd EEE_network/mod/
	graham$ cp /usr/site/nrniv/local/mod/ghk.inc ./ghk.inc
	graham$ git status
	On branch master
	Your branch is up to date with 'origin/master'.

	Untracked files:
	  (use "git add <file>..." to include in what will be committed)

		ghk.inc

	nothing added to commit but untracked files present (use "git add" to track)
	graham$ git add ghk.inc 
	graham$ git status
	On branch master
	Your branch is up to date with 'origin/master'.

	Changes to be committed:
	  (use "git reset HEAD <file>..." to unstage)

		new file:   ghk.inc

	graham$ git commit -m "Added ghk.inc which is needed by NMDAeee.mod"
	[master 5fb1177] Added ghk.inc which is needed by NMDAeee.mod
	 1 file changed, 35 insertions(+)
	 create mode 100644 mod/ghk.inc
	graham$ git push
	Counting objects: 4, done.
	Delta compression using up to 8 threads.
	Compressing objects: 100% (4/4), done.
	Writing objects: 100% (4/4), 742 bytes | 742.00 KiB/s, done.
	Total 4 (delta 2), reused 0 (delta 0)
	remote: Resolving deltas: 100% (2/2), completed with 2 local objects.
	To https://github.com/Neurosim-lab/EEE_network.git
	   700cd24..5fb1177  master -> master

So everything should work now.  Trying it out.

	graham$ cd ~
	graham$ rm -rf EEE_network/
	graham$ git clone https://github.com/Neurosim-lab/EEE_network.git
	graham$ cd EEE_network/mod/
	graham$ nrnivmodl

Works perfectly now.  

Need to symlink mod/x86_64 into eee_network

	graham$ ln -s /Users/graham/EEE_network/mod/x86_64 /Users/graham/EEE_network/eee_network/x86_64

Now hopefully everything works.

*** Running EEE network sim

To debug in Netpyne, run files in the following order:

1) netParams.py 
2) batch_init.py (just init.py in this case) 
3) batch.py

Trying to run netParams.py:
	graham$ python netParams.py 
	Traceback (most recent call last):
	  File "netParams.py", line 1, in <module>
	    from netpyne import specs
	ModuleNotFoundError: No module named 'netpyne'

Need to install Netpyne (development version to immediately get fixes):
http://www.netpyne.org/install.html#install-via-pip-development-version

	1. git clone https://github.com/Neurosim-lab/netpyne.git
	2. cd netpyne
	3. git checkout development
	4. pip install -e .

	pip will add a symlink in the default python packages folder to the cloned netpyne folder (so you don’t need to modify PYTHONPATH). If new changes are available just need to pull from cloned netpyne repo.

Commands:
	graham$ cd ~/Applications/
	graham$ git clone https://github.com/Neurosim-lab/netpyne.git
	graham$ cd netpyne/
	graham$ git checkout development
	graham$ pip install -e .

Everything seems to have worked.

Trying to run netParams again:
	
	graham$ cd ~/EEE_network/eee_network/
	graham$ python netParams.py
	Note: NeuroML import failed; import/export functions for NeuroML will not be available. 
	  To install the pyNeuroML & libNeuroML Python packages visit: https://www.neuroml.org/getneuroml
	Traceback (most recent call last):
	  File "netParams.py", line 95, in <module>
	    for secName,sec in netParams.cellParams['PT5_1']['secs'].iteritems():         
	TypeError: 'Dict' object is not callable

Seems to be a problem with Python 2 --> 3
https://github.com/mgymrek/itable/issues/9
https://stackoverflow.com/questions/10458437/what-is-the-difference-between-dict-items-and-dict-iteritems

I changed two `iteritems` in netParams to `items` and now it works.

So netParams works now.  Now to run init.py

	graham$ python init.py

Something's not quite right:

	Plotting raster...
	There was an exception in plotRaster(): 
	 "['tags'] not found in axis" 
	(<class 'KeyError'>, KeyError("['tags'] not found in axis"), <traceback object at 0x12223ea88>)

Also, traces plot appeared in eee_network dir, but it's blank.

Also, there are too few cells...

Line 130 in cfg.py was:
cfg.singleCellPops = True

Changed it to False and trying again.

Running netParams works fine.  
When I run init, it seems like there are no connections and no traces recorded:

	Creating network of 5 cell populations on 1 hosts...
	  Number of cells on node 0: 1500 
	  Done; cell creation time = 4.66 s.
	Making connections...
	  Number of connections on node 0: 0 
	  Done; cell connection time = 0.00 s.
	  Number of stims on node 0: 0 
	  Done; cell stims creation time = 0.00 s.
	Recording 0 traces of 0 types on node 0

Still getting raster error and blank traces plot.


Changing from hpc_slurm to mpi in batch.py:
#setRunCfg(b, type='hpc_slurm')
setRunCfg(b, type='mpi')

Trying to run batch.py

Getting an error:
	graham$ python batch.py
	Traceback (most recent call last):
	  File "batch.py", line 8, in <module>
	    from netpyne.batch import Batch, specs
	ImportError: cannot import name 'specs' from 'netpyne.batch' (/Users/graham/Applications/netpyne/netpyne/batch/__init__.py)

It seems like I should change importing specs from netpyne.batch to just from netpyne...

Changing batch.py and trying again.

Getting a new error:
	FileNotFoundError: [Errno 2] No such file or directory: 'batch_data/stim_batch6/stim_batch6_batch.json'

I think the dir must already exist...  Changing batch.py to remove need for
extra dir.

New error:
	Error: invalid runCfg 'type' selected; valid types are 'mpi_bulletin', 'mpi_direct', 'hpc_slurm', 'hpc_torque'

Will have to look into this.  Asked Salva:

	joe [9:59 AM]
	Hey Salva, it seems Netpyne used to accept `mpi` as a runCfg option, but now Netpyne requires `mpi_direct` or `mpi_bulletin`…

	Untitled 
	Error: invalid runCfg 'type' selected; valid types are 'mpi_bulletin', 'mpi_direct', 'hpc_slurm', 'hpc_torque'
	Would you mind explaining the difference between `direct` and `bulletin`?
	i.e. which should I be using?

	salvadord [10:03 AM]
	mpi_bulletin - uses NEURON’s mpi bulletin board (master slave) to run the batch sim — there is a master node that sends jobs (each sim) to the slave nodes

	joe [10:05 AM]
	And what does `mpi_direct` do?

	salvadord [10:07 AM]
	mpi_direct - runs each of the batch jobs directly using mpi by calling mpirun via Popen (a pipe) — can specify the number of cores of each mpi job … eg say you have a machine with 16 cores, you could run 4 of the batch jobs on 4 cores each simultaneously
	with mpi_bulleting, each job is always on a single core
	*mpi_bulletin

Okay, so switching to `mpi_bulletin` (seems less complicated):
Changing all `mpi` in batch.py to `mpi_bulletin`

Now batch.py seems to run, but Sergio's default batch was huge: four 
variables each with multiple values.  Will need to set up a smaller batch.  

For now, will look into why there are no connections and no traces.

Running single sim:

graham$ cd ~/EEE_network/eee_network/
graham$ ./runsim

It runs, but no connections or output traces.  Looking into it...

The lack of connectivity is because the connectivity stuff has been commented out. Once we have it working and are getting output we can worry about connectivity.

Having a hard time figuring out the problem with lack of output figures.
I tried adding a soma recording to the cfg file, and when I look in the output json file, the soma trace data is there, but the trace plot output is blank...

Reducing sim time to 50 ms to speed things up.  Commenting out basal trace recording in cfg.

Same thing.  No output traces.

The code is really convoluted.  I'm beginning to think it would be better to start from our cell models and build up network sims from scratch...

Will push my stuff to the git repo now.  Creating a new branch: joes_branch

Cloning, switching to joes_branch, swapping in my changes, then pushing.


* 2019-01-11 -- EEE Network Meeting

In progress
-----------
Summarize current network model
Prepare for discussion with EEE team
Meeting 12pm Eastern to discuss network

** Steps to run network sim

cd ~
git clone https://github.com/Neurosim-lab/EEE_network.git
cd EEE_network/
git checkout joes_branch
cd mod
nrnivmodl
ln -s ~/EEE_network/mod/x86_64 ~/EEE_network/x86_64
cd ../eee_network
./runsim

** EEE Network Sim Meeting -- 2018-01-11
https://docs.google.com/document/d/1jKOPmc2PkjyJme_dgMKip7mLxlXXPuehVY4q-qeBWZs/edit

Google Hangout URL: https://hangouts.google.com/call/UFV-belsSHz1VJv5J4ozAAEE 

Today’s agenda

How to start developing the network model
List of tasks
Division of tasks
	
Discussion

Current state
Disorganized

Network sim development plan
  Scrap existing model
  Two populations: Netpyne tutorial 5
  How many populations? Two
  Where data?  Connectivity?
    Layer 5 IT cells connectivity
    PV cells from M1 model
  Background inputs
  Inputs to both pops
  Want baseline oscillations
How to divide E cells
  Sergio had multiple -- good way to start
  Can force plateaus on subset
How to distribute synapses on neurons
  Bill: 500 inputs 
  One basal has convergence
  Look into clustering
  Strong convergence onto dend A then B
  Other dend possible synchronicity source
Number of cells: ~5000
Trello for task management
Goal of network
  Use existing cell models
  Plug into network
  Look for ensembles
  Preferably emergent
  Synchrony in embedded ensembles
  Activated → Synced
Tasks to be accomplished
  Joe gets framework in place
  Then we divvy up tasks


* 2019-01-15 -- Setting up new network model, EEE Meeting

In progress
-----------
Netpyne Tutorial 5 as basis for network model
Get new model framework into Github
List of synaptic clustering articles
Meeting 11am Eastern - prepare agenda

** Netpyne Tutorial 5

http://netpyne.org/tutorial.html#position-and-distance-based-connectivity-tutorial-5

Downloaded tut5.py and it runs, though I needed to uncomment the following line to see figures:

	import pylab; pylab.show()  # this line is only necessary in certain systems where figures appear empty

The figures should have been saved as well, but never appeared.  Will look into this later.

Downloaded runsim in order to parallelize sims:
	
	#!/bin/bash
	mpiexec -n $1 nrniv -python -mpi $2  # Run the model

Changed permissions on runsim so I can execute:

	graham$ chmod +x runsim

Now splitting tut5.py into three files: 
	
	netParams.py
	cfg.py
	init.py

Changing runsim to call init.py:

	#!/bin/bash
	# Runs simulation, including MPI.

	numprocesses=$1; if [ -z $numprocesses ]; then numprocesses=4; fi # Number of processes to use
	shift # Eliminate first argument

	mpiexec -np $numprocesses nrniv -python -mpi init.py $@  # Run the model

Copying init.py from earlier network sim:

	"""
	init.py

	Usage:
	    python init.py # Run simulation, optionally plot a raster

	MPI usage:
	    mpiexec -n 4 nrniv -python -mpi init.py

	Contributors: salvadordura@gmail.com
	"""

	#import matplotlib; matplotlib.use('Agg')  # to avoid graphics error in servers
	from netpyne import sim

	simConfig, netParams = sim.readCmdLineArgs()
	#sim.createSimulateAnalyze()

	sim.initialize(
	    simConfig = simConfig,    
	    netParams = netParams)        # create network object and set cfg and net params
	sim.net.createPops()              # instantiate network populations
	sim.net.createCells()             # instantiate network cells based on defined populations
	sim.net.connectCells()            # create connections between cells based on params
	sim.net.addStims()                # add network stimulation
	sim.setupRecording()              # setup variables to record for each cell (spikes, V traces, etc)
	sim.runSim()                      # run parallel Neuron simulation  
	sim.gatherData()                  # gather spiking data and cell info from each node
	sim.saveData()                    # save params, cell info and sim output to file (pickle,mat,txt,etc)
	sim.analysis.plotData()           # plot spike raster etc


Now to break tut5.py into netParams and cfg and try to run.

	graham$ ./runsim 1
	numprocs=1
	NEURON -- VERSION 7.6.4 master (50728e66) 2018-12-14
	Duke, Yale, and the BlueBrain Project -- Copyright 1984-2018
	See http://neuron.yale.edu/neuron/credits

	Note: NeuroML import failed; import/export functions for NeuroML will not be available. 
	  To install the pyNeuroML & libNeuroML Python packages visit: https://www.neuroml.org/getneuroml

	Reading command line arguments using syntax: python file.py [simConfig=filepath] [netParams=filepath]

	Warning: Could not load cfg from command line path or from default cfg.py

	Creating network of 6 cell populations on 1 hosts...
	  Number of cells on node 0: 300 
	  Done; cell creation time = 0.03 s.
	Making connections...
	  Number of connections on node 0: 6796 
	  Done; cell connection time = 0.67 s.
	Adding stims...
	  Number of stims on node 0: 300 
	  Done; cell stims creation time = 0.03 s.

	Running simulation for 1000.0 ms...
	  Done; run time = 3.08 s; real-time ratio: 0.32.

	Gathering data...
	  Done; gather time = 0.17 s.

	Analyzing...
	  Cells: 300
	  Connections: 7096 (23.65 per cell)
	  Spikes: 4879 (16.26 Hz)
	  Simulated time: 1.0 s; 1 workers
	  Run time: 3.08 s
	  Done; saving time = 0.01 s.
	  Done; plotting time = 0.00 s

	Total time = 4.00 s
	>>> 

No figures, and it doesn't seem to have worked:

	Warning: Could not load cfg from command line path or from default cfg.py

It seems the problem may be that in tut5.py we named the config object simConfig instead of cfg...

	simConfig = specs.SimConfig()

Will change all config file lines to:
	
	cfg = specs.SimConfig()

Commenting out line that runs sim in cfg.py

Renaming simConfig to cfg in init.py

Trying to run sim.

	graham$ ./runsim 1

Sim ran successfully, figures appeared but weren't saved.  Off to a good start.

Now that the sim is functional, I'll push to Github.

How I was taught to develop code:
	
	Step 1: make it run.
	Step 2: make it right.
	Step 3: make it fast.

Now to work on Step 2 while ensuring Step 1 continues to work.

Next steps:

Use our cell models
Modify population parameters 

** Updating the README

	# EEE_network

	## Steps to run the network simulation:

	1. cd ~
	2. git clone https://github.com/Neurosim-lab/EEE_network.git
	3. cd EEE_network/
	4. git checkout joes_branch
	5. cd mod
	6. nrnivmodl
	7. cd ../eee_net
	8. ln -s "../mod/x86_64" x86_64
	9. ./runsim

Tested these steps and they work from any location (not just home).

** Meeting agenda / notes

https://docs.google.com/document/d/1kZGWeilbLhc9Lv9ly82xLqsqFRsdW6iAsQdeytzcUXo/edit

*** Upcoming deadlines:

IMAG:		Feb 1, 11:59 EST
https://msmmeeting.nibib.nih.gov/instructions-for-submitting-materials

CNS: 		March 4, 11pm Pacific time
https://www.cnsorg.org/cns-2019-abstract-submission

BRAIN:	March 11, 5pm EST
http://www.cvent.com/events/5th-annual-brain-initiative-investigators-meeting/custom-117-de9c0d8f934b46eb8d80b55bcfbfe96a.aspx

SfN: 		May 2, 5pm EDT
https://www.sfn.org/Meetings/Neuroscience-2019/Dates-and-Deadlines

*** Network Meeting summary

2 populations (E and I)
E from Penny’s single cell model (simplified)
I from PV cells in Salva’s M1 model
5000 cells, 500 inputs per cell
Background inputs to both pops → oscillations
First force plateaus and explore sims
Work towards emergent plateaus / ensembles

Framework for network sims is in joes_branch in EEE_network/eee_net
https://github.com/Neurosim-lab/EEE_network/tree/joes_branch/eee_net

Currently it’s just Netpyne Tutorial 5 broken down into the files needed for organizing a larger simulation, but it runs
Next steps: swapping in our cell models, modifying pop parameters, etc.


** Synaptic clustering articles

Need to read these and pull relevant info.

Synaptic clustering articles:

Single excitatory axons form clustered synapses onto CA1 pyramidal cell dendrites
https://www.nature.com/articles/s41593-018-0084-6
“Here we show that single presynaptic axons form multiple, spatially clustered inputs onto the distal, but not proximal, dendrites of CA1 pyramidal neurons.”

Synaptic clustering by dendritic signalling mechanisms
https://www.sciencedirect.com/science/article/abs/pii/S095943880800086X
“Dendrites are endowed with mechanisms of nonlinear summation of synaptic inputs leading to regenerative dendritic events including local sodium, NMDA and calcium spikes. The generation of these events requires distinct spatio-temporal activation patterns of synaptic inputs. We hypothesise that the recent findings on dendritic spikes and local synaptic plasticity rules suggest clustering of common inputs along a subregion of a dendritic branch.”

Synaptic clustering within dendrites: An emerging theory of memory formation
https://www.sciencedirect.com/science/article/pii/S0301008214001373
“The emerging picture suggests that clusters of functionally related synapses may serve as key computational and memory storage units in the brain. We discuss both experimental evidence and theoretical models that support this hypothesis and explore its advantages for neuronal function.”

Synaptic clustering during development and learning: the why, when, and how
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3364493/
“Previous modeling and experimental studies have predicted that this specificity could entail a subcellular organization whereby synapses that carry similar information are clustered together on local stretches of dendrite. Recent imaging studies have now, for the first time, demonstrated synaptic clustering during development and learning in different neuronal circuits.”

Clusters of synaptic inputs on dendrites of layer 5 pyramidal cells in mouse visual cortex
https://elifesciences.org/articles/09222
“We mapped the spatial organization of glutamatergic synapses between layer 5 pyramidal cells by combining optogenetics and 2-photon calcium imaging in mouse neocortical slices. To mathematically characterize the organization of inputs we developed an approach based on combinatorial analysis of the likelihoods of specific synapse arrangements. We found that the synapses of intralaminar inputs form clusters on the basal dendrites of layer 5 pyramidal cells. These clusters contain 4 to 14 synapses within ≤30 µm of dendrite.”


* 2019-01-17 -- Setting up EEE populations

In progress
-----------
Setting up network model
Get our cell models in
Adjust population parameters
Set initial connectivity to Sergio's settings?

** Adjusting population properties

Sergio's original code:

	# add excitatory populations
	excPopLabels = ['PT5_1', 'PT5_2', 'PT5_3', 'PT5_4'] 
	for k,label in enumerate(excPopLabels):
	    netParams.popParams[label]  = {'cellModel': 'HH_reduced', 'cellType': label,  'xRange': columnA, 'ynormRange': layer['5'], 'numCells': numcellsPT5} 

	# add inhibitory population
	netParams.popParams['PV5']  = {'cellModel': 'HH_simple',  'cellType': 'PV','xRange': columnA, 'ynormRange': layer['5'], 'numCells': numcellsPV5} 

The layer['5'] comes from:
	
	# layer boundaries
	layer = {'5': [0.2,0.623], 'long': [0.7,1.0]} # yRange in column

Code from tutorial:

	netParams.popParams['E2'] = {'cellType': 'E', 'numCells': 50, 'yRange': [100,300], 'cellModel': 'HH'}
	netParams.popParams['I2'] = {'cellType': 'I', 'numCells': 50, 'yRange': [100,300], 'cellModel': 'HH'}
	netParams.popParams['E4'] = {'cellType': 'E', 'numCells': 50, 'yRange': [300,600], 'cellModel': 'HH'}
	netParams.popParams['I4'] = {'cellType': 'I', 'numCells': 50, 'yRange': [300,600], 'cellModel': 'HH'}
	netParams.popParams['E5'] = {'cellType': 'E', 'numCells': 50, 'ynormRange': [0.6,1.0], 'cellModel': 'HH'}
	netParams.popParams['I5'] = {'cellType': 'I', 'numCells': 50, 'ynormRange': [0.6,1.0], 'cellModel': 'HH'}

New code:

	## Population parameters
	netParams.popParams['PT5_1'] = {'cellType': 'E', 'numCells': 200, 'ynormRange': [0.2,0.623], 'cellModel': 'HH'}
	netParams.popParams['PT5_2'] = {'cellType': 'E', 'numCells': 200, 'ynormRange': [0.2,0.623], 'cellModel': 'HH'}
	netParams.popParams['PT5_3'] = {'cellType': 'E', 'numCells': 200, 'ynormRange': [0.2,0.623], 'cellModel': 'HH'}
	netParams.popParams['PT5_4'] = {'cellType': 'E', 'numCells': 200, 'ynormRange': [0.2,0.623], 'cellModel': 'HH'}
	netParams.popParams['PV5'] = {'cellType': 'I', 'numCells': 200, 'ynormRange': [0.2,0.623], 'cellModel': 'HH'}

Getting a strange NEURON error. Looking through netParams for any other necessary changes.

The I-->E pops need to be changed, from:

	netParams.connParams['I->E'] = {
	  'preConds': {'cellType': 'I'}, 'postConds': {'pop': ['E2','E4','E5']},       #  I -> E
	  
To:

	netParams.connParams['I->E'] = {
	  'preConds': {'cellType': 'I'}, 'postConds': {'pop': ['E']},       #  I -> E

Trying again.

Hmmm.  When I run it using once core, it seems to complete the sim, but stalls at the connectivity plot.  (There are 79621 connections, which probably would take awhile to plot...)

Reducing the number of cells and trying again.

Now it works and plots.  Trying it with multiple cores.

Still works.  Will add a variable to set the number of neurons.

Still works.  I have succesfully renamed the populations.

Now to use our cell models.  But first committing.


* 2019-01-18 -- Plugging PV5 model into network

In progress
-----------
Setting up network model
Get our cell models in
Set initial connectivity to Sergio's settings?

** Get our cell models in

Using info from here:
http://netpyne.org/advanced.html#importing-cells

*** Trying to swap in the PV5 cell model first

Sergio's code (from netParams.py):

	# Find path to cells directory
	cellpath = '../cells'
	eeeS_path = os.path.join(cellpath, 'eeeS.py')
	PV_path   = os.path.join(cellpath, 'FS3.hoc')

	# Import and modify PT5 cell
	cellRule = netParams.importCellParams(label='PT5_1', conds={'cellType': 'PT5_1', 'cellModel': 'HH_reduced'}, fileName=eeeS_path, cellName='MakeCell')

	# Import PV5 cell
	cellRule = netParams.importCellParams(label='PV5', conds={'cellType':'PV', 'cellModel':'HH_simple'}, fileName=PV_path, cellName='FScell1', cellInstance = True)

First changing all cellTypes from tutorial's E and I to PT5 and PV

Starting with importing the PV5 cell.

	## Import PV5 cell
	cellRule = netParams.importCellParams(label='PV5', conds={'cellType':'PV'}, fileName=PV_path, cellName='FScell1', cellInstance=True)
	netParams.cellParams['PVrule'] = cellRule

And attempting to run sim.

Getting an error:

	graham-mac:eee_net graham$ ipython -i netParams.py
	Python 3.7.1 (default, Dec 14 2018, 13:28:58) 
	Type 'copyright', 'credits' or 'license' for more information
	IPython 7.2.0 -- An enhanced Interactive Python. Type '?' for help.
	NEURON: syntax error
	 in FS3.hoc near line 37
	      insert Nafx
	                ^
	        xopen("FS3.hoc")
	      execute1("{xopen("FS...")
	    load_file("../cells/F...")
	Segmentation fault: 11

Looking into it.

I think I need to symlink the x86_64 dir into the dir eee_net...

That worked.  Now ./runsim works and generates figures, but PT5 trace figures didn't show up (PV5 trace figure did).  Looking into.

I changed the cellType of all PT5 pops from PT5_# to just PT5.  Switching back and seeing if trace figures work again.

Still none.

Ahh, I had commented out the code setting up the PT cells because I wasn't ready.  Uncommenting and checking.

Changed E to PT5:

	## Cell property rules
	cellRule = {'conds': {'cellType': 'PT5'},  'secs': {}}  # cell rule dict
	cellRule['secs']['soma'] = {'geom': {}, 'mechs': {}}                              # soma params dict
	cellRule['secs']['soma']['geom'] = {'diam': 15, 'L': 14, 'Ra': 120.0}                   # soma geometry
	cellRule['secs']['soma']['mechs']['hh'] = {'gnabar': 0.13, 'gkbar': 0.036, 'gl': 0.003, 'el': -70}      # soma hh mechanism
	netParams.cellParams['Erule'] = cellRule  

Now everything works fine.  Will commit and then insert eeeS cell model.


* 2019-01-21 -- Importing eeeS, gitting back to master

In progress
-----------
Setting up network model
Get our cell models in
Set initial connectivity to Sergio's settings?

** Chats 

	don [9:18 AM]
	joe, how is the code coming along. please let me know if there is anything i may help with

	joe [9:30 AM]
	I’m just sitting down at it now.  Right now it’s just Netpyne tutorial 5 broken into separate files.  I’m about to start setting it up how we discussed in the meeting.
	But if you could try running it now, that’d be great, and then you can help plug in the cell models, set the parameters, etc. with me.
	It’s in my branch right now: https://github.com/Neurosim-lab/EEE_network/tree/joes_branch
	GitHub
	Neurosim-lab/EEE_network
	Contribute to Neurosim-lab/EEE_network development by creating an account on GitHub.
	The README should explain how to run it.

	don [9:37 AM]
	ok … doing now

	don [9:45 AM]
	looks like i just pulled the same as before
	your branch is selected and then i clone
	i ran init.py

	joe [9:46 AM]
	After you clone, you have to `git checkout joes_branch`

	don [9:46 AM]
	oh, sorry!

	joe [9:47 AM]
	No worries.  git is confusing.

	joe [10:00 AM]
	So I left the old stuff in eee_network (so we can mine it for useful code) and I am now developing eee_net

	don [10:00 AM]
	ran. seems to run fine. gui windows appeared but i didn
	’t wait for content to appear
	need to run but will be back at it in about 1 hour

	joe [10:01 AM]
	:+1:

	don [12:48 PM]
	sorry, was pulled away longer than expected
	did a git fetch when i returned … guess you hadn’t updated repo?

	don [12:54 PM]
	running and displaying fine
	don’t want to redo that which you’ve already done so please assign me a task and i will do

	joe [2:25 PM]
	I’m trying to get all the old parameters and settings into the new model.  Probably won’t be done until sometime tomorrow.  Might as well wait until then to get you going so we don’t overlap.

	don [3:07 PM]
	Ok

	don [8:56 AM]
	how’s it going joe?

	joe [9:18 AM]
	Slowly, but it’s going.  I got the EEE populations into the model yesterday.  This morning I’m working on getting our cell models in.
	If you wanted to update your repo and make sure it still runs on your machine, that would be helpful.

	don [9:30 AM]
	already did and does ;)

	joe [9:33 AM]
	Sweet, thanks.  I’ll let you know when I get the cells in.

	don [9:48 AM]
	are the cells the ones in EEE_singlecell_simplified?

	joe [9:52 AM]
	We’ve got them in the repo as: `EEE_network/cells/eeeS.py` and `EEE_network/cells/FS3.hoc`
	But actually, there is something you could do that wouldn’t overlap!
	I’ve been meaning to re-compare `eeeS.py` with Penny’s detailed model again (it’s been awhile and she probably made some changes).
	We want to use all the same mod files, all the same parameter values, etc.

	joe [11:45 AM]
	Got the PV model cell inserted and working.  After lunch I’ll get the eeeS model plugged in.

	don [6:28 AM]
	Where can I find Penny’s original detailed model? Maybe EEE_singlecell_simplified? But says “simplified” not detailed model.

	joe [3:08 PM]
	Hmmm.  I’ll have to look for it.

	joe [3:12 PM]
	Hey Penny, Don is going to make sure that our simplified model uses all the same mod files and parameter values as your detailed model.  Is there some way we can access your current detailed model?

	penny [5:47 PM]
	Hello, here it is: https://github.com/super-penguin/EEE_Detailed_Cell. We are using the same mod files :-)
	GitHub
	super-penguin/EEE_Detailed_Cell
	A detailed model of prefrontal L5 pyramidal neuron --- for EEE project - super-penguin/EEE_Detailed_Cell
	But some of the parameters are a little bit different. I made changes to the simplified model from the network github repo before, but didn’t push it. I will push it tonight

	don [6:15 PM]
	great! thank you penny

	penny [7:27 PM]
	:+1:

	joe [7:47 PM]
	Thanks Penny!

	penny [12:39 AM]
	Hmmm, if I add a pull request, the new changes will be merged into the neurosim-lab/EEE_network master branch without permission. Is this how its set up?
	I just add a pull request, let me know if something is not right. Hope I didn’t mess up the repo

	joe [11:10 AM]
	Thanks, Penny! I don’t have a lot of experience with Git, but it looks like your pull request is great.  I’m just about to try inserting eeeS into the network model.  Once I get that working I’ll figure out how to merge my changes into the master branch.  :sweat_smile:

	penny [11:11 AM]
	Great! Thanks. I am pretty new to group work on github too:joy:


** Updating eeeS

I accepted Penny's pull request in the master branch, so the updated eeeS model is there.

I'm working in joes_branch though, so I need to get the latest model into my branch also.

I think I'll just download it from the master branch and copy and paste it into my local repo of joes_branch.

Cloning repo into temp, copying eeeS.py over to my repo of joes_branch.

That worked.  

	graham-mac:EEE_network graham$ git status
	On branch joes_branch
	Your branch is up to date with 'origin/joes_branch'.

	Changes not staged for commit:
	  (use "git add <file>..." to update what will be committed)
	  (use "git checkout -- <file>..." to discard changes in working directory)

		modified:   cells/eeeS.py
		modified:   nb_graham.org


Committing now.

** Swapping eeeS into network model

Here's how we now import the PV5 cell model:

	## Import PV5 cell
	cellRule = netParams.importCellParams(label='PV5', conds={'cellType':'PV'}, fileName=PV_path, cellName='FScell1', cellInstance=True)
	netParams.cellParams['PVrule'] = cellRule

Here's how we used to import the eeeS model:

	# Import and modify PT5 cell
	cellRule = netParams.importCellParams(label='PT5_1', conds={'cellType': 'PT5_1', 'cellModel': 'HH_reduced'}, fileName=eeeS_path, cellName='MakeCell')

But then to get separate pops, we used to copy the first cell rule:

	# make copy of cell rule for the other 3 pops
	# note: we are creating 1 cell type per pop because they could potentially have different Gfluct params           
	for k,label in enumerate(excPopLabels[1:]):    
	        cellRule = copy.deepcopy(netParams.cellParams['PT5_1'].todict())
	        cellRule['conds']['cellType'] = [label]
	        netParams.cellParams[label] = cellRule

Where

	excPopLabels = ['PT5_1', 'PT5_2', 'PT5_3', 'PT5_4']

I'm not quite sure what `cellInstance=True` does...  Can't find it anywhere in the Netpyne documentation.  I'll ask Salva.


** Asking Salva for help

	joe [11:43 AM]
	Hey Salva, in our old network code, when we did a `cellRule = netParams.importCellParams` we included the option `cellInstance=True`, but that never appears in the tutorial code, and I can’t find it in the Netpyne documentation.  Do you know if that does anything?

	salvadord [11:45 AM]
	yes it does … unfotunately a lot of stuff not documented
	cellInstance = True means you are extracting the cell parameters from a cell that has been instantiated from a template (hoc template or python class) instead of fromthe template itself (which is the default
	i.e. in the file you are importing from there’ll be something like `cell = PTCell()`

	joe [11:48 AM]
	Pretty sure I understand the distinction, just not sure what difference it would make.  I.e., is there a reason we need it for our eee network sims?

	joe [12:01 PM]
	One more question: in the old code, we used `importCellParams` once for PT5_1, and then deepcopied the cellRule three times for PT5_2, etc.  To me, this is less intuitive than just running `importCellParams` four times…  Does the copying offer some advantage I don’t see?

	salvadord [12:03 PM]
	no difference after being imported — just needed for some cases where eg. need to instantiate cell first because need to call cell class methdos that set some cell params
	needed for eee — not sure, I can check
	copying advantage - faster, since importing internally requires actually creating the cell in Neuron and using a bunch of Neuron funcs to extract all the params
	ideally all the cell params would remain the same, so could just create multiple populations from the same cellParams rule — however due to the setup of the artif noise input to cell, I think needed different cellParams entries

	joe [12:06 PM]
	Great, thanks Salva!

** Inserting eeeS cell model

New code:

	## Import eeeS cell (PT5)
	cellRule = netParams.importCellParams(label='PT5_1', conds={'cellType':'PT5_1'}, fileName=eeeS_path, cellName='MakeCell', cellInstance=True)
	netParams.cellParams['PT5_1'] = cellRule

	## Then copy the cellRule for the other pops (faster than importing again)
	## Note: we are creating 1 cell type per pop because they could potentially have different noise and connectivity params           
	for label in ['PT5_2', 'PT5_3', 'PT5_4']:    
	    cellRule = copy.deepcopy(netParams.cellParams['PT5_1'].todict())
	    cellRule['conds']['cellType'] = [label]
	    netParams.cellParams[label] = cellRule

And trying it out.  It ran, but not all figures appeared.  Need to change recording options to match cellTypes.

Actually, it already matched cellTypes.  The problem is that our eeeS cells have more than one soma compartment, requiring the following to record somas from both PV5 cells and PT5 (eeeS):

	cfg.recordTraces = {'V_soma':{'sec':'soma','loc':0.5,'var':'v'}}  # Dict with traces to record
	cfg.recordTraces['V_soma_0'] = {'sec':'soma_0','loc':0.5,'var':'v'}

The first line gets the soma from the PV cells, the second line gets a soma from the PT cells.  Problem is, neither has the other soma section, so trace-plotting gets hinky.

Easiest thing to do right now is probably compress the soma of eeeS into one compartment.  This will require figuring out how to keep the same surface area / volume, reconnecting all other branches to single soma, and testing before and after change to ensure they're the same.

About to go to lunch, so I'll see if Penny and Don can handle this.

** Chat with Penny and Don

	joe [12:41 PM]
	Hey Penny and Don, I’m still working on getting the network up and running, but there is something you guys could do in the meantime, if you have time.
	I’m having problems with figures.  PV cells have single soma compartment while eeeS cells have several.  That means I have to record two traces to see soma (`soma` in PV and `soma_0` or `soma_1` etc. in eeeS).  Since the other cell type doesn’t have that section, the figures break.
	I think the easiest fix would be just to collapse the several soma compartments in eeeS into a single one.
	This would require reconnecting branches to the new single soma and matching surface area/volume between multiple and new single cylinder.
	Then we’d probably want to run inputs into old multi-soma and new single-soma to ensure they behave the same.
	I’m about to head to lunch, but I’ll be back later.

	don [1:41 PM]
	i’m looking though newly fetched EEE_network … not seeing new stuff. maybe i’m looking in wrong place?

	joe [2:04 PM]
	I’m working in `joes_branch` in the `eee_net` directory.  The `eee_network` directory is the old stuff I’m keeping around until we get all useful code out of it.

	don [2:05 PM]
	makes sense

	penny [2:11 PM]
	Got it. Will look into it soon :slightly_smiling_face:


** Using cellType different from pop name

Was having to do a lot of work to connect pops.  Instead of having each pop having a cellType set to its name, all PT5 pops now have cellType PT5.

Now I can wire individually to a pop or collectively to a cellType.

e.g. conds: {'pop': PT5_1} or conds: {'cellType': PT5}

And running.  Looks good except background seems to have zero connectivity.

Problem was I was using old cellTypes in the bkg setting.

Changed from this:

	netParams.stimTargetParams['bkg->all'] = {'source': 'bkg', 'conds': {'cellType': ['PV','PT5_1','PT5_2','PT5_3','PT5_4']}, 'weight': 0.01, 'delay': 'max(1, normal(5,2))', 'synMech': 'exc'}

To this:

	netParams.stimTargetParams['bkg->all'] = {'source': 'bkg', 'conds': {'cellType': ['PV5','PT5']}, 'weight': 0.01, 'delay': 'max(1, normal(5,2))', 'synMech': 'exc'}

Now it works and everything looks good.

Committing.

** Replacing master branch with joes_branch

Now that my branch is working, I want to actually replace everything in the master branch with my own.

https://stackoverflow.com/questions/2862590/how-to-replace-master-branch-in-git-entirely-from-another-branch

Cleaned up some extraneous comments.  Committing now and then will attempt the branch grafting.

Commands to graft:

	git checkout joes_branch
	git merge -s ours master
	git checkout master
	git merge joes_branch

Doesn't seem to be working.  

	graham$ git merge -s ours master
	Already up to date.

I'm going to do it quick and dirty.  First, I'll make a branch copy of master named old_master.  

	graham-mac:EEE_network graham$ git checkout master
	Switched to branch 'master'
	Your branch is up to date with 'origin/master'.
	graham-mac:EEE_network graham$ git branch -m master old_master
	graham-mac:EEE_network graham$ git branch
	  joes_branch
	* old_master
	graham-mac:EEE_network graham$ git push
	fatal: The upstream branch of your current branch does not match
	the name of your current branch.  To push to the upstream branch
	on the remote, use

	    git push origin HEAD:master

	To push to the branch of the same name on the remote, use

	    git push origin old_master

	graham-mac:EEE_network graham$ git push origin old_master
	Total 0 (delta 0), reused 0 (delta 0)
	remote: 
	remote: Create a pull request for 'old_master' on GitHub by visiting:
	remote:      https://github.com/Neurosim-lab/EEE_network/pull/new/old_master
	remote: 
	To https://github.com/Neurosim-lab/EEE_network.git
	 * [new branch]      old_master -> old_master
	graham-mac:EEE_network graham$ 


Now to forcefully replace master with joes_branch

	graham-mac:EEE_network graham$ git checkout master
	error: Your local changes to the following files would be overwritten by checkout:
		nb_graham.org
	Please commit your changes or stash them before you switch branches.
	Aborting
	graham-mac:EEE_network graham$ 

Oops.  Need to commit the notebook changes first.

	graham-mac:EEE_network graham$ git checkout master
	error: Your local changes to the following files would be overwritten by checkout:
		nb_graham.org
	Please commit your changes or stash them before you switch branches.
	Aborting
	graham-mac:EEE_network graham$ git status
	On branch joes_branch
	Your branch is up to date with 'origin/joes_branch'.

	Changes not staged for commit:
	  (use "git add <file>..." to update what will be committed)
	  (use "git checkout -- <file>..." to discard changes in working directory)

		modified:   nb_graham.org

	Untracked files:
	  (use "git add <file>..." to include in what will be committed)

		cells/__pycache__/
		eee_net/__pycache__/
		eee_net/x86_64
		eee_network/__pycache__/
		mod/x86_64/
		x86_64

	no changes added to commit (use "git add" and/or "git commit -a")
	graham-mac:EEE_network graham$ git add nb_graham.org 
	graham-mac:EEE_network graham$ git status
	On branch joes_branch
	Your branch is up to date with 'origin/joes_branch'.

	Changes to be committed:
	  (use "git reset HEAD <file>..." to unstage)

		modified:   nb_graham.org

	Untracked files:
	  (use "git add <file>..." to include in what will be committed)

		cells/__pycache__/
		eee_net/__pycache__/
		eee_net/x86_64
		eee_network/__pycache__/
		mod/x86_64/
		x86_64

	graham-mac:EEE_network graham$ git commit -m "Notebook commit before branch grafting."
	[joes_branch 6251998] Notebook commit before branch grafting.
	 1 file changed, 52 insertions(+)
	graham-mac:EEE_network graham$ git checkout master
	Switched to branch 'master'
	Your branch is behind 'origin/master' by 2 commits, and can be fast-forwarded.
	  (use "git pull" to update your local branch)
	graham-mac:EEE_network graham$ git pull
	Updating 5fb1177..1f6a291
	Fast-forward
	 cells/eeeS.py | 64 +++++++++++++++++++---------------------------------------------
	 1 file changed, 19 insertions(+), 45 deletions(-)
	graham-mac:EEE_network graham$ git reset --hard joes_branch
	HEAD is now at 6251998 Notebook commit before branch grafting.
	graham-mac:EEE_network graham$ git push -f origin master
	Counting objects: 3, done.
	Delta compression using up to 8 threads.
	Compressing objects: 100% (3/3), done.
	Writing objects: 100% (3/3), 953 bytes | 953.00 KiB/s, done.
	Total 3 (delta 2), reused 0 (delta 0)
	remote: Resolving deltas: 100% (2/2), completed with 2 local objects.
	To https://github.com/Neurosim-lab/EEE_network.git
	 + 1f6a291...6251998 master -> master (forced update)
	graham-mac:EEE_network graham$ 

That seems to have worked fine.  :)

Updating the README.

Committing then pushing.


* 2019-01-22 -- EEE Meeting and various fixes

In progress
-----------
Setting up network model
Set up synaptic mechanisms
Set initial connectivity to Sergio's settings

** EEE meeting

Agenda:
https://docs.google.com/document/d/1ifVpuQo0gJJhj8epg4cWRoeJSASfI8AP3HP-oRDOteo/edit


** Collapsing soma into single compartment

Penny got this going, new cell is eeeS1.py.  I am renaming eeeS.py to eeeS_multi.py and renaming eeeS1.py as eeeS.py.

Commenting out the other soma trace request in cfg.py:
	#cfg.recordTraces['V_soma_0'] = {'sec':'soma_0','loc':0.5,'var':'v'}

Getting an error when I run the sim.

Found it by running netParams.py

	graham-mac:eee_net graham$ ipython -i netParams.py
	Python 3.7.1 (default, Dec 14 2018, 13:28:58) 
	Type 'copyright', 'credits' or 'license' for more information
	IPython 7.2.0 -- An enhanced Interactive Python. Type '?' for help.
	Balancing each compartment to -73 mV
	  File "../cells/eeeS.py", line 143
	    print "geom_nseg: changed from ", before, " to ", after, " total segments"
	                                   ^
	SyntaxError: Missing parentheses in call to 'print'. Did you mean print("geom_nseg: changed from ", before, " to ", after, " total segments")?

Added parentheses to print statement:

	print("geom_nseg: changed from ", before, " to ", after, " total segments")

Had to add parentheses to a bunch of print statements.

Now a new error:

	~/EEE_network/cells/eeeS.py in create_cell(self)
	    540         self.soma = h.Section(name='soma')
	    541         self.apical = [h.Section(name='apical[0]')]
	--> 542         self.basal = [h.Section(name='basal[%d]' % i) for i in xrange(10)]
	    543         self.axon = [h.Section(name='axon[0]')]
	    544 

	NameError: name 'xrange' is not defined

It seems xrange doesn't exist in Python 3.  range should do the same thing

Now it runs.  Output:

file:nb_gif/20190122_082937.png
file:nb_gif/20190122_082949.png
file:nb_gif/20190122_083017.png
file:nb_gif/20190122_083027.png
file:nb_gif/20190122_083039.png

Committing now and pushing.

** Chat with Penny and Don

	penny [11:01 PM]
	Hey Joe, the soma is collapsed into one compartment. I compared the plateau, it is consistent with the original simplified cell. I am not sure if it would cause any conflict, so I saved it in a new cell file called eeeS1.py (the class in this file is named as eeeS1).

	joe [7:53 AM]
	Awesome, thanks! I’ll try it out now.

	don [8:03 AM]
	is eeeS1 checked to joes_branch? don’t see it. sorry i’m not being much help :/

	joe [8:05 AM]
	Forget about joes_branch now (just as you were getting used to it).  :wink:  Everything is in master again now.
	Penny did a pull request and I just merged it into master.
	You’re fine Don, once we have the baseline model done we can all explore it.

	don [8:11 AM]
	ok. back to master. ty

	penny [9:00 AM]
	No worry Don, we are more familiar with the cell model. All minor changes. You can help more for the network part :slightly_smiling_face:

	don [9:10 AM]
	quick attempt to run (under eee_net) threw this error:

	NEURON: syntax error
	in FS3.hoc near line 37
	     insert Nafx
	               ^
	       xopen(“FS3.hoc”)
	     execute1(“{xopen(“FS...“)
	   load_file(“../cells/F...“)
	Segmentation fault: 11
	running under py3

	joe [9:18 AM]
	Could be one of two easy things: 1) make sure you compiled the mod files, 2) make sure `x86_64` dir is properly simlinked into `eee_net` dir.  Could also probably be a million complicated things.  :wink:

	don [9:19 AM]
	was thinking mod files while you typed ;)
	running now

	joe [9:20 AM]
	:sweat_smile:

	don [9:20 AM]
	looks good. all plots, etc showing correctly

	joe [9:21 AM]
	Awesome.  I’m off for a hike, but then I hope to get syn mechs and connectivity in today.
	That may be too ambitious.  We shall see.

	penny [9:25 AM]
	:+1:

	penny [9:51 AM]
	When I run python init.py, the figures can’t show up properly. Have u guys ever seen this before?
	No figures showing up 
	MacBook-Pro:eee_net Penny$ python init.py
	Balancing each compartment to -73 mV
	​
	Creating network of 5 cell populations on 1 hosts...
	 Number of cells on node 0: 100 
	 Done; cell creation time = 0.25 s.
	Making connections...
	 Number of connections on node 0: 1086 
	 Done; cell connection time = 0.07 s.
	Adding stims...
	 Number of stims on node 0: 100 
	 Done; cell stims creation time = 0.01 s.
	Recording 5 traces of 1 types on node 0
	​
	Running simulation for 1000 ms...
	 Done; run time = 33.19 s; real-time ratio: 0.03.
	​
	Gathering data...
	 Done; gather time = 0.19 s.
	​
	Analyzing...
	 Cells: 100
	 Connections: 1186 (11.86 per cell)
	 Spikes: 995 (9.95 Hz)
	 Simulated time: 1.0 s; 1 workers
	 Run time: 33.19 s
	 Done; saving time = 0.05 s.
	Plotting raster...
	Plotting recorded cell traces ...
	INFO:matplotlib.backends._backend_tk:Could not load matplotlib icon: can't use "pyimage10" as iconphoto: not a photo image
	INFO:matplotlib.backends._backend_tk:Could not load matplotlib icon: can't use "pyimage19" as iconphoto: not a photo image
	INFO:matplotlib.backends._backend_tk:Could not load matplotlib icon: can't use "pyimage28" as iconphoto: not a photo image
	INFO:matplotlib.backends._backend_tk:Could not load matplotlib icon: can't use "pyimage37" as iconphoto: not a photo image
	INFO:matplotlib.backends._backend_tk:Could not load matplotlib icon: can't use "pyimage46" as iconphoto: not a photo image
	Plotting 2D representation of network cell locations and connections...
	INFO:matplotlib.backends._backend_tk:Could not load matplotlib icon: can't use "pyimage55" as iconphoto: not a photo image
	Plotting connectivity matrix...
	INFO:matplotlib.backends._backend_tk:Could not load matplotlib icon: can't use "pyimage64" as iconphoto: not a photo image
	 Done; plotting time = 1.84 s
	​
	Total time = 35.61 s
	Collapse 
	I checked matplotlib, it is good. Not sure where the problem is.

	joe [9:53 AM]
	I haven’t done anything with `init.py` yet, that’s really for running batches of sims.  Right now `./runsim` should work though…

	penny [9:54 AM]
	Untitled 
	MacBook-Pro:eee_net Penny$ ./runsim
	[MacBook-Pro.local:97715] [[1500,0],0] mca_oob_tcp_recv_handler: invalid message type: 15
	[MacBook-Pro.local:97715] [[1500,0],0] mca_oob_tcp_recv_handler: invalid message type: 15
	[MacBook-Pro.local:97715] [[1500,0],0] mca_oob_tcp_recv_handler: invalid message type: 15
	[MacBook-Pro.local:97715] [[1500,0],0] mca_oob_tcp_recv_handler: invalid message type: 15
	--------------------------------------------------------------------------
	mpiexec noticed that the job aborted, but has no info as to the process
	that caused that situation.
	Collapse 
	When I do ./runsim, this error showed up. I can’t locate the problem, so tried init.py. So strange

	joe [9:55 AM]
	Hmmm.  Seems to be a problem with your MPI stuff.  Try running `./runsim 1`, which forces everything onto one core…

	penny [9:55 AM]
	Okay

	don [9:55 AM]
	i ran init.py but from python console
	ran fine
	after i compiled mods :)

	penny [9:57 AM]
	I see. Thanks. the errors are strange
	Untitled 
	MacBook-Pro:eee_net Penny$ ./runsim 1
	[MacBook-Pro.local:97848] [[1623,0],0] mca_oob_tcp_recv_handler: invalid message type: 15
	--------------------------------------------------------------------------
	mpiexec noticed that the job aborted, but has no info as to the process
	that caused that situation.

	don [9:57 AM]
	trying python init.py now

	joe [9:57 AM]
	You could post it in #tech and see if anybody else knows.  I have no idea.

	don [9:57 AM]
	windows don’t show because program exits
	no errors
	py3

	penny [9:58 AM]
	Okay. I will ask in #tech too! Thanks :slightly_smiling_face:

	joe [9:58 AM]
	Speaking of which, Don, if you could figure out how to save the figures in Netpyne (right now they don’t get saved for some reason), that would be really helpful.
	Off to a mountain for an hour.

	don [10:00 AM]
	what is 1 arg for Penny?
	when i run ./runsim 1 the windows remain blank

	penny [10:01 AM]
	Thats the number of core used

	don [10:01 AM]
	doesn’t throw an error that i can see

	penny [10:02 AM]
	sorry, number of processes

	don [10:02 AM]
	understood. ty

	penny [10:02 AM]
	Ah, when I run python -i init.py, all the figures showed up properly!
	Strange.

	don [10:03 AM]
	something about running mpi

	penny [10:05 AM]
	I guess I set up something wrong.        python init.py   --- network model runs successfully, but no figures show up;  python -i init.py    --- network  runs successfully and figures show up.
	I am guessing in the file init.py, the last part    sim.analysis.plotData()    needs to be set up with some paramters

	don [10:07 AM]
	ran:

	mpiexec -np 1 nrniv -python -mpi init.py
	numprocs=1

	got:

	There was an exception in plotConn():
	module ‘matplotlib.pyplot’ has no attribute ‘hold’

	penny [10:07 AM]
	Hmmm
	I tried the same command, but got different errors with the last plotting part. Strange.
	Going to check the netpyne documentation

	don [10:10 AM]
	you’re also using py3?

	penny [10:10 AM]
	yes

	don [10:11 AM]
	hmmm. you’re running on a mac?

	penny [10:12 AM]
	yup

	don [10:12 AM]
	argh!
	go figure …

	penny [10:13 AM]
	lol

	joe [12:44 PM]
	Did you guys get your problems sorted?

	don [12:45 PM]
	joe, it runs fine except under mpi
	i didn’t pursue mpi issue

	joe [12:45 PM]
	Penny, I realize that `./runsim` just calls `init.py` and parallelizes it.  So the first thing is to make sure you can run `init.py`.  You know, like you were trying before I said it was an mpi problem.  :joy:
	I can’t help with mpi issues.  I’m a neuroscientist in a computer scientist’s world.
	Did you have a chance to look into how to save figures, Don?

	don [12:48 PM]
	generally use cfg.analysis
	like:

	cfg.analysis[‘plotSpikeHist’] = {‘include’: [‘IT2’], ‘timeRange’: [0,1000], ‘yaxis’:‘rate’, ‘binSize’:5, ‘graphType’:‘bar’, ‘saveFig’: True, ‘showFig’: False, ‘popColors’: popColors, ‘figSize’: (10,4), ‘dpi’: 300}

	joe [12:57 PM]
	Yeah, tried to just add a saveFig option.  Didn’t work.
	Penny, if the problem is figures don’t show up for you, can you try uncommenting this line in `cfg.py`?
	#import pylab; pylab.show()  # this line is only necessary in certain systems where figures appear empty
	Hmmm.  Now figures aren’t showing up for me either.
	The problem may be this printout:
	Untitled 
	Reading command line arguments using syntax: python file.py [simConfig=filepath] [netParams=filepath]
	​
	Warning: Could not load cfg from command line path or from default cfg.py

** Summary of chat

Penny was having figures not show up.  Also problems with MPI.  Now my own figures aren't showing up.  It seems Netpyne is no longer reading the config file (cfg.py) properly.

I am going to commit, push, and then try the following commands as a sanity check:

cd ~ ; mkdir eee_temp ; cd eee_temp ; git clone https://github.com/Neurosim-lab/EEE_network.git ; cd EEE_network/mod ; nrnivmodl ; cd ../eee_net ; ln -s "../mod/x86_64" x86_64 ; ./runsim 1

** Chats 

	joe [1:44 PM]
	Moving a conversation here.
	I just pushed to repo.  For some reason, it’s no longer reading the config file.  Getting the same thing as the last Warning I posted.
	If you guys could update your repos and try to figure out why it’s not reading the config file, that would be helpful.
	The following one-liner should run everything (and it did until just recently):
	Untitled 
	cd ~ ; rm -rf eee_temp ; mkdir eee_temp ; cd eee_temp ; git clone https://github.com/Neurosim-lab/EEE_network.git ; cd EEE_network/mod ; nrnivmodl ; cd ../eee_net ; ln -s "../mod/x86_64" x86_64 ; ./runsim 1

	don [1:46 PM]
	running fine here joe except it throws an error on connectivity matrix

	Plotting connectivity matrix...
	There was an exception in plotConn():
	module ‘matplotlib.pyplot’ has no attribute ‘hold’
	running from py3 command

	joe [1:47 PM]
	Untitled 
	Reading command line arguments using syntax: python file.py [simConfig=filepath] [netParams=filepath]
	​
	Warning: Could not load cfg from command line path or from default cfg.py
	I’ve never seen that before, but Salva might know.
	Looking into why reading the config file failed…

	salvadord [1:54 PM]
	bugs in cfg.py
	run python cfg.py to see
	the last 2 lines are buggy

	joe [1:57 PM]
	Thanks.  Just figured out cfg crashed.  Everything is obvious in hindsight.  :joy:

** Fixing problems

So the problem was that running cfg.py caused a crash.  Fixed that problem. Sloppy coding. 

I believe it works now.  Pushing now to try.  After, the following should work:

	cd ~ ; rm -rf eee_temp ; mkdir eee_temp ; cd eee_temp ; git clone https://github.com/Neurosim-lab/EEE_network.git ; cd EEE_network/mod ; nrnivmodl ; cd ../eee_net ; ln -s "../mod/x86_64" x86_64 ; ./runsim 1

It does work now.  Asking others to try.

	salvadord [1:54 PM]
	bugs in cfg.py
	run python cfg.py to see
	the last 2 lines are buggy

	joe [1:57 PM]
	Thanks.  Just figured out cfg crashed.  Everything is obvious in hindsight.  :joy:

	joe [2:11 PM]
	Okay, fixed problem in cfg.py, and now everything seems to work.  Added `showFig` and `saveFig` options in cfg.py.  Committed and pushed.  I would appreciate if people would run the following one-liner and let me know if it crashes:
	Untitled 
	cd ~ ; rm -rf eee_temp ; mkdir eee_temp ; cd eee_temp ; git clone https://github.com/Neurosim-lab/EEE_network.git ; cd EEE_network/mod ; nrnivmodl ; cd ../eee_net ; ln -s "../mod/x86_64" x86_64 ; ./runsim
	Penny, let us know if you’re still getting MPI issues, and we’ll try to solve them.

	The one-liner should both display figures and save figures to: `~/eee_temp/EEE_network/eee_net`

	salvadord [2:16 PM]
	one-liner works for me! :woman-with-bunny-ears-partying:

	billl [2:17 PM]
	remind from whence to clone

	salvadord [2:17 PM]
	one-liner above does everything, including clone

	billl [2:18 PM]
	oh

	joe [2:28 PM]
	Don, let us know if you still get that plotConn error with the one-liner.  No hurry.
	Salva, would it be useful to have a Netpyne “pre-checker” that throws an error if either netParams.py or cfg.py crashes during loading?  I’d be happy to put a ticket in (and even work on it in my spare time), but I’m not sure if that’s worthwhile.

	salvadord [2:33 PM]
	what would be difference with warning msg you got above?

	billl [2:33 PM]
	failed; supposed to run with 3 or 2?

	joe [2:36 PM]
	Salva: it didn’t throw an error, just a non-specific warning.  It’s just I’ve had this problem before, and it would immediately remind me to check and make sure both netParams.py and cfg.py don’t throw an error.
	Bill: 3

	billl [2:36 PM]
	maybe need to build py3 into runsim?

	joe [2:37 PM]
	I have switched to Python 3 completely.  Finally.  I wouldn’t know how to include a Python version choice in runsim… but I’m open to suggestions.

	billl [2:38 PM]
	call it python3 typically

	salvadord [2:39 PM]
	joe: the warning is result of error loading cfg.py so maybe can just change warning msg to make clearer and/or stop execution — but sure feel free to open gituhb issue and work on it if have time… Im sure helpful

	joe [2:39 PM]
	The active line in runsim is: `mpiexec -np $numprocesses nrniv -python -mpi init.py $@  # Run the model`

	billl [2:39 PM]
	nrniv generally deprecated
	get this error now  `/usr/bin/python3: No module named pi`

	salvadord [2:40 PM]
	can you run with mpi calling python instead of nrniv?

	joe [2:40 PM]
	I would love to try.  How would you change the active line to make that happen?

	salvadord [2:41 PM]
	oh Im asking if possible :slightly_smiling_face:

	ramcdougal [2:41 PM]
	normally yes

	billl [2:41 PM]
	this maybe?  mpiexec -np $numprocesses python3 -mpi init.py $@  # Run the model

	ramcdougal [2:41 PM]
	not sure if something weird about this model
	drop the -mpi
	that tells it to run a module called mpi
	errr
	called pi

	billl [2:41 PM]
	oh ic

	ramcdougal [2:42 PM]
	e.g. python -m CGIHTTPServer launches a server
	in py2
	but yeah

	billl [2:42 PM]
	so how to run with python with mpi?

	ramcdougal [2:42 PM]
	no need for the -mpi
	as long as you have
	a `from mpi4py import MPI` before you import NEURON
	in super recent versions of NEURON, there's also a parallelcontext solution that removes the need for the `mpi4py` module...

	billl [2:43 PM]
	ic -- so would need to include in the init joe

	joe [2:46 PM]
	Untitled 
	 File "init.py", line 17, in <module>
	  from mpi4py import MPI
	ModuleNotFoundError: No module named 'mpi4py'

Error:

Traceback (most recent call last):
  File "init.py", line 17, in <module>
    from mpi4py import MPI
ModuleNotFoundError: No module named 'mpi4py'

pip install mpi4py

	graham-mac:EEE_network graham$ pip install mpi4py
	Collecting mpi4py
	  Downloading https://files.pythonhosted.org/packages/31/27/1288918ac230cc9abc0da17d84d66f3db477757d90b3d6b070d709391a15/mpi4py-3.0.0.tar.gz (1.4MB)
	    100% |████████████████████████████████| 1.4MB 6.3MB/s 
	Building wheels for collected packages: mpi4py
	  Running setup.py bdist_wheel for mpi4py ... done
	  Stored in directory: /Users/graham/Library/Caches/pip/wheels/23/03/c5/30289417f1428c692651e046174b64ac871a377df227802bf6
	Successfully built mpi4py
	Installing collected packages: mpi4py
	Successfully installed mpi4py-3.0.0

Now it runs.  Committing, pushing, asking others to run one-liner.

Whoops, actually changed the old runsim.  Reverting that, changing new one, and trying again.

Hmm.  Four processes and four of each figure.

	joe [2:56 PM]
	Hmmm.  Changing to remove -mpi and importing mpi4py made things wonky…  Running on four cores and got four of each figure…

	billl [2:56 PM]
	ok well if i'm only 1 with a problem let's ot worry on this
	i'll fix for myself

	joe [2:56 PM]
	:+1: Sweet.  Moving on.

Switching back, and everything works as expected.

Will commit, test one-liner, and then move on to swapping in our synaptic mechs.

One-liner worked.  Moving on.


* 2019-01-23 -- Synaptic mechanisms

In progress
-----------
Setting up network model
Set up synaptic mechanisms
Set initial connectivity to Sergio's settings


** Setting up synaptic mechanisms

Want to swap in our synaptic mechanisms for the generic Exp2Syns from the tutorial.

Code from old model:

	# MyExp2syn synaptic mechanisms
	netParams.synMechParams['GABAAfast'] = {'mod':'MyExp2SynBB','tau1':0.07,'tau2':18.2,'e': cfg.GABAAfast_e}
	netParams.synMechParams['GABAAslow'] = {'mod': 'MyExp2SynBB','tau1': 10, 'tau2': 200, 'e': cfg.GABAAslow_e}

	# DMS synaptic mechanisms 
	netParams.synMechParams['NMDA'] = {'mod': 'NMDAeee', 'Cdur': cfg.CdurNMDAScale * 1.0, 'Alpha': cfg.NMDAAlphaScale * 4.0, 'Beta': cfg.NMDABetaScale * 0.0015, 'gmax': cfg.NMDAgmax, 'e': cfg.eNMDA}
	netParams.synMechParams['AMPA'] = {'mod': 'AMPA', 'gmax': cfg.ratioAMPANMDA * cfg.NMDAgmax}

	ESynMech = ['AMPA','NMDA']
	ISynMech = ['GABAAfast','GABAAslow']

Code from tutorial:

	## Synaptic mechanism parameters
	netParams.synMechParams['exc'] = {'mod': 'Exp2Syn', 'tau1': 0.8, 'tau2': 5.3, 'e': 0}  # NMDA synaptic mechanism
	netParams.synMechParams['inh'] = {'mod': 'Exp2Syn', 'tau1': 0.6, 'tau2': 8.5, 'e': -75}  # GABA synaptic mechanism

Will need to add some parameters to the config file (or decide to hardcode them):

	Parameter 				cfg.py value            mod value
	=================       ==================      ============
	cfg.GABAAfast_e          -80.0                   0.0
	cfg.GABAAslow_e          -90.0                   0.0
	cfg.CdurNMDAScale          1.0                   1.0
	cfg.NMDAAlphaScale         1.0 (*4.0)            4.0
	cfg.NMDABetaScale         14.0                   0.0015
	cfg.NMDAgmax               0.01                  1.0
	cfg.eNMDA                -10.0                   0.0
	cfg.ratioAMPANMDA          4.0                   n/a

First, should make sure these parameters don't change the values that Penny uses in the detailed model.

Detailed model here:
https://github.com/super-penguin/EEE_Detailed_Cell

	Parameter 				Detailed model
	=================       ==================
	cfg.CdurNMDAScale        
	cfg.NMDAAlphaScale         
	cfg.NMDABetaScale         
	cfg.NMDAgmax               
	cfg.eNMDA                
	cfg.ratioAMPANMDA          

Actually, first I want to see which NMDA mod files are used in the detailed model:

The DMS model uses:   h.NMDA     
	from mod file :  NMDA.mod
	https://github.com/super-penguin/EEE_Detailed_Cell/blob/master/mod/NMDA.mod
With values set to:
    SynNMDA[-1].gmax = 0.005
    SynNMDA[-1].Beta = Beta
    SynNMDA[-1].Cdur = Cdur

The Major model uses:  h.nmda     
	from mod file   : NMDAmajor.mod
	https://github.com/super-penguin/EEE_Detailed_Cell/blob/master/mod/NMDAmajor.mod
With values set to:
    tempNMDA.gmax = 0.005 * Syn_w1

Hmmm.  So it seems that Penny's model uses a different NMDA mod file than we are (NMDA.mod --> NMDA, while we use NMDAeee.mod --> NMDAeee)

I'll have to run a diff.  Or just switch to Penny's mod file...

Hmmmm.  No sense in running a diff.  I'll ask in Slack which mod we want to start using for the network model.  


* 2019-01-25 -- Synaptic mechs and connectivity 

In progress
-----------
Setting up network model
Set up synaptic mechanisms
Set initial connectivity to Sergio's settings


** Setting up synaptic mechanisms

Asking about which NMDA mod to use:

	joe [9:37 AM]
	It’s easy enough to swap them out, but I’m wondering which of the detailed model’s NMDA mod files we should start using for the network model, the DMS or the Major?

	billl [9:38 AM]
	DMS since faster
	but if you have any reason for a major Major or a minor Major preference then can do that

So the DMS model is NMDA.mod.  I notice we already have an NMDA.mod in the network mod dir.  I'm going to compare with Penny's.

Penny's:
https://github.com/super-penguin/EEE_Detailed_Cell/blob/master/mod/NMDA.mod

Network:
https://github.com/Neurosim-lab/EEE_network/blob/master/mod/NMDA.mod

Diff using Sublime:

	--- /Users/graham/Desktop/NMDAdiff/NMDA_net.mod	Fri Jan 25 10:08:57 2019
	+++ /Users/graham/Desktop/NMDAdiff/NMDA_penny.mod	Fri Jan 25 10:09:26 2019
	@@ -81,7 +81,7 @@
	 	Cmax	= 1	 (mM)           : max transmitter concentration
	 	Cdur	= 1	 (ms)		: transmitter duration (rising phase)
	 	Alpha	= 4 (/ms /mM)	: forward (binding) rate (4)
	-	Beta 	=0.01   (/ms)
	+	Beta 	=0.01   (/ms)   : backward (unbinding) rate
	 	e	= 0	 (mV)		: reversal potential
	     mg   = 1      (mM)           : external magnesium concentration
	 	gmax = 1   (uS)

No significant differences, but I'll replace the network NMDA.mod with Penny's just so they're identical.

I see the network mod dir doesn't have Penny's NMDAmajor.mod:
https://github.com/super-penguin/EEE_Detailed_Cell/blob/master/mod/NMDAmajor.mod

I'll add it to the network mod dir.

Don't know what this means, but adding here just in case it becomes a problem:

	graham-mac:EEE_network graham$ git add mod/NMDAmajor.mod 
	warning: CRLF will be replaced by LF in mod/NMDAmajor.mod.
	The file will have its original line endings in your working directory.

Here's the current network NMDA settings:

	netParams.synMechParams['NMDA'] = {'mod': 'NMDAeee', 'Cdur': cfg.CdurNMDAScale * 1.0, 'Alpha': cfg.NMDAAlphaScale * 4.0, 'Beta': cfg.NMDABetaScale * 0.0015, 'gmax': cfg.NMDAgmax, 'e': cfg.eNMDA}

Need to change it to use NDMA.mod, and ensure the parameter values are the same as Penny's.

Here's how she sets up her NMDA:

    #Adding NMDA
    SynNMDA.append(h.NMDA(Cell.basal[34](loc1[i])))
    SynNMDA[-1].gmax = 0.005
    SynNMDA[-1].Beta = Beta
    SynNMDA[-1].Cdur = Cdur
    nc_NMDA.append(h.NetCon(ns, SynNMDA[i]))
    nc_NMDA[-1].delay = delay1[i]
    nc_NMDA[-1].weight[0] = Syn_w1

Here's the function she uses to run sims for figure 3:

	def Glu_Stim(TTX = False, Pool1_num = 9, Pool2_num = 9, Beta = 0.067,
	Cdur = 1, Syn_w1 = 0.01, Syn_w2 = 0.01, Loc = [0.2, 0.6]):

And here's how she calls that function for the figure 3 simulations
https://github.com/super-penguin/EEE_Detailed_Cell/blob/master/Fig3_exp_dms.py

    loc = [0.25, 0.6]
    weight = [0.1, 0.15, 0.20, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]

    for w in weight:
        Pool_num = 8 + int(20*w)
        Glu_Stim(False, Pool_num, Pool_num, 0.02, 50 + int(100*w), w, w, loc)

There are a couple things I find odd here...  

1) the number of synapses (Pool_num) is a function of the weight of glutamate stim instead of a constant
2) Cdur is also a function of weight
3) default Beta is 0.067, but the call uses 0.02

I'm going to look into how she runs sims for figure 5:
https://github.com/super-penguin/EEE_Detailed_Cell/blob/master/Fig5_exp_DMS.py

Here's her function:

	def Glu_Stim(Bnum = 34, TTX = False, Pool1_num = 9, Pool2_num = 9,
	Beta = 0.067, Cdur = 1, Syn_w1 = 0.01, Syn_w2 = 0.01, Loc = [0.2, 0.6], DenLoc = 0.5):

Here's how she calls it:

    Pool_num = 12
    weight = [0.7, 0.9] # 0.7 for Fig 5. B1, 0.9 for Fig D1

    basal_num = [15, 34, 14, 22, 25, 31]
    with open('data.json', 'r') as fp:
        data = json.load(fp)
    with open('dend_measure_data.json', 'r') as fp1:
        Ndata = json.load(fp1)

    for b in basal_num:
        loc = data[str(b)]
        DenLoc = Ndata[str(b)]
        for l1, l2 in zip(loc, DenLoc):
            for w in weight:
                Glu_Stim(b, False, Pool_num, Pool_num, 0.02, 10, w, w, l1, l2)
                Glu_Stim(b, True, Pool_num, Pool_num, 0.02, 10, w, w, l1, l2)

Okay, so here anyway, Pool_num is a constant (12) and Cdur is a constant (10).

Beta is set to 0.02 (though 0.067 is the default).  Looking into the values of Beta and Cdur in the NMDA.mod file.

Beta is 0.01 in NMDA.mod
Cdur is 1 in NMDA.mod

I should bring these oddities up with Penny et al.

One other thing: she uses a 1:1 NMDA:AMPA weight ratio...  We had always used an AMPA/NMDA ratio.

Actually, that was to adjust gmax for NMDA and AMPA.  Looking into NMDA and AMPA gmax in the detailed model...

	SynAMPA[-1].gmax = 0.05
	SynNMDA[-1].gmax = 0.005

So Penny uses a NMDA/AMPA ratio of 0.1 for gmax.

Need to set gmax for NMDA and AMPA in network model.

Added to top of netParams:

	## Network variables (move to cfg.py later)
	NMDAgmax        = 0.005
	NMDA2AMPA       = 0.1
	AMPAgmax        = NMDAgmax / NMDA2AMPA
	NMDAweight      = 0.8
	AMPAweight      = NMDAweight

And then below changed to:

	## Excitatory NMDA and AMPA synaptic mechs
	netParams.synMechParams['NMDA'] = {'mod': 'NMDA', 'Cdur': 10.0, 'Beta': 0.02, 'gmax': NMDAgmax}
	netParams.synMechParams['AMPA'] = {'mod': 'AMPA', 'gmax': AMPAgmax}

I think we'll need to test the network implementation of simplified cell model to ensure it behaves like detailed.


** Back to setting up NMDA mech

Previous code:

	netParams.synMechParams['NMDA'] = {'mod': 'NMDAeee', 'Cdur': cfg.CdurNMDAScale * 1.0, 'Alpha': cfg.NMDAAlphaScale * 4.0, 'Beta': cfg.NMDABetaScale * 0.0015, 'gmax': cfg.NMDAgmax, 'e': cfg.eNMDA}

New code:

	netParams.synMechParams['NMDA'] = {'mod': 'NMDA', 'Cdur': 10.0, 'Beta': 0.02, 'gmax': NMDAgmax}


** Setting up inhibitory mechs

The old code actually stays the same:

	## Inhibitory GABA synaptic mechs
	netParams.synMechParams['GABAAfast'] = {'mod':'MyExp2SynBB','tau1': 0.07,'tau2': 18.2,'e': cfg.GABAAfast_e}
	netParams.synMechParams['GABAAslow'] = {'mod': 'MyExp2SynBB','tau1': 10, 'tau2': 200, 'e': cfg.GABAAslow_e}


** Looking into connectivity

Now we need to make sure our connectivity is using the newly swapped in mechs.

Old code in netParams:

	## Cell connectivity rules
	netParams.connParams['PT5->all'] = {
	  'preConds': {'cellType': 'PT5'}, 'postConds': {'y': [100,1000]},  #  E -> all (100-1000 um)
	  'probability': 0.1 ,                  # probability of connection
	  'weight': '0.005*post_ynorm',         # synaptic weight 
	  'delay': 'dist_3D/propVelocity',      # transmission delay (ms) 
	  'synMech': 'exc'}                     # synaptic mechanism 

	netParams.connParams['PV5->PT5'] = {
	  'preConds': {'cellType': 'PV5'}, 'postConds': {'cellType': ['PT5']},       #  I -> E
	  'probability': '0.4*exp(-dist_3D/probLengthConst)',   # probability of connection
	  'weight': 0.001,                                      # synaptic weight 
	  'delay': 'dist_3D/propVelocity',                      # transmission delay (ms) 
	  'synMech': 'inh'}     

New code:

	## Cell connectivity rules
	netParams.connParams['PT5->all'] = {
	  'preConds': {'cellType': 'PT5'},
	  'postConds': {'cellType': ['PT5','PV5']},
	  'probability': 0.1,
	  'weight': [NMDAweight, AMPAweight],
	  'delay': 'dist_3D/propVelocity',
	  'synMech': 'ESynMech'}

	netParams.connParams['PV5->all'] = {
	  'preConds': {'cellType': 'PV5'},
	  'postConds': {'cellType': ['PT5', 'PV5']},
	  'probability': 0.1,
	  'weight': [GABAAfastWeight, GABAAslowWeight],
	  'delay': 'dist_3D/propVelocity',
	  'synMech': 'ISynMech'} 

Now need to set weights for GABAA fast and slow.

Looking into how the old network model did it.

Hmmm.  Interesting.  So the connectivity is such that for inh to exc, both GABA fast and slow are used.  For inh to inh, only GABA fast is used.

Old code:

	#     #inh to exc 
	#     for prePop in inhL5:
	#         for postPop in excL5:
	#             ruleLabel = prePop+'->'+postPop
	#             netParams.connParams[ruleLabel] = {
	#                 'preConds': {'pop': prePop},
	#                 'postConds': {'pop': postPop},
	#                 'synMech': ISynMech, 
	#                 'weight': 0.001*cfg.IEgain, 
	#                 'synMechWeightFactor': [0.7,0.3],
	#                 'delay': 'defaultDelay+dist_3D/propVelocity',
	#                 'convergence': 4,
	#                 'loc': 0.5,
	#                 'sec': 'soma_2'}
	  
	#     #inh to inh
	#     for prePop in inhL5:
	#         for postPop in inhL5:
	#             ruleLabel = prePop+'->'+postPop
	#             netParams.connParams[ruleLabel] = {
	#                 'preConds': {'pop': prePop},
	#                 'postConds': {'pop': postPop},
	#                 'synMech': 'GABAAfast',
	#                 'weight': 0.002*cfg.IIgain, 
	#                 'delay': cfg.IIdelay, #'defaultDelay+dist_3D/propVelocity',
	#                 'convergence': cfg.IIconv,
	#                 'loc': 0.5,
	#                 'sec': 'soma'}

Where:

	cfg.IEgain = 0.1 #10.0 #0.5    #PV to Exc 
	cfg.IIgain = 0.1 #1.0 #1.0 # PV to PV

So, the weight for I->E = 0.001*cfg.IEgain = 0.001*0.1 = 0.0001

The weight is the same for GABA fast and slow.

And the weight for I->I = 0.002*cfg.IIgain = 0.002*0.1 = 0.0002

Which is the weight for just GABA fast, as that is all that's used.

I'm going to set up the new connectivity in the same way and also ask about it in Slack.


** Setting up connectivity

New code:

	## Cell connectivity rules
	netParams.connParams['PT5->all'] = {
	  'preConds': {'cellType': 'PT5'},
	  'postConds': {'cellType': ['PT5','PV5']},
	  'probability': 0.1,
	  'weight': [NMDAweight, AMPAweight],
	  'delay': 'dist_3D/propVelocity',
	  'synMech': 'ESynMech'}

	netParams.connParams['PV5->PT5'] = {
	  'preConds': {'cellType': 'PV5'},
	  'postConds': {'cellType': 'PT5'},
	  'probability': 0.1,
	  'weight': [GABAAfastWeight, GABAAslowWeight],
	  'delay': 'dist_3D/propVelocity',
	  'synMech': 'ISynMech'} 

	netParams.connParams['PV5->PV5'] = {
	  'preConds': {'cellType': 'PV5'},
	  'postConds': {'cellType': 'PV5'},
	  'probability': 0.5,
	  'weight': GABAAfastWeight,
	  'delay': 'dist_3D/propVelocity',
	  'synMech': 'GABAAfast'} 

Okay, enough changing.  Time to make it run.

Committing first.

** Running the sim


* 2019-01-28 -- Synaptic mechs and connectivity 

In progress
-----------
Setting up network model
Set up synaptic mechanisms
Set initial connectivity to Sergio's settings


** Running the sim to see what's broken

Trial run:

	graham$ cd ~/EEE_network/eee_net ; ./runsim
	...
	Warning: Could not load netParams from command line path or from default netParams.py
	...

No dice.  Probably a problem in netParams.py

	graham-mac:EEE_network graham$ cd ~/EEE_network/eee_net
	graham-mac:eee_net graham$ ipython -i netParams.py
	Python 3.7.1 (default, Dec 14 2018, 13:28:58) 
	Type 'copyright', 'credits' or 'license' for more information
	IPython 7.2.0 -- An enhanced Interactive Python. Type '?' for help.
	Balancing each compartment to -73 mV
	---------------------------------------------------------------------------
	NameError                                 Traceback (most recent call last)
	~/EEE_network/eee_net/netParams.py in <module>
	     63 
	     64 ## Inhibitory GABA synaptic mechs
	---> 65 netParams.synMechParams['GABAAfast'] = {'mod':'MyExp2SynBB','tau1': 0.07,'tau2': 18.2,'e': cfg.GABAAfast_e}
	     66 netParams.synMechParams['GABAAslow'] = {'mod': 'MyExp2SynBB','tau1': 10, 'tau2': 200, 'e': cfg.GABAAslow_e}
	     67 

	NameError: name 'cfg' is not defined

Or perhaps a problem in cfg.py.  Nope.  cfg.py runs without crashing.

Adding the following to the top of netParams.py (it was in the old netParams):

	try:
	    from __main__ import cfg
	except:
	    from cfg import cfg

And executing netParams:

	AttributeError                            Traceback (most recent call last)
	~/EEE_network/eee_net/netParams.py in <module>
	     67 
	     68 ## Inhibitory GABA synaptic mechs
	---> 69 netParams.synMechParams['GABAAfast'] = {'mod':'MyExp2SynBB','tau1': 0.07,'tau2': 18.2,'e': cfg.GABAAfast_e}
	     70 netParams.synMechParams['GABAAslow'] = {'mod': 'MyExp2SynBB','tau1': 10, 'tau2': 200, 'e': cfg.GABAAslow_e}
	     71 

	AttributeError: 'SimConfig' object has no attribute 'GABAAfast_e'

Will add "cfg." in front of all variables, will later move these to cfg.py.

Okay, netParams.py runs now.

Now to try a whole sim.

Getting an error:

	graham$ cd ~/EEE_network/eee_net ; ipython -i init.py
	Python 3.7.1 (default, Dec 14 2018, 13:28:58) 
	Type 'copyright', 'credits' or 'license' for more information
	IPython 7.2.0 -- An enhanced Interactive Python. Type '?' for help.
	Note: NeuroML import failed; import/export functions for NeuroML will not be available. 
	  To install the pyNeuroML & libNeuroML Python packages visit: https://www.neuroml.org/getneuroml
	Balancing each compartment to -73 mV

	Creating network of 5 cell populations on 1 hosts...
	  Number of cells on node 0: 100 
	  Done; cell creation time = 0.30 s.
	Making connections...
	---------------------------------------------------------------------------
	TypeError                                 Traceback (most recent call last)
	~/EEE_network/eee_net/init.py in <module>
	     22 sim.net.createPops()                        # instantiate network populations
	     23 sim.net.createCells()                       # instantiate network cells based on defined populations
	---> 24 sim.net.connectCells()                      # create connections between cells based on params
	     25 sim.net.addStims()                          # add network stimulation
	     26 sim.setupRecording()                       # setup variables to record for each cell (spikes, V traces, etc)

	~/Applications/netpyne/netpyne/network/conn.py in connectCells(self)
	     76                                 sim.cfg.seeds['conn'])
	     77             self._connStrToFunc(preCellsTags, postCellsTags, connParam)  # convert strings to functions (for the delay, and probability params)
	---> 78             connFunc(preCellsTags, postCellsTags, connParam)  # call specific conn function
	     79 
	     80         # check if gap junctions in any of the conn rules

	~/Applications/netpyne/netpyne/network/conn.py in probConn(self, preCellsTags, postCellsTags, connParam)
	    402                                 connParam[paramStrFunc + 'Args'][funcKey] = connParam[paramStrFunc + 'Vars'][funcKey](preCellTags, postCellTags)
	    403                             # connParam[paramStrFunc+'Args'] = {k:v if isinstance(v, Number) else v(preCellTags,postCellTags) for k,v in connParam[paramStrFunc+'Vars'].items()}
	--> 404                         self._addCellConn(connParam, preCellGid, postCellGid) # add connection
	    405 
	    406 

	~/Applications/netpyne/netpyne/network/conn.py in _addCellConn(self, connParam, preCellGid, postCellGid)
	    610         if sim.cfg.includeParamsLabel: params['label'] = connParam.get('label')
	    611 
	--> 612         postCell.addConn(params=params)
	    613 
	    614 

	~/Applications/netpyne/netpyne/cell/compartCell.py in addConn(self, params, netStimParams)
	    740                     else:
	    741                         sec = self.secs[synMechSecs[i]]
	--> 742                         postTarget = synMechs[i]['hObj'] # local synaptic mechanism
	    743 
	    744                     if netStimParams:

	TypeError: 'NoneType' object is not subscriptable

So the crash occurs during `sim.net.connectCells()`, which implies a problem with connectivity.

It seems like `synMechs` is undefined, and thus not subscriptable.  Looking into this.

In the connectivity section of netParams, I had this:
	'synMech': 'ESynMech'

But I think it should be this:
	'synMech': ESynMech

Same for ISynMech.

Same error.

For the background input, I have the following:
	
	netParams.stimTargetParams['bkg->all'] = {'source': 'bkg', 'conds': {'cellType': ['PV5','PT5']}, 'weight': 0.01, 'delay': 'max(1, normal(5,2))', 'synMech': 'exc'}

But I realize I no longer have a synMech named 'exc'...  Looking into what 'exc' used to be...

From the Netpyne tutorial (http://netpyne.org/tutorial.html):

	netParams.synMechParams['exc'] = {'mod': 'Exp2Syn', 'tau1': 0.8, 'tau2': 5.3, 'e': 0}  # NMDA synaptic mechanism

Based on the comment, it's supposed to be an NMDA model, so I suppose I could use the NMDA.mod, but I'm just going to keep it the same for now.

It runs and produces figures.  :)

But the connectivity is a little wonky:
file:nb_gif/20190128_102730.png

Both `PV5` and `bkg` seem to have no connectivity.

Committing, pushing, and then looking into this.


** Fixing connectivity

Earlier I had increased the connection probability from 0.1 to 0.5, gonna try changing that back and seeing what happens.

Still missing connectivity, but the plots look much better.

Instead of lumping synMechs into excitatory and inhibitory:

	## Synaptic mechanism parameters
	ESynMech = ['NMDA','AMPA']
	ISynMech = ['GABAAfast','GABAAslow']

I'll set each connection type up separately.

	NMDA
	AMPA
	GABAAFast
	GABAASlow
	bkg


* 2019-01-29 -- EEE meeting and connectivity 

In progress
-----------
Setting up network model
Fixing connectivity


** EEE Meeting

https://docs.google.com/document/d/16vmQn6gmJzhUXq48PAuTd9uzx5keSdxT0qSn3yWfC9g/edit

Get connectivity fixed and then start setting up batch sims.


** Connectivity

Salva was looking into the problem.

	salvadord [9:17 AM]
	so all the conns are actually there!

	billl [9:18 AM]
	that's the good news

	salvadord [9:18 AM]
	for the PV5 if you plot eg. the probability instead of the strength you can see them
	strength=prob*weight

	billl [9:18 AM]
	maybe the strength == 0?

	salvadord [9:18 AM]
	so seems like PV5 weights are much lower
	just lower by several O - 0.0001 vs 0.8

	billl [9:19 AM]
	goose 'em joe

	salvadord [9:19 AM]
	and the bkg also there but since implemented as a stimSourceParam/stimTargetParam (it’s a NetStim) the conn matrix calculation doesnt really apply
	there’s one netstim per cell

	joe [9:20 AM]
	Awesome, thanks Salva!

	salvadord [9:20 AM]
	np!

	you can plot without bkg using `sim.analysis.plotConn(includePre=['allCells'], includePost=['allCells'], feature='probability')` — and can replace `probability` with `strength`, `weight` or `numConns`


** Preparing for batch sims

Ugh, sick as a dog.  This will have to wait.


* 2019-01-30 -- Reading journal club article

Cortical column and whole-brain
imaging with molecular contrast
and nanoscale resolution

https://paperpile.com/view/3070709c-e7e3-0e02-ad60-cf7cb111d3a4

Journal club was moved to Monday Feb 11th, 12pm EST.


* 2019-02-05 -- EEE meeting and connectivity 

In progress
-----------
Setting up network model
Fixing connectivity
Setting up batch sims


** Connectivity

So the connectivity actually works, some of it is just at very low values.

Best way to explore connectivity is using batch sims.

In order to start using batch sims, first I need to get all cfg.values into the cfg.py file.

Doing that now.


** Config file

First I just want to see what all default variables are in a cfg structure:

	graham-mac:EEE_network graham$ ipython
	Python 3.7.1 (default, Dec 14 2018, 13:28:58) 
	Type 'copyright', 'credits' or 'license' for more information
	IPython 7.2.0 -- An enhanced Interactive Python. Type '?' for help.

	In [1]: from netpyne import specs                                                                                         

	In [2]: cfg = specs.SimConfig()                                                                                           

	In [3]: cfg                                                                                                               
	Out[3]: <netpyne.specs.simConfig.SimConfig at 0x10a81c198>

	In [4]: cfgd = cfg.todict()                                                                                               
	Note: NeuroML import failed; import/export functions for NeuroML will not be available. 
	  To install the pyNeuroML & libNeuroML Python packages visit: https://www.neuroml.org/getneuroml

	In [5]: cfgd                                                                                                              
	Out[5]: 
	{'duration': 1000.0,
	 'tstop': 1000.0,
	 'dt': 0.025,
	 'hParams': {'celsius': 6.3, 'v_init': -65.0, 'clamp_resist': 0.001},
	 'cache_efficient': False,
	 'cvode_active': False,
	 'cvode_atol': 0.001,
	 'seeds': {'conn': 1, 'stim': 1, 'loc': 1},
	 'rand123GlobalIndex': None,
	 'createNEURONObj': True,
	 'createPyStruct': True,
	 'addSynMechs': True,
	 'includeParamsLabel': True,
	 'gatherOnlySimData': False,
	 'compactConnFormat': False,
	 'connRandomSecFromList': True,
	 'saveCellSecs': True,
	 'saveCellConns': True,
	 'timing': True,
	 'saveTiming': False,
	 'printRunTime': False,
	 'printPopAvgRates': False,
	 'printSynsAfterRule': False,
	 'verbose': False,
	 'recordCells': [],
	 'recordTraces': {},
	 'recordCellsSpikes': -1,
	 'recordStim': False,
	 'recordLFP': [],
	 'saveLFPCells': False,
	 'recordStep': 0.1,
	 'recordTime': True,
	 'simLabel': '',
	 'saveFolder': '',
	 'filename': 'model_output',
	 'saveDataInclude': ['netParams',
	  'netCells',
	  'netPops',
	  'simConfig',
	  'simData'],
	 'timestampFilename': False,
	 'savePickle': False,
	 'saveJson': False,
	 'saveMat': False,
	 'saveCSV': False,
	 'saveDpk': False,
	 'saveHDF5': False,
	 'saveDat': False,
	 'backupCfgFile': [],
	 'checkErrors': False,
	 'checkErrorsVerbose': False,
	 'analysis': OrderedDict()}

Now moving cfg variables from netParams.py to cfg.py.

And now trying to run.

It still works.  Cleaning up and committing.


** Setting up batch sims

http://netpyne.org/tutorial.html#running-batch-simulations-tutorial-8

	We will also need to add a new file to control the batch simulation:

	tut8_batch.py : Defines the parameters and parameter values to be explored in a batch of simulations, the run configuration – e.g. whether to use MPI+Bulletin Board (for multicore machines) or SLURM/PBS Torque (for HPCs) –, and the command to run the batch.

	In summary, netParams.py for fixed (network) parameters, cfg.py for variable (simulation) parameters, init.py to run a simulation, and batch.py to run a batch of simulations exploring combinations of parameter values.

Here's the code in tut8_batch.py:

	from netpyne import specs
	from netpyne.batch import Batch 

	def batchTauWeight():
		# Create variable of type ordered dictionary (NetPyNE's customized version) 
		params = specs.ODict()   

		# fill in with parameters to explore and range of values (key has to coincide with a variable in simConfig) 
		params['synMechTau2'] = [3.0, 5.0, 7.0]   
		params['connWeight'] = [0.005, 0.01, 0.15]

		# create Batch object with paramaters to modify, and specifying files to use
		b = Batch(params=params, cfgFile='tut8_cfg.py', netParamsFile='tut8_netParams.py')
		
		# Set output folder, grid method (all param combinations), and run configuration
		b.batchLabel = 'tauWeight'
		b.saveFolder = 'tut8_data'
		b.method = 'grid'
		b.runCfg = {'type': 'mpi_bulletin', 
					'script': 'tut8_init.py', 
					'skip': True}

		# Run batch simulations
		b.run()

	# Main code
	if __name__ == '__main__':
		batchTauWeight() 

Adding batch.py to the repo with that code.

** Running a test batch

Modified the original batch code example to:

	from netpyne import specs
	from netpyne.batch import Batch 

	def batchTest():
		# Create variable of type ordered dictionary (NetPyNE's customized version) 
		params = specs.ODict()   

		# fill in with parameters to explore and range of values (key has to coincide with a variable in simConfig) 
		params['GABAAfastWeight'] = [0.0001, 0.001, 0.01]   
		params['GABAAslowWeight'] = [0.0001, 0.001, 0.01]

		# create Batch object with paramaters to modify, and specifying files to use
		b = Batch(params=params, cfgFile='cfg.py', netParamsFile='netParams.py')
		
		# Set output folder, grid method (all param combinations), and run configuration
		b.batchLabel = 'batch_test'
		b.saveFolder = 'batch_data'
		b.method = 'grid'
		b.runCfg = {'type': 'mpi_bulletin', 
					'script': 'init.py', 
					'skip': True}

		# Run batch simulations
		b.run()

	# Main code
	if __name__ == '__main__':
		batchTest() 

So now, here's the command to run the batch sims:

	To run the batch simulations you will need to have MPI properly installed and NEURON configured to use MPI. Run the following command: mpiexec -np [num_cores] nrniv -python -mpi batch.py , where [num_cores] should be replaced with the number of processors you want to use. The minimum required is 2, since one will be uses to schedule the jobs (master node); e.g. if you select 4 processors, one will be used to schedule jobs, and the other 3 will run NEURON simulations with different parameter combinations.

I will make a new file called `runbatch` using `runsim` as a start.

runsim:

	#!/bin/bash
	# Runs simulation, including MPI.

	numprocesses=$1; if [ -z $numprocesses ]; then numprocesses=4; fi # Number of processes to use
	shift # Eliminate first argument

	mpiexec -np $numprocesses nrniv -python -mpi init.py $@  # Run the model

runbatch:

	#!/bin/bash
	# Runs batch simulations, including MPI.

	numprocesses=$1; if [ -z $numprocesses ]; then numprocesses=4; fi # Number of processes to use
	shift # Eliminate first argument

	mpiexec -np $numprocesses nrniv -python -mpi batch.py $@  # Run the batch sims

Trying it now.

	graham$ cd ~/EEE_network/eee_net ; ./runbatch

It seems to be working.

Well, it went through three sims so far, but now seems to have hung.

I'm going to set up a batch that only changes one variable and see how that does.

	params['GABAAfastWeight'] = [0.0001, 0.01, 1.0]   
	#params['GABAAslowWeight'] = [0.0001, 0.001, 0.01]

graham$ cd ~/EEE_network/eee_net ; ./runbatch

That produced three sims and expected figures (now inhib connectivity is visible in the connection strength matrix):

file:nb_gif/20190205_083659.png

The terminal never returned to the command prompt, but I suppose that's okay.

Committing and pushing now.


* 2019-02-11 -- Journal club and connectivity 

** Need to swap in the old connectivity probabilities

I think there are too many connections when I scale up from 80/20 (exc/inh) to 800/200

Trying to run a big one overnight, and we'll see.

It worked but a lot of it seems a little odd.  Details and figures are in the meeting notes.


* 2019-02-12 -- EEE Meeting and Article Revision

Meeting agenda and notes:
https://docs.google.com/document/d/1B7ql4aKGjfABxtbjWdRmSlpHuRSmoCncVEluCdkl7i8/edit


* 2019-02-13 -- Article revision


* 2019-02-14 -- Fixing connectivity

** E --> E connectivity

The last version of our old network, as I recall, didn't have the weird problems I'm seeing now.

Looking at the old connectivity code for E->E:

	excPopLabels = ['PT5_1', 'PT5_2', 'PT5_3', 'PT5_4']
	excL5 = excPopLabels

    # (Exc) to  Exc L5
    for prePop in excL5:
        for postPop in excL5:
            ruleLabel = prePop+'->'+postPop
            netParams.connParams[ruleLabel] = {
                'preConds': {'pop': prePop},
                'postConds': {'pop': postPop},
                'synMech': ESynMech, 
                'weight': 1.0*cfg.EEgain, 
                'synMechWeightFactor': cfg.ratiobdend,
                'delay': 'defaultDelay+dist_3D/propVelocity',
                'convergence': cfg.EEconv,#5,#3,
                'loc': 0.3,
                'sec': 'basal_8'}

Where:
	
	ESynMech = ['AMPA','NMDA']

	cfg.EEgain = 1.0
	cfg.ratiobdend = [0.666,0.334]
	cfg.EEconv = 3.0

	netParams.defaultDelay = 2.0 # default conn delay (ms)
	netParams.propVelocity = 100.0 # propagation velocity (um/ms)

By using a for loop, we create a cell rule for each individual pop to each other pop, 
which can then be modified individually later.  This seems like a better way to set 
this up than the simpler tutorial version.

I'm not totally sure what 

	'synMechWeightFactor': cfg.ratiobdend

does (and not currently documented in Netpyne), but I'm guessing it just scales 
the one weight given for each of the two mechs.  So, AMPA weight would be scaled
by 0.666 and NMDA by 0.334.  This would then indicate an AMPA/NMDA ratio of 2.0

But, the old and new code already takes care of the ratio by scaling gmax of AMPA 
and NMDA.  So I think I'll leave out synMechWeightFactor.

I am going to switch my code from being NMDA then AMPA to AMPA then NMDA, in order to match
with the old code and because it seems more common to say AMPA/NMDA ratio in the literature
than vice-versa.

And actually, I realize I should Check Penny's code to see what she sets NMDA and AMPA gmaxes
to, because that is what we should use.

	https://github.com/super-penguin/EEE_Detailed_Cell/blob/master/Fig3_exp_dms.py

	SynAMPA[-1].gmax = 0.05
	SynNMDA[-1].gmax = 0.005

Currently, network model has:

	cfg.NMDAgmax        = 0.005
	cfg.AMPANMDAratio   = 10.0
	cfg.AMPAgmax        = cfg.AMPANMDAratio * cfg.NMDAgmax

Which works out to the same thing. So we're good.

Trying to run sim, then will commit.

Still runs.  Committing now.

New E->E code:

	EPops = ['PT5_1', 'PT5_2', 'PT5_3', 'PT5_4']

	for prePop in EPops:
	    for postPop in EPops:
	        ruleLabel = prePop+'->'+postPop
	        netParams.connParams[ruleLabel] = {
	            'preConds': {'pop': prePop},
	            'postConds': {'pop': postPop},
	            'synMech': ESynMech, 
	            'weight': [cfg.AMPAweight, cfg.NMDAweight], #1.0*cfg.EEgain, 
	            'delay': 'defaultDelay+dist_3D/propVelocity',
	            'convergence': cfg.EEconv,#5,#3,
	            'loc': 0.3,
	            'sec': 'basal_8'}

Running sim.

	graham$ cd ~/EEE_network/eee_net ; rm *.png ; ./runsim

Something's not working.  Looking into it.

	graham-mac:eee_net graham$ python cfg.py
	graham-mac:eee_net graham$ python netParams.py
	Balancing each compartment to -73 mV
	Traceback (most recent call last):
	  File "netParams.py", line 86, in <module>
	    'convergence': cfg.EEconv,#5,#3,
	AttributeError: 'SimConfig' object has no attribute 'EEconv'

Forgot to add cfg.EEconv to cfg.py

It runs now.  Committing.

** E --> I connectivity

Old code:

    #exc to inh
    for prePop in excL5:
        for postPop in inhL5:
            ruleLabel = prePop+'->'+postPop
            netParams.connParams[ruleLabel] = {
                'preConds': {'pop': prePop},
                'postConds': {'pop': postPop},
                'synMech': 'AMPA',
                'weight': 2.0*cfg.EIgain, 
                'delay': 'defaultDelay+dist_3D/propVelocity',
                'convergence': 3,
                'loc': 0.5,
                'sec': 'soma'}

Adding cfg.EIconv to cfg.py

New code:

	for prePop in EPops:
	    for postPop in ['PV5']:
	        ruleLabel = prePop+'->'+postPop
	        netParams.connParams[ruleLabel] = {
	            'preConds': {'pop': prePop},
	            'postConds': {'pop': postPop},
	            'synMech': 'AMPA',
	            'weight': cfg.AMPAweight, 
	            'delay': 'defaultDelay+dist_3D/propVelocity',
	            'convergence': cfg.EIconv,
	            'loc': 0.5,
	            'sec': 'soma'}

Running sim.

	graham$ cd ~/EEE_network/eee_net ; rm *.png ; ./runsim

It runs.  Committing.

** I --> E connectivity

Old code:

     #inh to exc 
     for prePop in inhL5:
         for postPop in excL5:
             ruleLabel = prePop+'->'+postPop
             netParams.connParams[ruleLabel] = {
                 'preConds': {'pop': prePop},
                 'postConds': {'pop': postPop},
                 'synMech': ISynMech, 
                 'weight': 0.001*cfg.IEgain, 
                 'synMechWeightFactor': [0.7,0.3],
                 'delay': 'defaultDelay+dist_3D/propVelocity',
                 'convergence': 4,
                 'loc': 0.5,
                 'sec': 'soma_2'}

Adding cfg.IEconv = 4.0 to cfg.py

cfg.IEgain = 0.1 in the old code, so the weight would be 0.001 * 0.1 = 0.0001

That would be the weight for both GABAfast and GABAslow.

GABAfast weight was set to 0.0002 in the old model.

Note: I->E uses both fast and slow.  I->I only uses fast.

I am going to create individual fast and slow weights in cfg.py:

	cfg.GABAAfastWeight = 0.0001
	cfg.GABAAslowWeight = 0.0001

New code:

	# Inhibitory --> Excitatory

	for prePop in ['PV5']:
	    for postPop in Epops:
	        ruleLabel = prePop+'->'+postPop
	        netParams.connParams[ruleLabel] = {
	            'preConds': {'pop': prePop},
	            'postConds': {'pop': postPop},
	            'synMech': ISynMech, 
	            'weight': [cfg.GABAAfastWeight.cfg.GABAAslowWeight],
	            'delay': 'defaultDelay+dist_3D/propVelocity',
	            'convergence': cfg.IEconv,
	            'loc': 0.5,
	            'sec': 'soma'}

Running sim.  Didn't work.  Looking into.

	Traceback (most recent call last):
	  File "netParams.py", line 108, in <module>
	    for postPop in Epops:
	NameError: name 'Epops' is not defined

Had to capitalize the 'p'

	Traceback (most recent call last):
	  File "netParams.py", line 114, in <module>
	    'weight': [cfg.GABAAfastWeight.cfg.GABAAslowWeight],
	AttributeError: 'float' object has no attribute 'cfg'

New code that works:

	# Inhibitory --> Excitatory

	for prePop in ['PV5']:
	    for postPop in EPops:
	        ruleLabel = prePop+'->'+postPop
	        netParams.connParams[ruleLabel] = {
	            'preConds': {'pop': prePop},
	            'postConds': {'pop': postPop},
	            'synMech': ISynMech, 
	            'weight': [cfg.GABAAfastWeight, cfg.GABAAslowWeight],
	            'delay': 'defaultDelay+dist_3D/propVelocity',
	            'convergence': cfg.IEconv,
	            'loc': 0.5,
	            'sec': 'soma'}

Committing.


** I --> I connectivity

Old code:

    #inh to inh
    for prePop in inhL5:
        for postPop in inhL5:
            ruleLabel = prePop+'->'+postPop
            netParams.connParams[ruleLabel] = {
                'preConds': {'pop': prePop},
                'postConds': {'pop': postPop},
                'synMech': 'GABAAfast',
                'weight': 0.002*cfg.IIgain, 
                'delay': cfg.IIdelay, #'defaultDelay+dist_3D/propVelocity',
                'convergence': cfg.IIconv,
                'loc': 0.5,
                'sec': 'soma'}

Adding cfg.IIconv = 12.0 to config file

New code:

	# Inhibitory --> Inhibitory

	for prePop in ['PV5']:
	    for postPop in ['PV5']:
	        ruleLabel = prePop+'->'+postPop
	        netParams.connParams[ruleLabel] = {
	            'preConds': {'pop': prePop},
	            'postConds': {'pop': postPop},
	            'synMech': 'GABAAfast',
	            'weight': cfg.GABAAfastWeight, 
	            'delay': 'defaultDelay+dist_3D/propVelocity',
	            'convergence': cfg.IIconv,
	            'loc': 0.5,
	            'sec': 'soma'}

It works.  Committing.

** Running a big simulation

800 exc, 200 inh

Interesting results.  Looking into how to turn them into a pdf that can be referenced from here.

		b.runCfg = {'type': 'hpc_slurm', 
		    'allocation': 'shs100', # bridges='ib4iflp', comet m1='shs100', comet nsg='csd403'
		    #'reservation': 'salva1',
		    'walltime': '2:00:00',
		    'nodes': 5,
		    'coresPerNode': 24,  # comet=24, bridges=28
		    'email': 'salvadordura@gmail.com',
		    'folder': '/home/salvadord/m1/sim/',  # comet='/salvadord', bridges='/salvi82'
		    'script': 'init.py', 
		    'mpiCommand': 'ibrun', # comet='ibrun', bridges='mpirun'
		    'skip': True}


* 2019-02-15 -- Code review and HPC intro

Notes from meeting:
https://docs.google.com/document/d/1pj7cdq8XcPIaCNWD6nMM5fostTbtoXujyku6Y5ryZLQ/edit

EEE Theory Code Review -- 2018-02-15

Google Hangout URL: https://hangouts.google.com/call/UFV-belsSHz1VJv5J4ozAAEE 

Code repo: https://github.com/Neurosim-lab/EEE_network

Old code is in eee_network
New code is in eee_net

Agenda

Code review
HPC tutorial

Discussion

Fitting
Set known variables
Then explore lesser known ones programmatically
Salva: I play with E->E, E->I, I->E, I->I relative gains
Gain variable in front of weights
Conn prob is fairly well constrained
Gains: 0.8, 1.0, 1.2, e.g.
Can be global or define by layer
Evolutionary
Perhaps not ideal right now
Should look into
Code review
Run individual sim: ./runsim
Uses MPI to run init.py
Run batch sims: ./runbatch
Uses MPI to run batch.py
Connectivity
Probability: 
can be distance dependent
Convergence: 
random throughout pops
Divergence
How to do connectivity
Can have distance dependent weights
Salva not sure need we need to complexify now
This is more proof of concept
Don’t worry too much about details here: already so simplified
Find interesting things here, then explore in more realistic model
Steps upcoming
Get model output looking realistic
Need inputs to apical dendrites
These will be modeled as external inputs to network
Three conditions:
Standby: no plateaus
Prepared: just plateaus
Active: plateaus plus apical inputs
Active should show more synchrony
Input induced plateaus into a E pop
See how plateaus affect network behavior
Looking for synchrony


Get plateaus to emerge from network

Getting into HPC with Subha
Don adds Joe as user
Google search: SDSC comet
Get your own space 
SSH into comet.sdsc.edu (using your own user name)
ssh <your_username>@comet.sdsc.edu
ssh -l <your_username> comet.sdsc.edu 
Login node does not run jobs, but can explore files, etc.
Set up public-private keys
Directions:
Modules
module list 
Can do pip install package-name --user
Can check out different branches
Set up Python paths
Queues
Different types (debug, etc.)
Compute queue is for exclusive access
Debug for quick stuff, highly limited


Each node has 48 cores
Basic MPI job example
#!/bin/bash
#SBATCH --job-name="hellompi"
#SBATCH --output="hellompi.%j.%N.out"
#SBATCH --partition=compute
#SBATCH --nodes=2
#SBATCH --ntasks-per-node=24
#SBATCH --export=ALL
#SBATCH -t 01:30:00
The partition is the queue you want to use
-t is an estimate of time required for job
Always ask for more time than you think you’ll need
Scheduler will kill job after time 
Longer times require longer waits in the queue
Best to overestimate
ibrun is unique to Comet, makes it more efficient
Command ‘man’ gives info about things
Can also specify email address and other options
Netpyne can handle HPC configurations for Comet
example Comet batch.py (in netpyne)
Log into Comet, and run `python batch.py`

b.runCfg = {'type': 'hpc_slurm', 
    'allocation': 'shs100', # bridges='ib4iflp', comet m1='shs100', comet nsg='csd403'
    #'reservation': 'salva1',
    'walltime': '2:00:00',
    'nodes': 5,
    'coresPerNode': 24,  # comet=24, bridges=28
    'email': 'salvadordura@gmail.com',
    'folder': '/home/salvadord/m1/sim/',  # comet='/salvadord', bridges='/salvi82'
    'script': 'init.py', 
    'mpiCommand': 'ibrun', # comet='ibrun', bridges='mpirun'
    'skip': True}

Tip: start with smaller sims, then increase as you know they work
See Job Monitoring and Management to see how your sim is going
If you submit a bad job, can use scancel
Once job is running, you have access into that node
There is a command to show job characteristics
Shows which computer node your job is running
Then can SSH into that node from login
Then use command `top` to see memory usage



* 2019-02-20 -- OCNC 2019 application reviewing

OIST Computational Neuroscience Course
Reviewing student applications


* 2019-02-21 -- OCNC 2019 application reviewing

OIST Computational Neuroscience Course
Reviewing student applications


* 2019-02-26 -- EEE Meeting and plateau induction

** Matching up parameter values with old network model

I see the old network model had slightly different dimensions:

	cfg.sizeY = 1600
	cfg.sizeX = 400
	cfg.sizeZ = 300

Our current:

	netParams.sizeX = 100 # x-dimension (horizontal length) size in um
	netParams.sizeY = 1000 # y-dimension (vertical height or cortical depth) size in um
	netParams.sizeZ = 100 # z-dimension (horizontal length) size in um

I'll move these params to cfg and set them to the old values.


** Plotting raster arranged by cell gid

I'd like to see the raster with cells arranged by y-position (current setting), but would 
also like to see raster plot with cells arranged by gid (separated by pop type)

Adding this to cfg.py:
	
	cfg.analysis['plotRaster'] = {'orderBy': 'gid', 'orderInverse': True,'saveFig': saveFig, 'labels':'overlay','showFig': showFig}

That worked, but now I no longer get the raster by y-pos.  I'll have to ask Salva how to 
plot more than one raster.


** Looking into odd PT5 cell traces

Traces still look odd:  
file:nb_gif/20190226_061931.png

I'm going to turn off all connectivity to PT cells and see results.

Committing first.

First step, I'll turn off the noise.

Okay, without the noise there is no spiking in any cell pop.

PT5 sits at resting membrane potential RMP of about -69
PV5 sits at resting membrane potential RMP of about -71

Will have to look into appropriate RMPs.

Turning noise on but all other connectivity off.

	cfg.NMDAweight      = 0 #0.8
	cfg.AMPAweight      = 0 #cfg.NMDAweight
	cfg.GABAAfastWeight = 0 #0.0001
	cfg.GABAAslowWeight = 0 #0.0001 

Okay, now the traces look funky again:
file:nb_gif/20190226_063630.png

Ahhh, I am using a different (simpler) noise than we used in the old network
(simple Exp2Syn instead of Gfluctp)

Will switch to using Gfluctp now.

** Switching PT5 noise to Gfluctp

Original code:

	if cfg.noisePT5:
	    netParams.cellParams['PT5_1']['secs']['soma']['pointps'] = {
                        'noise': {'mod': 'Gfluctp', 
                        'loc': 0.5,
                        'std_e': 0.012 * cfg.exc_noise_amp,
                        'g_e0' : 0.0121, 
                        'tau_i': 10.49 * cfg.noise_tau, 
                        'tau_e': 2.728 * cfg.noise_tau, 
                        'std_i': 0.0264 * cfg.inh_noise_amp, 
                        'g_i0' : 0.0573, 
                        'E_e'  : cfg.e_exc_noise, 
                        'E_i'  : cfg.e_inh_noise, 
                        'seed1': 'gid', 
                        'seed2': sim.id32('gfluctp'), 
                        'seed3': cfg.seeds['stim']}}

Need to add all the variable params to cfg.py.

Adding seeds:

	cfg.seeds = {'conn': 4123,
			 'stim': 1234, 
			 'loc' : 3214}  

Here are the default values from Gfluctp.mod:

	  E_e	= 0 	(mV)	: reversal potential of excitatory conductance
	  E_i	= -75 	(mV)	: reversal potential of inhibitory conductance

	  g_e0	= 0.0121 (umho)	: average excitatory conductance
	  g_i0	= 0.0573 (umho)	: average inhibitory conductance

	  std_e	= 0.0030 (umho)	: standard dev of excitatory conductance
	  std_i	= 0.0066 (umho)	: standard dev of inhibitory conductance

	  tau_e	= 2.728	(ms)	: time constant of excitatory conductance
	  tau_i	= 10.49	(ms)	: time constant of inhibitory conductance

I think the noise amplitude is set wrong in old model...

Instead of 

	'std_e': 0.012 * cfg.exc_noise_amp
	'g_e0' : 0.0121, 

I think it should be
	
	'std_e': 0.012
	'g_e0' : 0.0121 * cfg.exc_noise_amp

Because g is the conductance, which determines amplitude. std is the variability of the 
conductance

Making this change.

Error:

	graham$ python netParams.py
	Balancing each compartment to -73 mV
	Traceback (most recent call last):
	  File "netParams.py", line 87, in <module>
	    'seed2': sim.id32('gfluctp'), 
	NameError: name 'sim' is not defined

Looks like the previous netParams.py had this:

	from netpyne import sim

Adding that and trying again.

Error:

	graham$ python netParams.py
	Balancing each compartment to -73 mV
	Traceback (most recent call last):
	  File "netParams.py", line 88, in <module>
	    'seed2': sim.id32('gfluctp'), 
	AttributeError: module 'netpyne.sim' has no attribute 'id32'

Searching around, I see:

	id32() provides a 32-bit hash for a name: def id32(obj):return hash(obj)&0xffffffff

From an article from our lab:

	https://bmcneurosci.biomedcentral.com/articles/10.1186/1471-2202-16-S1-P151

See also:

	https://stackoverflow.com/questions/793761/built-in-python-hash-function/3979894

Which explains:

	Hash results varies between 32bit and 64bit platforms

	If a calculated hash shall be the same on both platforms consider using

	def hash32(value):
	    return hash(value) & 0xffffffff

I'll just add an id32 function to the top of netParams:

	## Hash function
	def id32(obj):
	    return hash(obj) & 0xffffffff

And get rid of the sim in sim.id32

Now it works, and the traces look better:
file:nb_gif/20190226_074924.png

Committing now.


** Switching PV5 noise to Gfluctp

New code:

	# PV5 noise
	if cfg.noisePV5:
	    netParams.cellParams['PV5']['secs']['soma']['pointps'] = {
                        'noise': {'mod': 'Gfluctp', 
                        'loc': 0.5,
                        'std_e': 0.012,
                        'g_e0' : 0.0121 * cfg.PV5_exc_noise_amp, 
                        'tau_i': 10.49 * cfg.PV5_inh_noise_tau, 
                        'tau_e': 2.728 * cfg.PV5_exc_noise_tau, 
                        'std_i': 0.0264, 
                        'g_i0' : 0.0573 * cfg.PV5_inh_noise_amp, 
                        'E_e'  : cfg.PV5_exc_noise_e, 
                        'E_i'  : cfg.PV5_inh_noise_e, 
                        'seed1': 'gid', 
                        'seed2': id32('gfluctp'), 
                        'seed3': cfg.seeds['stim']}}

It works and traces look good.  

Activating connectivity and running a larger sim (80/20 instead of 8/2)

Also running a very large sim (800/200)

Everything works.  Will post figs in EEE Meeting agenda.

Committing now.

** EEE Meeting

https://docs.google.com/document/d/1DeegMQNZIMpLq36klrj9kUMvpHJQJ3wsm3SAGRIYnt4/edit

Discussion

Penny puts in CNS abstract, will use same one for BRAIN meeting
Poster out of paper figures, plus some network stuff
Next step: induce plateaus
Then: larger network, look for emergent plateaus
Bill: save spikes for each run, can make figures later then
RMP values look fine
Play around with convergence to find emergent plateaus
Want to expand to 10,000 cells
How does Netpyne convergence work?  It it a percent or a number of cells?
Should look into connectivity, measure output from different con/divergences

Action items for next week

Penny: abstract for CNS
Joe: induced plateaus
Joe/Subha: run batch sims on HPC


** Getting plateau induction going

Getting an error:

	graham$ cd ~/EEE_network/eee_net ; ipython -i init.py
	Python 3.7.1 (default, Dec 14 2018, 13:28:58) 
	Type 'copyright', 'credits' or 'license' for more information
	IPython 7.2.0 -- An enhanced Interactive Python. Type '?' for help.
	Note: NeuroML import failed; import/export functions for NeuroML will not be available. 
	  To install the pyNeuroML & libNeuroML Python packages visit: https://www.neuroml.org/getneuroml
	Balancing each compartment to -73 mV

	Creating network of 5 cell populations on 1 hosts...
	  Number of cells on node 0: 100 
	  Done; cell creation time = 0.32 s.
	Making connections...
	  Number of connections on node 0: 2400 
	  Number of synaptic contacts on node 0: 4320 
	  Done; cell connection time = 0.30 s.
	Adding stims...
	---------------------------------------------------------------------------
	IndexError                                Traceback (most recent call last)
	~/EEE_network/eee_net/init.py in <module>
	     24 sim.net.createCells()         # instantiate network cells based on defined populations
	     25 sim.net.connectCells()        # create connections between cells based on params
	---> 26 sim.net.addStims()            # add network stimulation
	     27 sim.setupRecording()          # setup variables to record (spikes, V traces, etc)
	     28 sim.runSim()                  # run parallel Neuron simulation

	~/Applications/netpyne/netpyne/network/stim.py in addStims(self)
	     60             if 'cellList' in target['conds']:
	     61                 orderedPostGids = sorted(postCellsTags.keys())
	---> 62                 gidList = [orderedPostGids[i] for i in target['conds']['cellList']]
	     63                 postCellsTags = {gid: tags for (gid,tags) in postCellsTags.items() if gid in gidList}
	     64 

	~/Applications/netpyne/netpyne/network/stim.py in <listcomp>(.0)
	     60             if 'cellList' in target['conds']:
	     61                 orderedPostGids = sorted(postCellsTags.keys())
	---> 62                 gidList = [orderedPostGids[i] for i in target['conds']['cellList']]
	     63                 postCellsTags = {gid: tags for (gid,tags) in postCellsTags.items() if gid in gidList}
	     64 

	IndexError: list index out of range


Here's where the problem arises:

        for cur_pop in ['PV5_1']:    

            for i in range(len(ns['synMech'])):
                
                netParams.stimTargetParams[nslabel+'_'+cur_pop+'_'+ns['synMech'][i]] = {'source': nslabel, 'conds': {'pop': cur_pop, 'cellList': range(0, int(cfg.numPT5cells/4))}, 'sec': ns['sec'], 'synsPerConn': cfg.numSyns, 'loc': list(cur_locs), 'synMech': ns['synMech'][i], 'weight': list(cur_weights), 'delay': list(cur_delays)}

I'm going to remove cellList from the conds.

Okay it runs now, but I'm not seeing the glutamate puff.  Netpyne says it is setting up 0 stims.

Looking into it.

Part of it was that I said `for cur_pop in ['PV5_1']:` instead of `PT5_1`.

Now the stim connection works, but I'm still not seeing the plateau.  Looking into it.

Committing and taking a break.


* 2019-02-27 -- Plateau induction

** Inducing plateaus

The plateaus should be induced in PT5_1, but I don't see any indication...

Looking into it.

Turned off noise to PT pops, and now PT5_1 does spike as if the plateau stimulus was coming 
in, but there is no visible plateau...

file:gif/20190227_083858.png

Recording from plateau dendrite:
	cfg.recordTraces['V_dend'] = {'sec':'basal_8', 'loc':0.5, 'var':'v'}

The plateau does appear in the dendrite, it just doesn't make it to the soma...

file:gif/20190227_085430.

So I need to figure out why the plateau doesn't make it to the soma...

I think I'll plot voltage traces in each branch leading to basal_8, where the glut puff is
released.

Looking at eeeS.py: self.basal[8].connect(self.basal[0])

So 8 connects to 0, which connects to the soma.

Adding this to cfg.py:

cfg.recordTraces['V_dend_8'] = {'sec':'basal_8', 'loc':0.5, 'var':'v'}
cfg.recordTraces['V_dend_0'] = {'sec':'basal_0', 'loc':0.5, 'var':'v'}

Running sim.

The plateau doesn't even seem to make it to the next branch, but there is spiking,
so something is reaching the soma:
file:gif/20190227_095200.png

Something weird is going on.

I'm going to plot all dends.  All other dends just seem to get bAPs.

On the plus side, I can see in the other PT cells (w/o plateau), that the EPSPs look good.

** Checking using old eeeS

I saved the old eeeS.py as eeeS_multi.py before Penny took the multi-compartment soma and 
collapsed it into one compartment.

I'm going to plug that in.

#eeeS_path = os.path.join(cellpath, 'eeeS.py')
eeeS_path = os.path.join(cellpath, 'eeeS_multi.py')

Nope same problem.  Must be something else.

** Looking into old detailed/simplified single cell comparisons



* 2019-02-28 -- Plateau induction part deux

I think it's time to dig in a little deeper and make sure everything is working as it 
should.

I'm going to dig up the old code to compare the detailed single cell model with the 
simplified.

Need to get the old code first:

	cd ~ ; mkdir eee_singlecell ; cd eee_singlecell 
	hg clone ssh://no.neurosim.downstate.edu://u/graham/projects/eee
	cd ~/eee_singlecell/eee ; python setup.py

Error:

	graham-mac:eee graham$ python setup.py
	  File "setup.py", line 141
	    except OSError, e:  
	                  ^
	SyntaxError: invalid syntax

https://stackoverflow.com/questions/32613375/python-2-7-exception-handling-syntax

Looks like I need to `except OSError as e:` instead of `except OSError, e:`

Now setup.py works.

Now to try running the batches:

	cd ~/eee_singlecell/eee/sim/batches_indcell/batch_20180424/
	python my_batches.py

Error:

	Traceback (most recent call last):
	  File "my_batches.py", line 16, in <module>
	    import batch_utils
	ModuleNotFoundError: No module named 'batch_utils'

	During handling of the above exception, another exception occurred:

	Traceback (most recent call last):
	  File "my_batches.py", line 22, in <module>
	    import batch_utils
	  File "/Users/graham/eee_singlecell/eee/sim/batch_utils.py", line 68
	    print '\nLoading single file with all data...'
	                                                 ^
	SyntaxError: Missing parentheses in call to 'print'. Did you mean print('\nLoading single file with all data...')?

Adding parentheses to all print statements.

New error:

	Running batch with label: synLocMiddle_ttx
	Traceback (most recent call last):
	  File "my_batches.py", line 183, in <module>
	    batch_utils.run_batch(**batch)
	  File "/Users/graham/eee_singlecell/eee/sim/batch_utils.py", line 50, in run_batch
	    for k,v in params.iteritems():
	AttributeError: 'collections.OrderedDict' object has no attribute 'iteritems'

Changing to .items() -- new to Python 3

New error:

	Running batch with label: synLocMiddle_ttx
	Note: NeuroML import failed; import/export functions for NeuroML will not be available. 
	  To install the pyNeuroML & libNeuroML Python packages visit: https://www.neuroml.org/getneuroml
	Saving batch to batch_data/synLocMiddle_ttx/synLocMiddle_ttx_batch.json ... 
	(0,) (0.2,)
	synLocMiddle = 0.2
	Saving simConfig to batch_data/synLocMiddle_ttx/synLocMiddle_ttx_0_cfg.json ... 
	Error: invalid runCfg 'type' selected; valid types are 'mpi_bulletin', 'mpi_direct', 'hpc_slurm', 'hpc_torque'

batch_utils.py starting at line 59:

    b.runCfg = {'type': 'mpi', 
                'script': 'batch_init.py', 
                'skip': True}

From Slack:

	salvadord   [2 months ago]
	the previous ‘mpi’ corresponds to ‘mpi_bulletin’, so would recommend that. I just added ‘mpi_direct’ for a specific case

Changing it to:

	b.runCfg = {'type': 'mpi_bulletin',

Okay, the batches ran, but there is no output.  Debugging.

	graham$ cd /Users/graham/eee_singlecell/eee/sim/batches_indcell/batch_20180424 
	graham$ python cfg.py
	graham$ python netParams.py
	Couldn't import cfg from __main__
	Attempting to import cfg from cfg.
	Traceback (most recent call last):
	  File "netParams.py", line 57, in <module>
	    cellRule = netParams.importCellParams(label='eeeD', conds={'cellType': 'eeeD', 'cellModel': 'PFC_full'}, fileName=eeeD_path, cellName='MakeCell')
	  File "/Users/graham/Applications/netpyne/netpyne/specs/netParams.py", line 339, in importCellParams
	    secs, secLists, synMechs, globs = conversion.importCell(fileName, cellName, cellArgs, cellInstance)
	  File "/Users/graham/Applications/netpyne/netpyne/conversion/neuronPyHoc.py", line 191, in importCell
	    tempModule = importlib.import_module(moduleName)
	  File "/Users/graham/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
	    return _bootstrap._gcd_import(name[level:], package, level)
	  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
	  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
	  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
	  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
	  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
	  File "<frozen importlib._bootstrap_external>", line 860, in get_code
	  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
	  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
	  File "/Users/graham/eee_singlecell/eee/sim/cells/eeeD.py", line 166
	    print "geom_nseg: changed from ", before, " to ", after, " total segments"
	                                   ^
	SyntaxError: Missing parentheses in call to 'print'. Did you mean print("geom_nseg: changed from ", before, " to ", after, " total segments")?

Looks like eeeD.py has print statements without parentheses.  There is a newer version Penny made
which should already be updated for Python 3...

Will run a diff on ~/eee_singlecell/eee/sim/cells/eeeD.py and ~/EEE_network/cells/eeeD.py

Nevermind, they're identical.  Updating print statements for py3

Trying again:

	graham$ python netParams.py
	Couldn't import cfg from __main__
	Attempting to import cfg from cfg.
	Traceback (most recent call last):
	  File "netParams.py", line 57, in <module>
	    cellRule = netParams.importCellParams(label='eeeD', conds={'cellType': 'eeeD', 'cellModel': 'PFC_full'}, fileName=eeeD_path, cellName='MakeCell')
	  File "/Users/graham/Applications/netpyne/netpyne/specs/netParams.py", line 339, in importCellParams
	    secs, secLists, synMechs, globs = conversion.importCell(fileName, cellName, cellArgs, cellInstance)
	  File "/Users/graham/Applications/netpyne/netpyne/conversion/neuronPyHoc.py", line 194, in importCell
	    cell = getattr(modulePointer, cellName)(**cellArgs) # create cell using template, passing dict with args
	  File "/Users/graham/eee_singlecell/eee/sim/cells/eeeD.py", line 2090, in MakeCell
	    cell = eeeD()
	  File "/Users/graham/eee_singlecell/eee/sim/cells/eeeD.py", line 133, in __init__
	    self.create_cell()
	  File "/Users/graham/eee_singlecell/eee/sim/cells/eeeD.py", line 559, in create_cell
	    self.soma = [h.Section(name='soma[%d]' % i) for i in xrange(4)]
	NameError: name 'xrange' is not defined
	graham-mac:batch_20180424 graham$ 

Maybe `xrange` no longer exists in Python 3?

Yup.  https://treyhunner.com/2018/02/python-3-s-range-better-than-python-2-s-xrange/

Replacing `xrange` with `range` and trying again.

Okay, now I need to all the same stuff to eeeS.py.  But eeeS has been updated.  Running a 
diff first.

	/Users/graham/EEE_network/cells/eeeS.py
	/Users/graham/eee_singlecell/eee/sim/cells/eeeS.py

*** eeeS diff

--- /Users/graham/Desktop/eeeS/eeeS_new.py	Mon Mar  4 15:45:08 2019
+++ /Users/graham/Desktop/eeeS/eeeS_old.py	Mon Mar  4 15:45:32 2019
@@ -8,6 +8,18 @@
 Feb 01, 2018
 The cell class has 3d morphology structure infomation.
 They can be placed in a network (logical 3d location).
+
+Improved on March 01, 2018 to have better membrane time constant & resting membrane potential.
+Previous model has time constant ~ 6ms, most experimental data of
+neocortex pyramidal L5-6 neurons have time constant ~ 10ms.
+SpineFACTOR is increased from 1.5 to 1.6
+somaRm increased from 1000/0.4 to 1400/0.04
+dendRm increased to same value as somaRm
+somaCm increased from 1 to 1.5431
+dendCm increased to somaCm*spineFACTOR
+
+pasVm increased from -80 to -65
+kBK_gpeak increased from 2.68e-4 to 16.8e-4
 
 Ref: https://neuroelectro.org/neuron/111/
      https://senselab.med.yale.edu/ModelDB/ShowModel.cshtml?model=168148&file=/stadler2014_layerV/LayerVinit.hoc#tabs-2
@@ -27,19 +39,28 @@
 # Parameters
 #########################################
 # Cell passive properties
-global_Ra = 100
-spineFACTOR = 1.5
-somaRm = 1500/0.04
-dendRm = somaRm/spineFACTOR
-somaCm = 1.45
-
+global_Ra = 90
+spineFACTOR = 1.5 # It was 1.5 originally, in order to match the time constant,
+# We try to increase it on Feb.27, 2018 according to Reetz et al. (2014)
+somaRm = 1500/0.04 # Try 1500/0.04 on Feb.27, 2018, Original 1000/0.04
+dendRm = somaRm/spineFACTOR # somaRm/spineFACTOR
+somaCm = 1.45 # It was 1 originally, in order to increase the time constant,
+# We increased it on Marth 1, 2018 according to Reetz et al. (2014)
+
+############ This is where the problem comes from when i want the hyperpolarization
+# after spike change
+# If dendCm = somaCm*spineFACTOR: No hyperpolarization after spike on plateau at all
+# If dendCm = somaCm/spineFACTOR: Huge hyperpolarization!!!
 dendCm = somaCm*spineFACTOR
-spinedist = 40 # distance at which spines start
-Vk = -87
-VNa = 60
-pasVm = -65
+spinedist = 50 # distance at which spines start
+Vk = -100 # -100 #-105 # -80
+VNa = 65 #65 #60 #55
+pasVm = -70 #-80 #-85 #-89 #-90 #-65
+
 # Specify cell biophysics
-somaNa = 900  # [pS/um2]
+# ratio = 0
+
+somaNa = 150 # 900  # [pS/um2]
 axonNa = 5000   # [pS/um2]
 basalNa = 150  # [pS/um2]
 mNa = 0.5  # decrease in sodium channel conductance in basal dendrites [pS/um2/um]
@@ -51,7 +72,11 @@
 mKV = 0  # increase in KV conductance in basal dendrites
 gKVmax = 500  # maximum basal KV conductance
 axonKv = 100
-somaKA = 150
+somaKA = 150 #100  # It was 150 in the best fit model from Srdjan 2009
+# In order to decrease the hyperpolirization after APs on plateau
+# decreased to 100 on Feb 27, 2018
+# Changed back to 150 on March 01, 2018
+# initial basal total GKA conductance [pS/um2] equals somatic
 mgka = 0.7  # linear rise in IA channel density
 mgkaratio = 1./300 # linear drop in KAP portion, 1 at soma
 apicalKA = 300  # apical total GKA conductance
@@ -72,8 +97,9 @@
 ILdist = 15
 
 #############kBK.mod
-kBK_gpeak = 2.68e-4
-kBK_caVhminShift = 45
+kBK_gpeak = 2.68e-4 #7.67842640257e-05 #2.68e-4 #16.8e-4 #2.68e-4 #7.67842640257e-05 # Tried 2.68e-4 # original value of 268e-4 too high for this model
+# 7.67842640257e-05 or 6.68e-4 both works, can change it based on the interspike invervals we are aiming for
+kBK_caVhminShift = 45 #45 #50 #45.0 # shift upwards to get lower effect on subthreshold
 
 
 #########################################
@@ -89,7 +115,7 @@
     Membrane Exitability and Action Potential Backpropagation in Basal Dendrites
     of Prefrontal Cortical Pyramidal Neurons.
 
-    soma: 1 compartment
+    soma: soma compartments (soma[0] - soma[3])
     apical: apical dendrites (apical[0] - apical[44])
     basal: basal dendrites (basal[0] - basal[35])
     basals: SectionList of all basal but excluing basal[16]
@@ -129,7 +155,7 @@
         for sec in self.all:
             # creates the number of segments per section
             # lambda_f takes in the current section
-
+            
             print
             print(sec.name())
             print(sec.nseg)
@@ -140,7 +166,7 @@
             print(sec.nseg)
             print
         for sec in self.all: after += sec.nseg
-        print("geom_nseg: changed from ", before, " to ", after, " total segments")
+        print "geom_nseg: changed from ", before, " to ", after, " total segments"
 
     def lambda_f (self, section):
         # these are reasonable values for most models
@@ -171,10 +197,9 @@
         # Set up sectionList - easy to modify properties
         self.all = h.SectionList()
         self.all_no_axon = h.SectionList()
-
-        self.all.append(sec = self.soma)
-        self.all_no_axon.append(sec = self.soma)
-
+        for section in self.soma:
+            self.all.append(sec = section)
+            self.all_no_axon.append(sec = section)
         for section in self.basal:
             self.all.append(sec = section)
         for section in self.apical:
@@ -225,7 +250,7 @@
     # Add basic properties
     ###################
     def add_all(self):
-
+        
         for sec in self.all:
             sec.insert('vmax')
             sec.insert('pas')
@@ -298,7 +323,7 @@
             h.thi2_na = -58
 
             sec.insert('kl')
-            h.distance(0,0.5,sec=self.soma)
+            h.distance(0,0.5,sec=self.soma[0])
             for seg in sec.allseg():
                 dist = h.distance(seg.x, sec=sec)
                 if (dist>= ILdist):
@@ -314,22 +339,22 @@
             sec.gbar_na = somaNa
 
         for sec in self.basals:
-            h.distance(0, 0.5, sec = self.soma)
+            h.distance(0, 0.5, sec = self.soma[0])
             for seg in sec.allseg():
                 dist = h.distance(seg.x, sec = sec)
                 gNalin = basalNa - mNa * dist
                 if (gNalin > gNamax):
                     gNalin = gNamax
-                    print("Setting basal Na to maximum ",gNamax,
-                    " at distance ",dist," in basal dendrite ", sec.name())
+                    print "Setting basal Na to maximum ",gNamax,
+                    " at distance ",dist," in basal dendrite ", sec.name()
                 elif (gNalin < 0):
                     gNalin = 0
-                    print("Setting basal Na to zero at distance ",dist,
-                    " in basal dendrite ",sec.name())
+                    print "Setting basal Na to zero at distance ",dist,
+                    " in basal dendrite ",sec.name()
                 sec(seg.x).gbar_na = gNalin
 
         for sec in self.axon:
-            h.distance(0, 0.5, sec = self.soma)
+            h.distance(0, 0.5, sec = self.soma[0])
             for seg in sec.allseg():
                 dist = h.distance(seg.x, sec = sec)
                 if (dist >= 50 and dist <= 100):
@@ -348,16 +373,16 @@
             sec.gbar_kv = somaKv
 
         for sec in self.basals:
-            h.distance(0,0.5,sec=self.soma)
+            h.distance(0,0.5,sec=self.soma[0])
             for seg in sec.allseg():
                 dist = h.distance(seg.x, sec=sec)
                 gKVlin = somaKv + mKV * dist
                 if (gKVlin > gKVmax):
                     gKVlin = gKVmax
-                    print("Setting basal GKV to maximum ",gKVmax," at distance ",dist," in basal dendrite",sec.name())
+                    print "Setting basal GKV to maximum ",gKVmax," at distance ",dist," in basal dendrite",sec.name()
                 elif (gKVlin < 0):
                     gKVlin = 0
-                    print("Setting basal GKV to zero at distance ",dist," in basal dendrite ",sec.name())
+                    print "Setting basal GKV to zero at distance ",dist," in basal dendrite ",sec.name()
                 sec(seg.x).gbar_kv = gKVlin
 
         for sec in self.axon:
@@ -375,7 +400,7 @@
             gkabar_kap = somaKA/1e4
 
         for sec in self.basals:
-            h.distance(0,0.5,sec=self.soma)
+            h.distance(0,0.5,sec=self.soma[0])
             for seg in sec.allseg():
                 dist = h.distance(seg.x, sec=sec)
                 gkalin = somaKA + mgka*dist
@@ -387,15 +412,15 @@
 
                 if (gkalin > gkamax):
                     gkalin = gkamax
-                    print("Setting GKA to maximum ",gkamax," in basal dendrite",sec.name())
+                    print "Setting GKA to maximum ",gkamax," in basal dendrite",sec.name()
                 elif (gkalin < 0):
                     gkalin = 0
-                    print("Setting GKA to 0 in basal dendrite",sec.name())
+                    print "Setting GKA to 0 in basal dendrite",sec.name()
                 sec(seg.x).gkabar_kap = gkalin * ratio/1e4
                 sec(seg.x).gkabar_kad = gkalin * (1-ratio)/1e4
 
         for sec in self.apical:
-            h.distance(0,0.5,sec=self.soma)
+            h.distance(0,0.5,sec=self.soma[0])
             for seg in sec.allseg():
                 dist = h.distance(seg.x, sec=sec)
                 ratiolin = 1 - mgkaratio*dist
@@ -415,7 +440,7 @@
             sec.gbar_it = SomaCaT/1e4
 
         for sec in self.basals:
-            h.distance(0,0.5,sec = self.soma)
+            h.distance(0,0.5,sec = self.soma[0])
             for seg in sec.allseg():
                 dist = h.distance(seg.x, sec = sec)
                 if (dist > cadistB):
@@ -426,7 +451,7 @@
                     sec(seg.x).gbar_it = SomaCaT/1e4
 
         for sec in self.apical:
-            h.distance(0,0.5,sec = self.soma)
+            h.distance(0,0.5,sec = self.soma[0])
             for seg in sec.allseg():
                 dist = h.distance(seg.x, sec=sec)
                 if (dist > cadistA):
@@ -441,7 +466,7 @@
 #########################################
     def distspines(self):
         for sec in self.basals:
-            h.distance(0,0.5,sec = self.soma)
+            h.distance(0,0.5,sec = self.soma[0])
             for seg in sec.allseg():
                 dist = h.distance(seg.x, sec=sec)
                 if (dist >= spinedist):
@@ -452,7 +477,7 @@
                     sec(seg.x).g_pas = 1./somaRm
 
         for sec in self.apical:
-            h.distance(0,0.5,sec = self.soma)
+            h.distance(0,0.5,sec = self.soma[0])
             for seg in sec.allseg():
                 dist = h.distance(seg.x, sec=sec)
                 if (dist >= spinedist):
@@ -466,16 +491,17 @@
 # Add Ih channels
 #########################################
     def add_ih(self):
-        self.soma.insert('Ih')
-        self.soma.gIhbar_Ih = 0.0001
-
-        for sec in self.basals:
+        for sec in self.soma:
             sec.insert('Ih')
             sec.gIhbar_Ih = 0.0001
 
-        for sec in self.apical:
+        for sec in self.basals:
             sec.insert('Ih')
-            h.distance(0,0.5,sec=self.soma)
+            sec.gIhbar_Ih = 0.0001
+
+        for sec in self.apical:
+            sec.insert('Ih')
+            h.distance(0,0.5,sec=self.soma[0])
             for seg in sec.allseg():
                 dist = h.distance(seg.x, sec=sec)
                 sec(seg.x).gIhbar_Ih = 0.0002*(-0.8696 + 2.0870*exp(dist/323))
@@ -503,10 +529,10 @@
             sec.insert('kBK')
             sec.gpeak_kBK = kBK_gpeak
             sec.caVhmin_kBK = -46.08 + kBK_caVhminShift
-
-        self.soma.insert('kBK')
-        self.soma.gpeak_kBK = kBK_gpeak
-        self.soma.caVhmin_kBK = -46.08 + kBK_caVhminShift
+        for sec in self.soma:
+            sec.insert('kBK')
+            sec.gpeak_kBK = kBK_gpeak
+            sec.caVhmin_kBK = -46.08 + kBK_caVhminShift
 
 #########################################
 # TTX
@@ -520,8 +546,9 @@
 # No calcium
 #########################################
     def no_ca(self):
-        self.soma.gbar_ca = 0
-        self.soma.gbar_it = 0
+        for sec in self.soma:
+            sec.gbar_ca = 0
+            sec.gbar_it = 0
         for sec in self.apical:
             sec.gbar_ca = 0
             sec.gbar_it = 0
@@ -537,50 +564,59 @@
         The diam and L of each compartment is determined by 3D structure.
         Same as hoc 3D morphology: CA229.hoc
         """
-        self.soma = h.Section(name='soma')
+        self.soma = [h.Section(name='soma[%d]' % i) for i in xrange(4)]
         self.apical = [h.Section(name='apical[0]')]
-        self.basal = [h.Section(name='basal[%d]' % i) for i in range(10)]
+        self.basal = [h.Section(name='basal[%d]' % i) for i in xrange(10)]
         self.axon = [h.Section(name='axon[0]')]
 
         self.axon[0].L = 200.0
         self.axon[0].diam = 1.03
         self.axon[0].nseg = 1
-        self.axon[0].connect(self.soma)
+        self.axon[0].connect(self.soma[2])
 
         self.apical[0].L = 454.5
         self.apical[0].diam = 6.00
         self.apical[0].nseg = 1
-        self.apical[0].connect(self.soma)
+        self.apical[0].connect(self.soma[3])
 
         self.basal[9].L = 157.2
         self.basal[9].diam = 6.00
         self.basal[9].nseg = 1
-        self.basal[9].connect(self.soma)
+        self.basal[9].connect(self.soma[1])
 
         self.basal[8].nseg = 3
 
 
 
         # Set up the 3d morphology and connection of soma
-        h.pt3dclear(sec = self.soma)
-        h.pt3dstyle(1, -53.42,3.52,-5.95,13.43, sec = self.soma)
-        h.pt3dadd(-53.42,3.52,-5.96,13.43, sec = self.soma)
-        h.pt3dadd(-53.74,0.93,-5.96,15.35, sec = self.soma)
-        h.pt3dadd(-54.06,-1.66,-5.96,11.51, sec = self.soma)
-        h.pt3dadd(-54.06,-4.25,-5.96,7.99, sec = self.soma)
-
-
-        h.pt3dadd(-53.42,3.52,-5.96,13.43, sec = self.soma)
-        h.pt3dadd(-53.1,6.12,-5.96,11.19, sec = self.soma)
-        h.pt3dadd(-52.78,8.71,-5.96,9.59, sec = self.soma)
-        h.pt3dadd(-52.78,11.62,-5.96,7.36, sec = self.soma)
-        h.pt3dadd(-53.1,14.22,-5.96,5.76, sec = self.soma)
+        h.pt3dclear(sec = self.soma[0])
+        h.pt3dstyle(1, -53.42,3.52,-5.95,13.43, sec = self.soma[0])
+        h.pt3dadd(-53.42,3.52,-5.96,13.43, sec = self.soma[0])
+
+        self.soma[1].connect(self.soma[0])
+        h.pt3dclear(sec = self.soma[1])
+        h.pt3dadd(-53.42,3.52,-5.96,13.43, sec = self.soma[1])
+        h.pt3dadd(-53.74,0.93,-5.96,15.35, sec = self.soma[1])
+        h.pt3dadd(-54.06,-1.66,-5.96,11.51, sec = self.soma[1])
+
+        self.soma[3].connect(self.soma[0])
+        h.pt3dclear(sec = self.soma[3])
+        h.pt3dadd(-53.42,3.52,-5.96,13.43, sec = self.soma[3])
+        h.pt3dadd(-53.1,6.12,-5.96,11.19, sec = self.soma[3])
+        h.pt3dadd(-52.78,8.71,-5.96,9.59, sec = self.soma[3])
+        h.pt3dadd(-52.78,11.62,-5.96,7.36, sec = self.soma[3])
+        h.pt3dadd(-53.1,14.22,-5.96,5.76, sec = self.soma[3])
+
+        self.soma[2].connect(self.soma[1])
+        h.pt3dclear(sec = self.soma[2])
+        h.pt3dadd(-54.06,-1.66,-5.96,11.51, sec = self.soma[2])
+        h.pt3dadd(-54.06,-4.25,-5.96,7.99, sec = self.soma[2])
 
         # Set up the 3d morphology and connection of basal dendrites
-
-
-
-        self.basal[0].connect(self.soma)
+      
+        
+
+        self.basal[0].connect(self.soma[0])
         h.pt3dclear(sec = self.basal[0])
         h.pt3dadd(-53.42,3.52,-5.96,2.5, sec = self.basal[0])
         h.pt3dadd(-60.3,3.99,0.28,1.28, sec = self.basal[0])
@@ -729,4 +765,4 @@
 
 def MakeCell():
     cell = eeeS()
-    return cell
+    return cell


* 2019-03-04 -- Inducing plateaus

** Inducing plateaus

I am looking at how we induced plateaus in the single cell models, because right now something 
is wrong with inducing plateaus in network model.

I am going to copy the new eeeS.py from the network repo to the old single cell repo, so that
parameters are updated and it works in Python 3.  Will rename old file eeeS_py2.py

Then try to induce plateaus.

Updated single cell repo:

	graham-mac:eee graham$ pwd
	/Users/graham/eee_singlecell/eee
	graham-mac:eee graham$ hg status
	M setup.py
	M sim/batch_utils.py
	M sim/batches_indcell/batch_20180424/analyze.py
	M sim/batches_indcell/batch_20180424/batch_init.py
	M sim/batches_indcell/batch_20180424/instantiate.py
	M sim/batches_indcell/batch_20180424/runmybatches
	M sim/cells/eeeD.py
	M sim/cells/eeeS.py
	? sim/cells/eeeS_py2.py
	graham-mac:eee graham$ hg add sim/cells/eeeS_py2.py 
	graham-mac:eee graham$ hg status
	M setup.py
	M sim/batch_utils.py
	M sim/batches_indcell/batch_20180424/analyze.py
	M sim/batches_indcell/batch_20180424/batch_init.py
	M sim/batches_indcell/batch_20180424/instantiate.py
	M sim/batches_indcell/batch_20180424/runmybatches
	M sim/cells/eeeD.py
	M sim/cells/eeeS.py
	A sim/cells/eeeS_py2.py
	graham-mac:eee graham$ hg commit -m "Updated repo for Python 3, replaced eeeS with latest version from network model"
	graham-mac:eee graham$ hg status
	graham-mac:eee graham$ hg push
	pushing to ssh://no.neurosim.downstate.edu//u/graham/projects/eee
	searching for changes
	remote: adding changesets
	remote: adding manifests
	remote: adding file changes
	remote: added 1 changesets with 9 changes to 9 files
	graham-mac:eee graham$ 

Now trying to run single cell batches.

	cd ~/eee_singlecell/eee/sim/batches_indcell/batch_20180424/
	python netParams.py

Error:

	Traceback (most recent call last):
	  File "netParams.py", line 69, in <module>
	    for cell_label, cell_params in netParams.cellParams.iteritems():
	  File "/Users/graham/Applications/netpyne/netpyne/specs/dicts.py", line 170, in __getattr__
	    raise AttributeError(k)
	AttributeError: iteritems

Will change all dict iteritems to items in netParams.py

Now netParams runs without crashing.

my_batches.py runs, but there is no output.  Testing batch_init.py 

	cd /Users/graham/eee_singlecell/eee/sim/batches_indcell/batch_20180424
	python batch_init.py

It runs, and generates output, but has some weird error messages:

	Traceback (most recent call last):
	  File "/Users/graham/Applications/netpyne/netpyne/tests/tests.py", line 1046, in testValidStimSource
	    mechVarList = mechVarList()
	UnboundLocalError: local variable 'mechVarList' referenced before assignment
	Traceback (most recent call last):
	  File "/Users/graham/Applications/netpyne/netpyne/tests/tests.py", line 3265, in execRunTests
	    errorMessages = self.testTypeObj.testValidStimSource(paramValues)
	  File "/Users/graham/Applications/netpyne/netpyne/tests/tests.py", line 1046, in testValidStimSource
	    mechVarList = mechVarList()
	UnboundLocalError: local variable 'mechVarList' referenced before assignment
	ERROR: local variable 'mechVarList' referenced before assignment.
	Traceback (most recent call last):
	  File "/Users/graham/Applications/netpyne/netpyne/tests/tests.py", line 1046, in testValidStimSource
	    mechVarList = mechVarList()
	UnboundLocalError: local variable 'mechVarList' referenced before assignment
	Traceback (most recent call last):
	  File "/Users/graham/Applications/netpyne/netpyne/tests/tests.py", line 3265, in execRunTests
	    errorMessages = self.testTypeObj.testValidStimSource(paramValues)
	  File "/Users/graham/Applications/netpyne/netpyne/tests/tests.py", line 1046, in testValidStimSource
	    mechVarList = mechVarList()
	UnboundLocalError: local variable 'mechVarList' referenced before assignment
	ERROR: local variable 'mechVarList' referenced before assignment.
	ERROR: SimConfig->'analysis'->'plotTraces': plotTraces must be a bool or dict with keys in list ['include', 'timeRange', 'overlay', 'oneFigPer', 'rerun', 'figSize', 'saveData', 'showFig']. Keys supplied are ['include', 'oneFigPer', 'saveFig', 'showFig', 'figSize', 'timeRange'].
	ERROR: SimConfig->'analysis'->'plotTraces'->'saveFig': saveFig must be tuple if specified. Value provided is True.

Ugh.  I don't think this is helping.  I'm going to go back to the network model and try to figure
out why the plateau is behaving so weirdly: shape doesn't look quite right in dendrite, and the
plateau doesn't reach the soma at all.


** Back to exploring plateu in network model

Plateau is behaving weirdly: shape doesn't look quite right in dendrite, and the
plateau doesn't reach the soma at all.

Looking into it.

I'll start by just injecting current into the cell model and seeing how it responds.

Added the following to cfg.py:

	# Current clamps
	cfg.addIClamp = True

	cfg.delIClamp1 = 200
	cfg.durIClamp1 = 20
	cfg.ampIClamp1 = 10
	cfg.popIClamp1 = ['PT5_2']
	cfg.secIClamp1 = 'soma'
	cfg.locIClamp1 = 0.5

	cfg.IClamp1 = {'pop': cfg.popIClamp1, 'sec': cfg.secIClamp1, 'loc': cfg.locIClamp1, 'del': cfg.delIClamp1, 'dur': cfg.durIClamp1, 'amp': cfg.ampIClamp1}

Added the following to netParams.py:

	if cfg.addIClamp:

	    for iclabel in [k for k in dir(cfg) if k.startswith('IClamp')]:
	        ic = getattr(cfg, iclabel, None)  # get dict with params

	        # add stim source
	        netParams.stimSourceParams[iclabel] = {'type': 'IClamp', 'del': ic['del'], 'dur': ic['dur'], 'amp': ic['amp']}
	        
	        # add stim target
	        for curpop in ic['pop']:
	            netParams.stimTargetParams[iclabel+'_'+curpop] = \
	                {'source': iclabel, 'conds': {'popLabel': ic['pop']}, 'sec': ic['sec'], 'loc': ic['loc']}

It worked, but not seeing the soma plot in PT5 pops for some reason (soma traces appear for PV5)

file:gif/20190304_205604.png

It will plot the soma v trace if I use soma_0 or soma_1...  I think Penny's nseg optimizer may
be adding nseg's to the soma.  Looking into it.

That's not it.  I already commented out geom_nseg for the simplified cell...

Added this to netParams:

	for secName, sec in netParams.cellParams['PT5_1']['secs'].items():  
	    print(secName) 

And got the following output:

	soma_0
	soma_1
	soma_2
	soma_3
	apical_0
	basal_0
	basal_1
	basal_2
	basal_3
	basal_4
	basal_5
	basal_6
	basal_7
	basal_8
	basal_9
	axon_0

For some reason, there are four soma compartments...

Added the following line to eeeS.py:

	self.soma.nseg = 1

D'oh. I forgot to change back to the cell model with only one soma compartment.

	eeeS_path = os.path.join(cellpath, 'eeeS.py')
	#eeeS_path = os.path.join(cellpath, 'eeeS_multi.py')

Okay, now the soma voltage trace gets plotted.


** Running a batch to explore IClamp amplitudes

Modified batch.py:

	params['ampIClamp1'] = [0.1, 1.0, 10.0]

But all the output looks the same...  Maybe I need to use the actual cfg values in the netParams
file instead of pulling them from the cfg dict...

Modified netParams.py:

        # add stim source
        #netParams.stimSourceParams[iclabel] = {'type': 'IClamp', 'del': ic['del'], 'dur': ic['dur'], 'amp': ic['amp']}
        netParams.stimSourceParams[iclabel] = {'type': 'IClamp', 'del': ic['del'], 'dur': ic['dur'], 'amp': cfg.ampIClamp1}

And trying a batch again:

	graham$ cd ~/EEE_network/eee_net ; ./runbatch

Now it works.  So I should use direct references to cfg.variable in netParams.py instead of creating
a dict in cfg.py which is then pulled into netParams.

But, it looks like each trace is identical...  There should be attenuation.


** Putting IClamp into basal dendrite

In cfg.py:

	cfg.secIClamp1 = 'basal_8' #'soma'
	cfg.locIClamp1 = 1.0 #0.5

Okay, there is attenuation in the other direction.

file:gif/20190304_222057.png

I think I need to confirm that our eeeS cell behaves like Penny's detailed model.

** Checking simplification of cell

Basically, I want to replicate the single cell detailed vs simplified comparisons that I did 
before.

This will require new cfg.py and netParams.py files, which create a network with two unconnected 
cells: eeeD.py and eeeS.py

Feed the same inputs into both and make sure they are similar.

First I'm going to make sure the normal sim still runs and then commit.

Committed.

I copied the whole eee_net dir as eee_single.  Now to find useful code from old single
cell analysis and put it into the cfg and netParams.

Modified cfg and netParams.  Trying to run sim.

Need to update eeeD.py for Python 3.

Fixed that and a few other things and it runs.  

	graham$ cd ~/EEE_network/eee_single/ ; ./runsim

But no traces figures appear.  Looking into why.

Problem was in cfg.py:

	#cfg.analysis['plotTraces'] = {'include': [('PT5_1',0), ('PT5_2', 0), ('PT5_3', 0), ('PT5_4', 0), ('PV5', 0)], 'saveFig': saveFig, 'showFig': showFig}  
	cfg.analysis['plotTraces'] = {'include': ['eeeD', 'eeeS'], 'saveFig': saveFig, 'showFig': showFig} 

Running again.

Better, but no soma plot for eeeD.  That'd be because it has soma_0, soma_1, etc.

Added soma_0

	# Recording options
	cfg.recordTraces = {'V_soma': {'sec':'soma', 'loc':0.5, 'var':'v'}} 
	cfg.recordTraces['V_soma_0'] = {'sec':'soma_0', 'loc':0.5, 'var':'v'}

Looks good:
file:gif/20190304_233346.png

Committing now.

A couple problems: 
1) the plateau is way too large in the dendrite (about 70 mV)
2) the plateau isn't even visible in the soma

Because it is also happening in both the detailed cell model and the simplified, 
I think it's probably a problem with the glutamate puff implementation.

I will try to get the exact setup as Penny's and make sure the detailed model works.

Will look into this tomorrow.


* 2019-03-05 -- Inducing plateaus, EEE meeting

** Trying a range of glutamate puff amplitudes

Setting up a batch sim

Added to batch.py:

	params['glutAmp'] = [0.02, 0.2, 2.0]

Output:

file:gif/20190305_054408.png
Top row is eeeD, bottom is eeeS, left column is glutAmp 0.02, right column is 2.0

Trying another range of glutAmps:

	params['glutAmp'] = [0.1, 0.2, 0.3, 0.4, 0.5, 1.0]

Oddly, it only runs the first three values...  But the range looks better.

I am going to turn off Na (TTX) to see underlying plateaus.

Added to cfg.py:

	# Channel variables
	cfg.ttx = True

Added to netParams.py:

	for secName, sec in netParams.cellParams['eeeD']['secs'].items(): 
	    if cfg.ttx:
	        sec['mechs']['nax']['gbar'] = 0.0

	for secName, sec in netParams.cellParams['eeeS']['secs'].items(): 
	    if cfg.ttx:
	        sec['mechs']['nax']['gbar'] = 0.0

Running batch.  Now can see underlying activity, but it's not large enough to be a plateau...

Need to make sure the detailed model matches up with Penny's detailed model...

But first: an error message from Netpyne


** Error message from Netpyne

Noticed the following when running the sim:
	
	ERROR: Some mechanisms and/or ions were not inserted (for details run with cfg.verbose=True). Make sure the required mod files are compiled.

Setting verbose to True and re-running 

Message:

	# Error inserting nax mechanims in soma section! (check mod files are compiled)
	# Error inserting nax mechanims in apical_0 section! (check mod files are compiled)
	...

Setting cfg.ttx = False and retrying.

Yeah, now the message disappears.

Committing now.  Oops, added too much stuff (e.g. output) to eee_single/
Looking into untracking files with Git...

	git rm -rf eee_single/__pycache__/
	git rm -rf eee_single/output/
	git add -u
	git commit -m "Working on matching eeeD with previous detailed model"


** Ensuring match of detailed models

Interesting output from Netpyne verbose:

	Setting h global variables ...
	  h.celsius = 6.3
	  h.v_init = -65.0
	  h.clamp_resist = 0.001
	  h.taur_cad = 100.0
	  h.thi1_na = -58.0
	  h.thi2_na = -58.0
	  h.vshift_ca = 10.0
	  h.vshift_na = -10.0
	  h.tstop = 1000.0

Will ensure Penny's model uses these values as well.

I see Penny uses h.celsius = 32

Changing to that value and re-running.

	cfg.hParams.celsius = 32.0	

Much better!

file:gif/20190305_070140.png

Left column, celsius = 6.3; Right column celsius = 32.0
Top row: eeeD; Bottom row: eeeS

Adding the temperature change to eee_net/cfg.py

I see Penny uses h.v_init =  -73.6927850677

Setting this value and seeing the effect.

	cfg.hParams.v_init =  -73.7

Looks very similar, but the initial voltage is closer to steady-state:
file:gif/20190305_071153.png

Left column, old v_init; Right column, new v_init
Top row: eeeD; Bottom row: eeeS

Adding new v_init to eee_net/cfg.py


** Running network sim with improvements

To run:

	graham$ cd ~/EEE_network/eee_net/ ; ./runsim

Turned noise back on, verbose off, 100 cells total

file:gif/20190305_072635.png

Looks pretty good, though perhaps too much E->E (basal_8 stays pretty depolarized)

Turning plateau off and running for comparison.

	cfg.glutamate         = False

No plat:

file:gif/20190305_073147.png

Turning plat back on and committing.

Turning temperature up to body temp (36) and seeing what happens

Output:
file:gif/20190305_073923.png

Hmmm.  Doesn't look too good, lots of depolarization blockade.

Switching back to 32 celsius and moving on.

Running a big sim (1000 cells)

Raster plot (traces look similar to previous):
file:gif/20190305_075218.png

** Turning off PV5 noise 

To see if we can see EPSPs and IPSPs.

Looks okay:
file:gif/20190305_080208.png


** Adding external inputs to see synchrony

The external inputs existed on 2018-05-09

https://stackoverflow.com/questions/3790671/how-to-in-git-clone-a-remote-github-repository-from-a-specifed-date

	Cloning the repository will give you the entire commit history of all the source code.

	You need only scroll back through git log and find the desired commit on your target date. Running  git checkout SHA where SHA is the commit hash will give you the state of the source code on that date.

	edit:

	git log --since=2010-06-05 --until=2010-06-06 will help narrow it down!

Trying the log

	cd ~ ; mkdir eee_temp ; cd eee_temp ; hg clone ssh://no.neurosim.downstate.edu://u/graham/projects/eee
	git log --since=2018-05-01 --until=2018-05-15

Whoops.  This repo is actually in Mercurial (hg)

https://stackoverflow.com/questions/10545800/clone-an-hg-directory-from-a-particular-date

	(EDIT: My love of revsets has caused me to overlook the obvious answer: hg update --date 2012-04-04 should get you the tipmost revision as of that date.)

	If you have the whole repository cloned already (date specifications don't seem to work with clone), you can do

	hg update --rev "date('< 2012-04-04')"
	If there's a possibility that the repository had multiple heads/branches at the date you want, you'll have to AND in some more conditions to narrow it down to the right changeset:

	hg update --rev "date('< 2012-04-04') and branch(v1.1)"
	Check out hg help revsets and hg help dates for more information.

	Later, if you want to go back to the tip, just

	hg update

So I will try:

	cd ~ ; rm -rf eee_temp ; mkdir eee_temp ; cd eee_temp ; hg clone ssh://no.neurosim.downstate.edu://u/graham/projects/eee ; cd eee

	hg update --date 2018-05-09

	found revision 580 from Wed May 09 10:19:15 2018 -0700
	26 files updated, 0 files merged, 103 files removed, 0 files unresolved

Now to look in cfg.py and netParams.py in this repo...

From cfg_joe.py:

	cfg.secStim  = 'basal_9'#'apical_0'
	cfg.synTime2 = 50
	cfg.synTime3 = 250
	cfg.intervalStim = 10
	cfg.stimNumber2 = 5
	cfg.glutAmp2 = 7.5
	cfg.glutDelay = 1.0

	cfg.Stim_2 = {'loc': 0.5, 'sec': cfg.secStim, 'synMech': ['NMDA','AMPA'], 'start': cfg.synTime2, 'interval': cfg.intervalStim, 'noise': 0.0, 'number': cfg.stimNumber2, 'weight': [cfg.glutAmp2, cfg.glutAmp2], 'delay': cfg.glutDelay}

	cfg.Stim_3 = {'loc': 0.5, 'sec': cfg.secStim, 'synMech': ['NMDA','AMPA'], 'start': cfg.synTime3, 'interval': cfg.intervalStim, 'noise': 0.0, 'number': cfg.stimNumber2, 'weight': [cfg.glutAmp2, cfg.glutAmp2], 'delay': cfg.glutDelay}

From netParams.py:

    if cfg.addNetStim:   
                      
        for nslabel1 in [k for k in dir(cfg) if k.startswith('Stim')]:
            ns1 = getattr(cfg, nslabel1, None) 
            for postPop in plateau:             
                ruleLabel = nslabel1+'->'+postPop
                netParams.connParams[ruleLabel] = {
                    'preConds': {'pop': nslabel1},
                    'postConds': {'pop': postPop},
                    'synMech': ESynMech,                   
                    'weight': cfg.glutAmp2,
                    'synMechWeightFactor':  cfg.ratioapical, 
                    'delay': 1, 
                    'synsPerConn': 2,#numActiveSpines,  
                    'connList': connList,
                    'loc': ns1['loc'], 
                    'sec': ns1['sec']}

Added to cfg.py:

	# Common synaptic input
	cfg.addCommonInput = True

	cfg.delCommonInput = 220  # delay or start
	cfg.numCommonInput = 5    # number
	cfg.intCommonInput = 20   # interval

	cfg.secCommonInput = 'soma'
	cfg.locCommonInput = 0.5
	cfg.wgtCommonInput = 2.0

Added to netParams:

	if cfg.addCommonInput:

	    netParams.stimSourceParams['CommonInput'] = {'type': 'NetStim', 'start': cfg.delCommonInput, 'interval': cfg.intCommonInput, 'number': cfg.numCommonInput}
	                  
	    for postPop in ['PV5_1', 'PV5_3']:             
	        
	        ruleLabel = 'CommonInput->'+postPop
	        netParams.stimTargetParams[ruleLabel] = {
	            'source' : 'CommonInput', 
	            'conds'  : {'pop': postPop}, 
	            'sec'    : cfg.secCommonInput, 
	            'loc'    : cfg.locCommonInput, 
	            'synMech': ['AMPA', 'NMDA'], 
	            'weight' : cfg.wgtCommonInput, 
	            'delay'  : 0.0}

After some fixing, it works, though can't see the inputs with everything else going on.

Committing now and then exploring.

** EEE Meeting

https://docs.google.com/document/d/1lXhpxnmUTK8bgW2MF3YqqnQMPSDJu8oBfiBW0rujywo/edit

Action items for next week

Joe fixes up abstract
Joe adds external input before and during plateaus (look at synchrony)
HPC parameter exploration


* 2019-03-06 -- External common input to cells

** Common input

Coming back to this later.

Working on abstracts for CNS 2019


* 2019-03-08 -- CNS abstract for EEE

Submitted version:

https://docs.google.com/document/d/1KcM9T4cV7p-GoAZsDS54BivaqTFuR-B7laK3gEKRbho/edit

Experiments and modeling of NMDA plateau potentials in cortical pyramidal neurons 

Experiments have shown that application of glutamate near basal dendrites of cortical pyramidal neurons activates AMPA and NMDA receptors, which can result in dendritic plateau potentials: long-lasting depolarizations which spread into the soma, reducing the membrane time constant and bringing the cell closer to the spiking threshold.  Utilizing a morphologically-detailed reconstruction of a Layer 5 pyramidal cell from prefrontal cortex, a Hodgkin-Huxley compartmental model was developed in NEURON.  Synaptic AMPA/NMDA and extrasynaptic NMDA receptor models were placed on basal dendrites to explore plateau potentials.  The properties of the model were tuned to match plateau potentials recorded by voltage-sensitive dye imaging in dendrites and whole-cell patch measurements in somata of prefrontal cortex pyramidal neurons from rat brain slices.  The model was capable of reproducing experimental observations: a threshold for activation of the plateau, saturation of plateau amplitude with increasing glutamate application, depolarization of the soma by approximately 20 mV, and back-propagating action potential amplitude attenuation and time delay.  The model predicted that membrane time constant is shortened during the plateau, that synaptic inputs are more effective during the plateau due to both depolarization and time constant change, the plateau durations are longer when activated by more distal dendritic segments, and that plateau initiation location can be predicted from somatic plateau amplitude.  Dendritic plateaus induced by strong basilar dendrite stimulation can increase population synchrony produced by weak coherent stimulation in apical dendrites.  The morphologically-detailed cell model was simplified while maintaining the observed plateau behavior and then utilized in cortical network models along with a previously-published inhibitory interneuron model.  The network model simulations showed increased synchrony between cells during induced dendritic plateaus. These results support our hypothesis that dendritic plateaus provide a 200-500 ms time window during which a neuron is particularly excitable. At the network level, this predicts that sets of cells with simultaneous plateaus would provide an activated ensemble of responsive cells with increased firing. Synchronously spiking subsets of these cells would then create an embedded ensemble. This embedded ensemble would demonstrate a temporal code, at the same time as the activated (embedded) ensemble showed rate coding.  
 
Peng P Gao1, Joe W Graham2, Wen-Liang Zhou1, Jinyoung Jang1, Sergio L Angulo2, Salvador Dura-Bernal2, Michael L Hines3, William W Lytton2, Srdjan D Antic1
  
1Neuroscience Department, University of Connecticut Health Center, Farmington CT 06030, USA
2Neurosim Lab, Department Physiology & Pharmacology, SUNY Downstate, Brooklyn, NY 11203, USA
3Neuroscience Department, Yale School of Medicine, New Haven, CT 06510, USA


* 2019-03-11 -- CNS abstract for morphology

Submitted version:
https://docs.google.com/document/d/1Ar_K_ShErbP_zHnDSYnGPc3zNNhZ7Nww1uTPu61XybU/edit

Request for oral presentation:
https://docs.google.com/document/d/1Fl3lSeSKfI2tgm5SDnrsQ32A-3J3dwR1_oDOcSNfrJA/edit



The shape of thought: data-driven synthesis of neuronal morphology and the search for fundamental parameters of form

Joe W. Graham
joe.w.graham@gmail.com

Abstract:

Neuronal morphology is critical in the form and function of nervous systems. Morphological diversity in and between populations of neurons contributes to functional connectivity and robust behavior. Morphologically-realistic computational models are an important tool in improving our understanding of nervous systems. Continual improvements in computing make large-scale, morphologically-realistic, biophysical models of nervous systems increasingly feasible. However, reconstructing large numbers of neurons experimentally is not scalable. Algorithmic generation of neuronal morphologies (“synthesis” of “virtual” neurons) holds promise for deciphering underlying patterns in branching morphology as well as meeting the increasing need in computational neuroscience for large numbers of diverse, realistic neurons.

There are many ways to quantify neuronal form, not all are useful. Hillman (1979) proposed that “from the mass of quantitative information available” a small set of “fundamental parameters of form” and their intercorrelations could be measured from reconstructed neurons which could potentially “completely describe” the population. A parameter set completely describing the original data would be useful for classification of neuronal types, exploring embryological development of neurons, and for understanding morphological changes following illness or intervention. Burke et al. (1992) realized that virtual dendritic trees could be generated by stochastic sampling from a set of fundamental parameters (a synthesis model). Persistent differences between the reconstructed and virtual trees guided model refinement. Ascoli et al. (2001) realized entire virtual neurons could be created by synthesizing multiple dendritic trees from a virtual soma. Ascoli et al. implemented the models of Hillman and Burke et al. and made the code and data publicly available. Both groups used the same data set: a population of six fully-reconstructed cat alpha motoneurons. They were able to generate virtual motoneurons that were similar to the reconstructed ones, however, persistent, significant differences remained unexplained.

Exploration of these motoneurons and novel synthesis models led to two major insights into dendritic form. 1) Parameter distributions correlate with local properties, and these correlations must be accounted for in synthesis models. Dendritic diameter is an important local property, correlating with most parameters. 2) Parent branch parameters correlate differently than those of terminal branches, requiring setting a branch’s type before synthesizing it. Inclusion of these findings in a synthesis model produces virtual motoneurons that are far more similar to the reconstructions than previous models and which are statistically indistinguishable across most measures. These findings hold true across a variety of neuronal types, and may constitute a key to the elusive “fundamental parameters of form” for neuronal morphology.

References

Hillman DE. Neuronal shape parameters and substructures as a basis of neuronal form. In: Schmitt FO, Worden FG, editors. The Neurosciences, 4th Study program. Cambridge: MIT Press; 1979, pp. 477–498.
Burke RE, Marks WB, Ulfhake B. A parsimonious description of motoneuron dendritic morphology using computer simulation. J Neurosci. 1992, 12(6), pp. 2403-2416.
Ascoli GA, Krichmar JL, Scorcioni R, et al. Computer generation and quantitative morphometric analysis of virtual neurons. Anat Embryol. 2001, 204, pp. 283-301.


* 2019-03-12 -- Common input and EEE meeting

** EEE Meeting

Agenda:
https://docs.google.com/document/d/1IHby1FeYCav9c2JIifEq5kDkcQ3dAY_jkTuBY09uNqo/edit

Notes:

Discussion

Noise problem: work with e_e
  Bill is adding flags in gfluct mod file to turn off noise
  He’ll push and Joe’ll pull and try out
Y-limits in Netpyne
  Should be an option for setting
  Can also modify figure after produced
Once saving data, can then make nice figures

Action items for next week

Poster outline for CNS / BRAIN 
Try new Gfluct (look into noise problem)
Get HPC running
Joe submits BRAIN abstract today



** Common input

Setting noise to zero so I can see the input.
	cfg.noisePT5 = False #True

Running:
	graham$ cd ~/EEE_network/eee_net ; ./runsim

Reducing NMDA/AMPA weight by half because traces sit well above RMP and never gets near it.

	cfg.NMDAweight      = 0.4 #0.8
	cfg.AMPAweight      = cfg.NMDAweight

Looks better, but I still can't see the common inputs:

	file:nb_gif/20190312_060900.png

Increasing common input weight:

	cfg.wgtCommonInput = 20.0 #2.0

Whoops, had the common input going to non-existent PV pops instead of PT pops:

    for postPop in ['PV5_1', 'PV5_3']:   
    -->
    for postPop in ['PT5_1', 'PT5_3']:   

Reducing weight.

	cfg.wgtCommonInput = 2.0

Adding a second common input not during plateau:

	# Common synaptic input
	cfg.addCommonInput1 = True
	cfg.popCommonInput1 = ['PT5_1', 'PT5_3']

	cfg.secCommonInput1 = 'soma'
	cfg.locCommonInput1 = 0.5
	cfg.wgtCommonInput1 = 4.0
	cfg.delCommonInput1 = 220  # delay or start
	cfg.numCommonInput1 = 5    # number
	cfg.intCommonInput1 = 20   # interval


	cfg.addCommonInput2 = True
	cfg.popCommonInput2 = ['PT5_1', 'PT5_3']

	cfg.secCommonInput2 = 'soma'
	cfg.locCommonInput2 = 0.5
	cfg.wgtCommonInput2 = 4.0
	cfg.delCommonInput2 = 620  # delay or start
	cfg.numCommonInput2 = 5    # number
	cfg.intCommonInput2 = 20   # interval

And in netParams:

	if cfg.addCommonInput2:

	    netParams.stimSourceParams['CommonInput2'] = {'type': 'NetStim', 'start': cfg.delCommonInput2, 'interval': cfg.intCommonInput2, 'number': cfg.numCommonInput2}
	                  
	    for postPop in cfg.popCommonInput2:             
	        
	        ruleLabel = 'CommonInput2->'+postPop
	        netParams.stimTargetParams[ruleLabel] = {
	            'source' : 'CommonInput2', 
	            'conds'  : {'pop': postPop}, 
	            'sec'    : cfg.secCommonInput2, 
	            'loc'    : cfg.locCommonInput2, 
	            'synMech': ['AMPA', 'NMDA'], 
	            'weight' : cfg.wgtCommonInput2, 
	            'delay'  : 0.0}

Reducing NMDA/AMPA weight:

	cfg.NMDAweight      = 0.2 #0.4 #0.8
	cfg.AMPAweight      = cfg.NMDAweight

Looking pretty good.  Turning noise back on.

Reducing exc noise in PT5:

	cfg.PT5_exc_noise_amp = 0.006 #0.0121

And again:

	cfg.PT5_exc_noise_amp = 0.003 #0.0121

Hmmm.  Even when I set noise amp to 0.0, there is still noise...

Setting to zero, running sim, then turning off completely and running.

Zero:
file:gif/20190312_070351.png

Off:
file:gif/20190312_070525.png

So setting the noise amp to zero still ends up with noise. Perhaps it's because of the 
standard deviation of noise, which is not currently a parameter in cfg.py...

Will look into noise later.

** Interesting figure

file:gif/20190312_071642.png

This cell (from PT5_3) doesn't get induced plateaus, just 5 synaptic inputs during and after plateaus
(plats just in PT5_1 and PT5_2), but that's enough to get some spiking during plateau.


** Looking into noise

Noise comes from Gfluct.mod

Maybe it's because the standard deviation of the noise is non-zero...

Aha, that was the problem! Setting the mean conductance to zero still creates noise when the 
standard deviation is non-zero.

Setting mean and std to zero removes the noise.

I should run some batches to explore the effects of the mean and std on Gfluct noise.


* 2019-03-14 -- Batches

** Batches

I need to get batches running smoothly and then maybe even pull my old batch plots
back in.  They made for nice easier comparisons across 2D batch runs.

First I'm going to look in Netpyne documentation for batch info, maybe a template.

http://netpyne.org/tutorial.html#running-batch-simulations-tutorial-8

That's the same way I have batches set up in the repo now. I'm going to set up a batch
varying two params and try running it.

	params['cfg.EEconv'] = [0.0, 3.0, 6.0] # Default 3.0
	params['cfg.IEconv'] = [0.0, 12.0, 24.0] # Default 12.0

It's doing the same thing as it did before: getting hung up before completing all sims.

Turning noise parameters back to default, running sim: it works. Running batch: still gets hung.

I'll commit, push, and ask for Salva's help.

The following should set it up and run the batch from scratch:

cd ~ ; rm -rf eee_temp ; mkdir eee_temp ; cd eee_temp ; git clone https://github.com/Neurosim-lab/EEE_network.git ; cd EEE_network/mod ; nrnivmodl ; cd ../eee_net ; ln -s "../mod/x86_64" x86_64 ; ./runbatch


** Chatting about batches, errors

joe [2:34 PM]
I’m having trouble running Netpyne batches…  They start and get through the first params values, but then it hangs.
I’ve pushed, the following one-liner should end up hanging in the middle of running a batch:
Untitled 
cd ~ ; rm -rf eee_temp ; mkdir eee_temp ; cd eee_temp ; git clone https://github.com/Neurosim-lab/EEE_network.git ; cd EEE_network/mod ; nrnivmodl ; cd ../eee_net ; ln -s "../mod/x86_64" x86_64 ; ./runbatch

billl [2:35 PM]
on comet?

joe [2:36 PM]
@salvadord, would you take a look when you have a chance?
Locally. Just tried running it on `no`, but got a different error I need help on.

billl [2:36 PM]
if having a hang maybe try linebyline to see where hang is -- i would assume at the end but good to check

joe [2:36 PM]
Untitled 
>>> >>> Traceback (most recent call last):
 File "batch.py", line 1, in <module>
  from netpyne import specs
 File "/usr/site/nrniv/local/python/netpyne/netpyne/specs/__init__.py", line 13, in <module>
  from future import standard_library
ModuleNotFoundError: No module named 'future'
Collapse

billl [2:36 PM]
are we uptodate for netpyne on neurosim?
oh future
nuisance - that's for py2 to make more like py3
can you jus tuse py3 or too much hassle
pip install whatever gives 3 or else use anaconda (if we have anaconda2) ...
i'm still pissed at von rossum for making this big mess with 2>3

joe [2:38 PM]
The EEE code should all be py3, I don’t know about Netpyne on neurosim…

billl [2:41 PM]
check it and pls update if needs it

salvadord [2:43 PM]
pip install future

billl [2:44 PM]
need --target
see moh note on 'tech'
but doesnt that mean he's using 2?
or is future for 3 looking forward to 4? :)

joe [2:44 PM]
0.8.1 on neurosim, 0.9.1.3 on development branch of git

mohamed.sherif [2:44 PM]
I am using 2

joe [2:45 PM]
Untitled 
no% pip install future
pip: Command not found.

billl [2:45 PM]
pls update joe ... we have instructions somewhere on how to do? -- `pip install --update netpyne` right?

joe [2:48 PM]
Um, I’m happy to, but I don’t want to break anything.  I should install pip first?
https://pip.pypa.io/en/stable/installing/

mohamed.sherif [2:54 PM]
how about trying a different machine, like pt or zn?
I check pt - pip not there

billl [2:55 PM]
no pip on no?

mohamed.sherif [2:56 PM]
ok - weired - when I do py2env, pip is there
on pt and on zn
py2env - changes some of the enviromnet variables to run python 2

salvadord [3:43 PM]
updated netpyne for py3 on ‘no’ç
need to add `/usr/site/python3/` to PYTHONPATH in  `py3env` alias in /usr/site/nrniv/simctrl/nrnenv.csh — but I don’t have permissions

salvadord [6:12 AM]
@billl - can you make this change in nrnenv.csh?

billl [6:12 AM]
was about to hgshare but noticed that 'no' rebooted somehow???
ok should be shared now -- can pull and push
submitted for BRAIN meeting:  "Experiment and modeling of NMDA plateau potentials in cortical pyramidal neurons William Lytton, Srdjan Antic, Peng Gao, Joseph Graham, Salvador Dura Bernal; Confirmation Number: RZDAMGMMJM Date Submitted: 03/15/2019"

billl [6:16 AM]
do we have a poster penny?

billl [6:41 AM]
"Posters must fit boards that are 4 feet tall by 6 feet wide."  or if we have one that's a little smaller is fine too

salvadord [7:00 AM]
@joe - perhaps better if you use Comet for the sims — I spent a couple hours with don last week helping him get set up, so maybe he can help you
that would also help use up the XSEDE hours before the end of the month

salvadord [7:01 AM]
(I calculated it and even if I run continuously on the max num cores per user from now till the end of the month, I wouldn’t be able to use up all our hours)

billl [7:01 AM]
time for me to calc pi?
(i'm always here to help out with research)

salvadord [7:06 AM]
it was pi’s day ysterday so makes sense


* 2019-03-18 -- Batching, etc.

** Trying a batch on 'no'

The problems I was having before should be fixed by the update to py3

One liner: 

mkdir eee_temp ; cd eee_temp ; git clone https://github.com/Neurosim-lab/EEE_network.git ; cd EEE_network/mod ; nrnivmodl ; cd ../eee_net ; ln -s "../mod/x86_64" x86_64 ; ./runbatch

Hmmm.  I still get the no future module error.

Will try on zn.  

My alias to zn no longer works...


** Fixing aliases

So the aliases that are in ~/.bash_profile still work, but not those in ~/.bashrc

Will copy aliases to bash_profile

Actually the only alias I want from there is qlfix

alias qlfix='qlmanage -r ; qlmanage -r cache ; killall Finder /System/Library/CoreServices/Finder.app'

Copying that over. The sshzn alias must be in my old tcsh profile...

Some useful aliases from my .tcshrc:

	alias hgpush  'hg push ssh://no.neurosim.downstate.edu://u/graham/projects/eee/; sshno "cd projects/eee; hg update"'
	alias hgpull  'hg pull ssh://no.neurosim.downstate.edu://u/graham/projects/eee'
	alias ip      'ipython -i; echo "ipython -i"'
	alias eeeip   'eee; echo "ipython -i setup.py"; ipython -i setup.py'
	alias sshzn   'ssh -t -Y no.neurosim.downstate.edu "ssh -Y zn"'
	alias sshmy   'ssh -t -Y no.neurosim.downstate.edu "ssh -Y my"'
	alias eeetemp 'rm -r eeetemp; mkdir eeetemp; cd eeetemp; hg clone ssh://no.neurosim.downstate.edu//u/graham/projects/eee/; cd eee/sim; echo $PWD'
	alias hgl     'hg log --limit 5'
	alias hgs     'hg status'
	alias nsimstatus 'python /usr/site/nrniv/local/python/nsimrepos.py'
	alias nsimupdate 'python /usr/site/nrniv/local/python/nsimrepos.py update'

Just listing them for future reference.  I'll get the following into bash (translated from tcsh):

	alias sshzn='ssh -t -Y no.neurosim.downstate.edu "ssh -Y zn"'
	alias sshmy='ssh -t -Y no.neurosim.downstate.edu "ssh -Y my"'
	alias nsimstatus='python /usr/site/nrniv/local/python/nsimrepos.py'
	alias nsimupdate='python /usr/site/nrniv/local/python/nsimrepos.py update'

And add that to .bash_profile.

Aliases work now.

** Run batch on zn

Couldn't use the alias to get to zn:

	graham-mac:~ graham$ sshzn
	Warning: No xauth data; using fake authentication data for X11 forwarding.
	@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
	@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @
	@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
	IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!
	Someone could be eavesdropping on you right now (man-in-the-middle attack)!
	It is also possible that a host key has just been changed.
	The fingerprint for the ECDSA key sent by the remote host is
	SHA256:cwQFllPQXPQCAULdRRXujJ5+vO4etSvufqtKlfObhYE.
	Please contact your system administrator.
	Add correct host key in /u/graham/.ssh/known_hosts to get rid of this message.
	Offending ECDSA key in /u/graham/.ssh/known_hosts:5
	  remove with:
	  ssh-keygen -f "/u/graham/.ssh/known_hosts" -R "zn"
	ECDSA host key for zn has changed and you have requested strict checking.
	Host key verification failed.
	Connection to no.neurosim.downstate.edu closed.
	graham-mac:~ graham$ 

Trying to ssh to no and then to zn.  Still no.  Boo.


** Running batch locally

I need to ensure batches complete before moving to HPC

I am going to run the current batch, it probably won't complete.  Afterwards, I will look at 
my old batch setup (inlcuding analysis and figs).

Trying now:

	cd ~ ; rm -rf eee_temp ; mkdir eee_temp ; cd eee_temp ; git clone https://github.com/Neurosim-lab/EEE_network.git ; cd EEE_network/mod ; nrnivmodl ; cd ../eee_net ; ln -s "../mod/x86_64" x86_64 ; ./runbatch

Yeah, same old. The batch has two parameters each with three values. The sims get through the 
frist value of the first parameter, but then it just sits.

I.e., param sets 0_0, 0_1, and 0_2 get run, but not 1_0, 1_1, 1_2, 2_0, 2_1, or 2_2.

Will have to ask about this in the meeting. For now, trying my old batch stuff that worked well.


** Trying old batch routines

Currently using the batch template from the Netpyne tutorial.  Will switch back to my old routines
that used to work.

https://github.com/Neurosim-lab/EEE_singlecell_simplified/blob/master/eee/sim/batch_utils.py
https://github.com/Neurosim-lab/EEE_singlecell_simplified/blob/master/eee/sim/batch_analysis.py


** Update Netpyne first

/Users/graham/Applications/netpyne/
git pull

Checking, and I am on the development branch.

Running a batch again.

	cd ~ ; rm -rf eee_temp ; mkdir eee_temp ; cd eee_temp ; git clone https://github.com/Neurosim-lab/EEE_network.git ; cd EEE_network/mod ; nrnivmodl ; cd ../eee_net ; ln -s "../mod/x86_64" x86_64 ; ./runbatch

No good.

** Removing cfg. from front of params

	params['cfg.EEconv'] = [0.0, 3.0, 6.0] # Default 3.0
	params['cfg.IEconv'] = [0.0, 12.0, 24.0] # Default 12.0

	params['EEconv'] = [0.0, 3.0, 6.0] # Default 3.0
	params['IEconv'] = [0.0, 12.0, 24.0] # Default 12.0

Same problem. Ugh.

Will commit and push and ask for help.


** Exploring batch problem

First to see if running `python batch.py` works instead of ./runbatch

Nope, that doesn't give any output (though it does create the input files)

I think it's time to actually try to run the Netpyne batch tutorial to make sure that works.

http://www.netpyne.org/tutorial.html#running-batch-simulations-tutorial-8

After a break.


* 2019-03-19 -- Batching, EEE meeting

** Meeting

https://docs.google.com/document/d/1Y-P9emA3k5ZoPMYTKsj7AWLVrH8QL_-4BzDCaAcWp-0/edit


** Batching

Trying to run the Netpyne batch tutorial

http://www.netpyne.org/tutorial.html#running-batch-simulations-tutorial-8

Downloaded all files.  Running `python init.py` works.

To run batch, should use:

	mpiexec -np [num_cores] nrniv -python -mpi batch.py

Or:

	mpiexec -np 4 nrniv -python -mpi tut8_batch.py

Didn't complete...  Got almost all the way there, but never ran the last batch sim...

Taking a quick break to install NeuroML (been getting warnings about it):

** Install NeuroML

Warning:

	Note: NeuroML import failed; import/export functions for NeuroML will not be available. 
  	To install the pyNeuroML & libNeuroML Python packages visit: https://www.neuroml.org/getneuroml

Installing directions from here:

  	https://github.com/NeuroML/pyNeuroML

Running:

	pip install pyneuroml

And that seems to have been successful.

Back to batching tutorial.


** Batching tutorial

Saving the following:

	mpiexec -np 4 nrniv -python -mpi tut8_batch.py

To a file: runbatch

Trying to run it:

	graham-mac:netpyne_tut graham$ ./runbatch
	-bash: ./runbatch: Permission denied

Need to allow execution:

	chmod +x runbatch

Now it runs, and NeuroML warning no longer appears.

But, I'm having the same problem as when I run my own batches:
I get outout for the first two values of param1 (0_0, 0_1, 0_2, 1_0, 1_1, 1_2) but not for 
the final value of param1 (don't get: 2_0, 2_1, 2_2)

When I run tut8_analysis.py, I get the following print statements:

	Reading data...
	0 (0, 0)
	... file missing
	1 (0, 1)
	... file missing
	2 (0, 2)
	... file missing
	3 (1, 0)
	... file missing
	4 (1, 1)
	... file missing
	5 (1, 2)
	... file missing
	6 (2, 0)
	... file missing
	7 (2, 1)
	... file missing
	8 (2, 2)
	... file missing
	9 files missing

So it doesn't look like ANY of the files are actually functional.  

** Running batch tutorial on Neurosim machines

Will add tutorial files to EEE dir, commit and push, and try to run on `no` and `zn`

	sshno
	git clone https://github.com/Neurosim-lab/EEE_network.git
	cd EEE_network/batch_tut/
	./runbatch

Still getting the same error as before:

	>>> >>> Traceback (most recent call last):
	  File "tut8_batch.py", line 1, in <module>
	    from netpyne import specs
	  File "/usr/site/nrniv/local/python/netpyne/netpyne/specs/__init__.py", line 13, in <module>
	    from future import standard_library
	ModuleNotFoundError: No module named 'future'

Ugh.

** Trying to install future

Seems to have worked

	no% pip install future
	pip: Command not found.
	no% 
	no% pip3 install future
	Collecting future
	  Downloading https://files.pythonhosted.org/packages/90/52/e20466b85000a181e1e144fd8305caf2cf475e2f9674e797b222f8105f5f/future-0.17.1.tar.gz (829kB)
	    100% |████████████████████████████████| 829kB 743kB/s 
	Building wheels for collected packages: future
	  Running setup.py bdist_wheel for future ... done
	  Stored in directory: /u/graham/.cache/pip/wheels/0c/61/d2/d6b7317325828fbb39ee6ad559dbe4664d0896da4721bf379e
	Successfully built future
	Installing collected packages: future
	Successfully installed future-0.17.1

Trying to runbatch

	ModuleNotFoundError: No module named 'numpy'

I'm not sure it's a good idea for me to keep installing stuff...  Will ask in the meeting.


** Asking Don to run batch

Coming up with a one-liner:

	cd ~ ; rm -rf eee_temp ; mkdir eee_temp ; cd eee_temp ; git clone https://github.com/Neurosim-lab/EEE_network.git ; cd EEE_network/batch_tut ; ./runbatch

And asking and waiting.

	joe [7:25 AM]
	Hey Don, I’m trying to see if I’m the only one with Netpyne batching issues.  Could you run the following one-liner when you have a chance?
	Untitled 
	cd ~ ; rm -rf eee_temp ; mkdir eee_temp ; cd eee_temp ; git clone https://github.com/Neurosim-lab/EEE_network.git ; cd EEE_network/batch_tut ; ./runbatch
	And then let me know if you get output figs for param sets 2_0, 2_1, and 2_2 ?


* 2019-03-20 -- Batching

** Connecting to zn

Problem:

	WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!
	@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
	IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!
	Someone could be eavesdropping on you right now (man-in-the-middle attack)!
	It is also possible that a host key has just been changed.
	The fingerprint for the ECDSA key sent by the remote host is
	SHA256:cwQFllPQXPQCAULdRRXujJ5+vO4etSvufqtKlfObhYE.
	Please contact your system administrator.
	Add correct host key in /u/graham/.ssh/known_hosts to get rid of this message.
	Offending ECDSA key in /u/graham/.ssh/known_hosts:5
	  remove with:
	  ssh-keygen -f "/u/graham/.ssh/known_hosts" -R "zn"
	ECDSA host key for zn has changed and you have requested strict checking.
	Host key verification failed.

Looking at /u/graham/.ssh/known_hosts on no

	no% ssh-keygen -f "/u/graham/.ssh/known_hosts" -R "zn"
	# Host zn found: line 5
	/u/graham/.ssh/known_hosts updated.
	Original contents retained as /u/graham/.ssh/known_hosts.old
	no% 

	no% ssh zn
	The authenticity of host 'zn (138.5.101.136)' can't be established.
	ECDSA key fingerprint is SHA256:cwQFllPQXPQCAULdRRXujJ5+vO4etSvufqtKlfObhYE.
	Are you sure you want to continue connecting (yes/no)? yes
	Warning: Permanently added 'zn' (ECDSA) to the list of known hosts.
	Warning: the ECDSA host key for 'zn' differs from the key for the IP address '138.5.101.136'
	Offending key for IP in /u/graham/.ssh/known_hosts:4
	Are you sure you want to continue connecting (yes/no)? yes
	Welcome to Ubuntu 18.04.2 LTS (GNU/Linux 4.15.0-46-generic x86_64)

	 * Documentation:  https://help.ubuntu.com
	 * Management:     https://landscape.canonical.com
	 * Support:        https://ubuntu.com/advantage

	  System information as of Wed Mar 20 20:01:55 EDT 2019

	  System load:  0.0              Processes:                 537
	  Usage of /:   0.9% of 1.79TB   Users logged in:           1
	  Memory usage: 0%               IP address for enp193s0f0: 138.5.101.136
	  Swap usage:   0%


	 * Canonical Livepatch is available for installation.
	   - Reduce system reboots and improve kernel security. Activate at:
	     https://ubuntu.com/livepatch

	33 packages can be updated.
	0 updates are security updates.

	zn% 

Awesome, I'm in. Trying to run tutorial batch sims.

	zn% mkdir eee_temp ; cd eee_temp ; git clone https://github.com/Neurosim-lab/EEE_network.git ; cd EEE_network/batch_tut ; ./runbatch

	ModuleNotFoundError: No module named 'pandas'

	zn% pip install pandas
	pip: Command not found.
	zn% pip3 install pandas
	pip3: Command not found.

Bill had said it's probably better to install stuff with Conda anyway.

http://docs.continuum.io/anaconda/install/
https://anaconda.org/anaconda/pandas

	zn% conda install -c anaconda pandas

Got a lot of warnings saying files couldn't be deleted because I lack permissions, ending with 
an error:

	ERROR conda.core.link:_execute(568): An error occurred while uninstalling package 'defaults::conda-4.6.8-py37_0'.
	PermissionError(13, 'Permission denied')
	Attempting to roll back.

	Rolling back transaction: done

	[Errno 13] Permission denied: '/usr/site/nrniv/local/python/anaconda3/condabin/conda' -> '/usr/site/nrniv/local/python/anaconda3/condabin/conda.c~'

Will try sudo

Forgot my password. Resetting it here: http://www.neurosimlab.com/user

New password isn't working on zn. Maybe it takes a little while.  Will come back to this.

Well, I'll try to install pip first.  https://anaconda.org/anaconda/pip

	zn% conda install -c anaconda pip 

Still lacking permission.


** Exploring batching

What happens if each param has only one value?  If each has two?  If each has four?

Original

	params['synMechTau2'] = [3.0, 5.0, 7.0]   
	params['connWeight'] = [0.005, 0.01, 0.15]

One value each: 

	params['synMechTau2'] = [3.0] #, 5.0, 7.0]   
	params['connWeight'] = [0.005] #, 0.01, 0.15]

It just ends up sitting here:

	graham-mac:~ graham$ cd ~/EEE_network/batch_tut/ ; ./runbatch
	numprocs=4
	NEURON -- VERSION 7.6.4 master (50728e66) 2018-12-14
	Duke, Yale, and the BlueBrain Project -- Copyright 1984-2018
	See http://neuron.yale.edu/neuron/credits

	Saving batch to tut8_data/tauWeight_batch.json ... 
	Saving batch to tut8_data/tauWeight_batch.json ... 
	Saving batch to tut8_data/tauWeight_batch.json ... 
	Saving batch to tut8_data/tauWeight_batch.json ... 
	(0, 0) (3.0, 0.005)
	synMechTau2 = 3.0
	connWeight = 0.005
	Saving simConfig to tut8_data/tauWeight_0_0_cfg.json ... 
	Submitting job  tut8_data/tauWeight_0_0
	--------------------------------------------------------------------------------
	   Finished submitting jobs for grid parameter exploration   
	--------------------------------------------------------------------------------
	>>> 


* 2019-03-21 -- Batching

** Exploring batch problem

So a 1x1 batch doesn't run.  What about a 2x2?

	params['synMechTau2'] = [3.0, 5.0] #, 7.0]   
	params['connWeight'] = [0.005, 0.01] #, 0.15]

Running:
	
	graham$ cd ~/EEE_network/batch_tut/ ; ./runbatch

It gets through the first three (of four) sims, but then just sits.  Ugh.

I am going to set cfg.verbose to True and look at terminal output.

Wow.  Very verbose.  Looking for problems.

No obvious problems.  Turning off verbose.

** Submitting problem to Netpyne Github

I am going to document the problem and post it as an issue in Github repo.

First, to come up with code that produces the problem.  

I think I'll try to download the tutorial 8 files programatically.

https://www.thegeekstuff.com/2012/07/wget-curl/

My system doesn't have wget, so I will use curl.

	curl -O <URL> (save file with same name as remote in current dir)

	or

	curl -o <output name> <URL> (save file as <output name> in current dir)

Files I need to download:

http://www.netpyne.org/_downloads/11bf4e0a6395bbf144b644269a25b8be/tut8_netParams.py
http://www.netpyne.org/_downloads/07e5be985bfca5ede59f15f8e38eb289/tut8_cfg.py
http://www.netpyne.org/_downloads/473a938270d9e719882bd861fcb1e8b9/tut8_init.py
http://www.netpyne.org/_downloads/a023a2e3de0d562f75dbf29656110821/tut8_batch.py

And I may want to create a file with the following command:

mpiexec -np [num_cores] nrniv -python -mpi batch.py
mpiexec -np 4 nrniv -python -mpi tut8_batch.py

Okay, working on a one-liner to reproduce problem:

cd ~ ;
mkdir netpyne_batch_tut ; 
cd netpyne_batch_tut ; 
curl -O http://www.netpyne.org/_downloads/11bf4e0a6395bbf144b644269a25b8be/tut8_netParams.py ; 
curl -O http://www.netpyne.org/_downloads/07e5be985bfca5ede59f15f8e38eb289/tut8_cfg.py ; 
curl -O http://www.netpyne.org/_downloads/473a938270d9e719882bd861fcb1e8b9/tut8_init.py ; 
curl -O http://www.netpyne.org/_downloads/a023a2e3de0d562f75dbf29656110821/tut8_batch.py ; 
touch runbatch ; 
echo "mpiexec -np 4 nrniv -python -mpi tut8_batch.py" > runbatch ; 
chmod +x runbatch ; 
./runbatch

Actually, I think I'll forget adding the `runbatch` file...

cd ~ ;
mkdir netpyne_batch_tut ; 
cd netpyne_batch_tut ; 
curl -O http://www.netpyne.org/_downloads/11bf4e0a6395bbf144b644269a25b8be/tut8_netParams.py ; 
curl -O http://www.netpyne.org/_downloads/07e5be985bfca5ede59f15f8e38eb289/tut8_cfg.py ; 
curl -O http://www.netpyne.org/_downloads/473a938270d9e719882bd861fcb1e8b9/tut8_init.py ; 
curl -O http://www.netpyne.org/_downloads/a023a2e3de0d562f75dbf29656110821/tut8_batch.py ; 
mpiexec -np 4 nrniv -python -mpi tut8_batch.py

Tested it and it works. I mean, it runs, it doesn't complete all sims.

Posting to Netpyne Github repo as an issue.

https://github.com/Neurosim-lab/netpyne/issues/412

	Not all batch simulations complete #412

	When running a batch of simulations, not all of them complete.

	In the batch tutorial (http://www.netpyne.org/tutorial.html#running-batch-simulations-tutorial-8), for example, there are two parameters varied and three values for each parameter, for a total of 9 simulations. But only the first 6 get run (0_0, 0_1, 0_2, 1_0, 1_1, 1_2) and then the terminal just sits at the Python prompt. (Missing sims 2_0, 2_1, 2_2)

	The following commands should reproduce the problem:

	cd ~ 
	mkdir netpyne_batch_tut 
	cd netpyne_batch_tut 
	curl -O http://www.netpyne.org/_downloads/11bf4e0a6395bbf144b644269a25b8be/tut8_netParams.py 
	curl -O http://www.netpyne.org/_downloads/07e5be985bfca5ede59f15f8e38eb289/tut8_cfg.py 
	curl -O http://www.netpyne.org/_downloads/473a938270d9e719882bd861fcb1e8b9/tut8_init.py 
	curl -O http://www.netpyne.org/_downloads/a023a2e3de0d562f75dbf29656110821/tut8_batch.py 
	mpiexec -np 4 nrniv -python -mpi tut8_batch.py

	The output will appear in a dir called tut8_data. Rasters and traces (.png) for the final three sims will be missing if this reproduces my problem.

Chatting on Slack.  Bill is looking into as well, and updating Neurosim machines so we can 
try it there.


** conda activate py36

Switches to Python 3

joe [6:44 AM]
Error on `no`: ModuleNotFoundError: No module named ‘numpy’

billl [6:44 AM]
did you `conda activate py36` ?
then run python and makes sure can `import numpy`

Craig [6:46 AM]
joined #netpyne.

joe [6:47 AM]
What does `conda activate py36` do?  I’m not familiar with that.  But yeah, it solved the numpy problem.

adamnewton [6:49 AM]
We have two conda environments, one with python 2.7 and one with 3.6, it switches to the python 3.6 one.




* 2019-03-21 -- HPC at SDSC

** Message from Salva

Batch sims on no weren't working.  Need following commands:

salvadord [7:46 AM]
ok got it
ok netpyne working now on no — 1) `py3env` , 2) `conda activate py36`  — @joe


** Using --user and .local

So running `pip install <package name> --user` installs the package into the .local dir in 
home directory.

Subha recommends using this method and only installing needed packages

It looks like we need future, matplotlib_scalebar, and pandas

Will then need to change my Python path to .local instead of local (where Don and I installed)

First adding a new alias to my .bash_profile file

	alias sshc='ssh jwgraham@comet.sdsc.edu'

Looking at my .bashrc file on Comet




	graham-mac:~ graham$ sshc
	Password: 
	Last login: Fri Mar 15 11:24:42 2019 from 184.101.210.88
	Rocks 6.2 (SideWinder)
	Profile built 16:45 08-Feb-2016

	Kickstarted 17:27 08-Feb-2016
	                                                                       
	                      WELCOME TO 
	      __________________  __  _______________
	        -----/ ____/ __ \/  |/  / ____/_  __/
	          --/ /   / / / / /|_/ / __/   / /
	           / /___/ /_/ / /  / / /___  / /
	           \____/\____/_/  /_/_____/ /_/

	*******************************************************************************

	[1] Example Scripts: /share/apps/examples

	[2] Filesystems:

	     (a) Lustre scratch filesystem : /oasis/scratch/comet/$USER/temp_project
	         (Preferred: Scalable large block I/O)
	            *** Meant for storing data required for active simulations
	            *** Not backed up and should not be used for storing data long term
	            *** Periodically clear old data not required for active simulations

	     (b) Compute/GPU node local SSD storage: /scratch/$USER/$SLURM_JOBID
	         (Meta-data intensive jobs, high IOPs)

	     (c) Lustre projects filesystem: /oasis/projects/nsf
	     
	     (d) /home/$USER : Only for source files, libraries, binaries.
	         *Do not* use for I/O intensive jobs.

	[3] Comet User Guide: http://www.sdsc.edu/support/user_guides/comet.html
	******************************************************************************
	[jwgraham@comet-ln3 ~]$ pwd
	/home/jwgraham
	[jwgraham@comet-ln3 ~]$ ls
	EEE_network  local  matlab  netpyne
	[jwgraham@comet-ln3 ~]$ cat .bashrc
	# .bashrc

	# Source global definitions
	if [ -f /etc/bashrc ]; then
	        . /etc/bashrc
	fi

	# User specific aliases and functionsi
	#source /projects/ps-nsg/home/nsguser/.bashrc 
	module purge
	module load gnu
	module load openmpi_ib
	module load gsl

	module load python
	module load scipy

	# update scipy
	# export MODULEPATH=/share/apps/compute/modulefiles/applications:$MODULEPATH
	# module load python/2.7.13
	#export PYTHONPATH=/share/apps/compute/python-2.7.13/lib/python/site-packages:$PYTHONPATH

	#export SITE=/home/lytton/site

	# NEURON 7.5
	export PATH=/projects/ps-nsg/home/nsguser/applications/neuron7.5/installdir/x86_64/bin:$PATH
	#export PATH=/home/salvadord/site/nrniv/local/bin:/projects/ps-nsg/home/nsguser/applications/neuron7.5/installdir/x86_64/bin:$PATH
	#export NEURON_INIT_MPI=0
	#export LIBS=-ldl
	#export CPU=`uname -p`

	#export MODL_INCLUDE=/home/salvadord/site/nrniv/local/mod
	#export HOC_LIBRARY_PATH=/home/salvadord/site/nrniv/local/hoc:/home/salvadord/site/nrniv/simctrl/hoc

	# NEURON 7.5
	#export PYTHONPATH=/projects/ps-nsg/home/nsguser/applications/neuron7.5/installdir/lib/python:$PYTHONPATH
	export PYTHONPATH=/projects/ps-nsg/home/nsguser/applications/neuron7.5/src/nrnpython/lib/python2.7/site-packages:$PYTHONPATH
	#export NEURONHOME=/projects/ps-nsg/home/nsguser/applications/neuron7.5/installdir

	#export PYTHONPATH=/home/jwgraham/local/:/home/jwgraham/local/netpyne:$PYTHONPATH


Changing local to .local (and removing Netpyne addition, Comet should have Netpyne):

	export PYTHONPATH=/home/jwgraham/local/:/home/jwgraham/local/netpyne:$PYTHONPATH

	-->

	#export PYTHONPATH=/home/jwgraham/local/:/home/jwgraham/local/netpyne:$PYTHONPATH
	export PYTHONPATH=/home/jwgraham/.local/:$PYTHONPATH


** Running to see what happens

While connected to Comet (sshc)

To run:
	sbatch runeee

Where runeee is:

	#!/bin/bash 
	#SBATCH --job-name=eee_net_03-25-2019_03
	#SBATCH -A shs100
	#SBATCH -t 0:30:00
	#SBATCH --nodes=1
	#SBATCH --ntasks-per-node=4
	#SBATCH -o eee_net_03-25-2019_03.run
	#SBATCH -e eee_net_03-25-2019_03.err
	#SBATCH --mail-user=joe.w.graham@gmail.com
	#SBATCH --mail-type=end
	#SBATCH --partition=debug
	source ~/.bashrc
	cd /home/jwgraham/EEE_network/eee_net/
	ibrun -np 4 nrniv -python -mpi init.py

Need to remember I'm using the debugginh partition: #SBATCH --partition=debug

Need to delete that line to be in normal operation

First I'll get rid of the old err and run files: eee_net_03-25-2019_03.err and eee_net_03-25-2019_03.run

	rm eee_net_03-25-2019_03*

Now to run it

	[jwgraham@comet-ln3 eee_net]$ sbatch runeee
	Submitted batch job 22101184
	[jwgraham@comet-ln3 eee_net]$ squeue -u jwgraham
	             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
	          22101184     debug eee_net_ jwgraham  R       0:37      1 comet-14-04
	[jwgraham@comet-ln3 eee_net]$ squeue -u jwgraham
	             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
	          22101184     debug eee_net_ jwgraham  R       2:40      1 comet-14-04
	[jwgraham@comet-ln3 eee_net]$ 

Weird, it just keeps running, I thought it would have crashed by now...

But the error and run files showed up.

eee_net_03-25-2019_03.run

	[jwgraham@comet-ln3 eee_net]$ cat eee_net_03-25-2019_03.run
	numprocs=4
	first instance of dp_total_L2
	first instance of dp_total_L5
	--------------------------------------------------------------------------
	An MPI process has executed an operation involving a call to the
	"fork()" system call to create a child process.  Open MPI is currently
	operating in a condition that could result in memory corruption or
	other system errors; your MPI job may hang, crash, or produce silent
	data corruption.  The use of fork() (or system() or other calls that
	create child processes) is strongly discouraged.  

	The process that invoked fork was:

	  Local host:          comet-14-04 (PID 28014)
	  MPI_COMM_WORLD rank: 3

	If you are *absolutely sure* that your application will successfully
	and correctly survive a call to fork(), you may disable this warning
	by setting the mpi_warn_on_fork MCA parameter to 0.
	--------------------------------------------------------------------------

	Reading command line arguments using syntax: python file.py [simConfig=filepath] [netParams=filepath]

	Reading command line arguments using syntax: python file.py [simConfig=filepath] [netParams=filepath]

	Reading command line arguments using syntax: python file.py [simConfig=filepath] [netParams=filepath]
	Note: NeuroML import failed; import/export functions for NeuroML will not be available. 
	  To install the pyNeuroML & libNeuroML Python packages visit: https://www.neuroml.org/getneuroml

	Reading command line arguments using syntax: python file.py [simConfig=filepath] [netParams=filepath]
	Balancing each compartment to -73 mV
	Balancing each compartment to -73 mV
	Balancing each compartment to -73 mV
	Balancing each compartment to -73 mV

	Warning: Could not load netParams from command line path or from default netParams.py

	Warning: Could not load netParams from command line path or from default netParams.py

	Warning: Could not load netParams from command line path or from default netParams.py
	  Number of cells on node 1: 0 
	  Number of connections on node 1: 0 
	  Number of stims on node 1: 0 

	Warning: Could not load netParams from command line path or from default netParams.py
	  Number of cells on node 3: 0 
	  Number of connections on node 3: 0 
	  Number of stims on node 3: 0 

	Creating network of 0 cell populations on 4 hosts...
	  Number of cells on node 0: 0 
	  Done; cell creation time = 0.00 s.
	Making connections...
	  Number of connections on node 0: 0 
	  Done; cell connection time = 0.00 s.
	  Number of stims on node 0: 0 
	  Done; cell stims creation time = 0.00 s.
	  Number of cells on node 2: 0 
	  Number of connections on node 2: 0 
	  Number of stims on node 2: 0 

	Running simulation for 1000 ms...
	  Done; run time = 0.01 s; real-time ratio: 67.08.

	Gathering data...
	  Done; gather time = 0.00 s.

	Analyzing...
	  Cells: 0
	  Connections: 0 (0.00 per cell)
	  Spikes: 0 (0.00 Hz)
	  Simulated time: 1.0 s; 4 workers
	  Run time: 0.01 s

	Gathering data...
	[jwgraham@comet-ln3 eee_net]$

Since all the numbers are 0, obviously it didn't work, probably frozen.

Looking at error file.

eee_net_03-25-2019_03.err

	[jwgraham@comet-ln3 eee_net]$ cat eee_net_03-25-2019_03.err 
	Unloading compiler-dependent module mkl/11.1.2.144
	Unloading compiler-dependent module gsl/2.1
	Unloading compiler-dependent module openmpi_ib/1.8.4
	NEURON -- VERSION 7.5 master (6b4c19f) 2017-09-25
	Duke, Yale, and the BlueBrain Project -- Copyright 1984-2016
	See http://neuron.yale.edu/neuron/credits

	Additional mechanisms from files
	 ampa.mod Cad.mod CaDynamics_E2.mod cadyn.mod Ca_HVA.mod ca.mod canin.mod CaT.mod gabaa.mod gabab.mod Gfluctp.mod glutamate.mod hin.mod h_kole.mod h_migliore.mod Ih.mod IKsin.mod IL.mod kadist.mod kapin.mod kaprox.mod kBK.mod kctin.mod kdrin.mod kv.mod MyExp2SynBB.mod nafx.mod na.mod NMDAeee.mod NMDAmajor.mod NMDA.mod PlateauConductance.mod SK_E2.mod vecstim.mod vmax.mod
	>>> >>> >>> 


	[comet-14-04.sdsc.edu:28009] 3 more processes have sent help message help-mpi-runtime.txt / mpi_init:warn-fork
	[comet-14-04.sdsc.edu:28009] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
	[jwgraham@comet-ln3 eee_net]$ 

** Whoops

I modified .bashrc but didn't reload the terminal.  Will cancel job and reconnect to Comet.

	[jwgraham@comet-ln3 ~]$ squeue -u jwgraham
	             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
	          22101184     debug eee_net_ jwgraham  R      24:01      1 comet-14-04
	[jwgraham@comet-ln3 ~]$ 
	[jwgraham@comet-ln3 ~]$ scancel 22101184
	[jwgraham@comet-ln3 ~]$ 
	[jwgraham@comet-ln3 ~]$ squeue -u jwgraham
	             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
	[jwgraham@comet-ln3 ~]$

Reconnecting, deleting err and run files, and running.

	graham-mac:~ graham$ sshc
	[jwgraham@comet-ln2 ~]$ cd EEE_network/eee_net
	[jwgraham@comet-ln2 eee_net]$ ls
	batch.py    cfg.py   eee_net_03-25-2019_03.err	init.py       netParams.pyc  runbatch  runsim
	cfg_old.py  cfg.pyc  eee_net_03-25-2019_03.run	netParams.py  output	     runeee    x86_64
	[jwgraham@comet-ln2 eee_net]$ rm eee_net_0*
	[jwgraham@comet-ln2 eee_net]$ ls
	batch.py  cfg_old.py  cfg.py  cfg.pyc  init.py	netParams.py  netParams.pyc  output  runbatch  runeee  runsim  x86_64
	[jwgraham@comet-ln2 eee_net]$ 
	[jwgraham@comet-ln2 eee_net]$ sbatch runeee
	Submitted batch job 22104710
	[jwgraham@comet-ln2 eee_net]$ squeue -u jwgraham
	             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
	[jwgraham@comet-ln2 eee_net]$ 
	[jwgraham@comet-ln2 eee_net]$ ls
	batch.py    cfg.py   eee_net_03-25-2019_03.err	init.py       netParams.pyc  runbatch  runsim
	cfg_old.py  cfg.pyc  eee_net_03-25-2019_03.run	netParams.py  output	     runeee    x86_64
	[jwgraham@comet-ln2 eee_net]$ 
	[jwgraham@comet-ln2 eee_net]$ cat eee_net_03-25-2019_03.run 
	numprocs=4
	[jwgraham@comet-ln2 eee_net]$ 
	[jwgraham@comet-ln2 eee_net]$ cat eee_net_03-25-2019_03.err
	Unloading compiler-dependent module mkl/11.1.2.144
	Unloading compiler-dependent module gsl/2.1
	Unloading compiler-dependent module openmpi_ib/1.8.4
	NEURON -- VERSION 7.5 master (6b4c19f) 2017-09-25
	Duke, Yale, and the BlueBrain Project -- Copyright 1984-2016
	See http://neuron.yale.edu/neuron/credits

	Additional mechanisms from files
	 ampa.mod Cad.mod CaDynamics_E2.mod cadyn.mod Ca_HVA.mod ca.mod canin.mod CaT.mod gabaa.mod gabab.mod Gfluctp.mod glutamate.mod hin.mod h_kole.mod h_migliore.mod Ih.mod IKsin.mod IL.mod kadist.mod kapin.mod kaprox.mod kBK.mod kctin.mod kdrin.mod kv.mod MyExp2SynBB.mod nafx.mod na.mod NMDAeee.mod NMDAmajor.mod NMDA.mod PlateauConductance.mod SK_E2.mod vecstim.mod vmax.mod
	Traceback (most recent call last):
	  File "init.py", line 14, in <module>
	Traceback (most recent call last):
	  File "init.py", line 14, in <module>
	Traceback (most recent call last):
	  File "init.py", line 14, in <module>
	Traceback (most recent call last):
	  File "init.py", line 14, in <module>
	    from netpyne import sim
	    from netpyne import sim
	ImportError: No module named netpyne
	>>>     from netpyne import sim
	ImportError: No module named netpyne
	ImportError: No module named netpyne
	>>> 

	>>> 
	    from netpyne import sim
	ImportError: No module named netpyne
	>>> 
	[jwgraham@comet-ln2 eee_net]$


Looking at err file:

	ImportError: No module named netpyne

Perfect, now to install netpyne and try again.


** Installing Netpyne

http://www.netpyne.org/install.html#install-via-pip-development-version

	Install via pip (development version)
	This will install the version in the github “development” branch – it will include some of the latest enhancements and bug fixes, but could also include temporary bugs:

	git clone https://github.com/Neurosim-lab/netpyne.git
	cd netpyne
	git checkout development
	pip install -e .
	pip will add a symlink in the default python packages folder to the cloned netpyne folder (so you don’t need to modify PYTHONPATH). If new changes are available just need to pull from cloned netpyne repo.

Making a .local dir in home dir, installing netpyne there

Tried that, and it didn't work... Failed with this:

	OSError: [Errno 13] Permission denied: '/opt/python/lib/python2.7/site-packages/matplotlib_scalebar'

Installed matplotlib_scalebar without error:

	pip install matplotlib-scalebar --user

Tried again to install Netpyne development branch, failed with:

    error: could not create '/opt/python/lib/python2.7/site-packages/_thread': Permission denied

Tried to install default Netpyne:

	pip install netpyne --user

Was successful:

	Successfully installed future-0.17.1 netpyne-0.9.1.3 pandas-0.16.2 python-dateutil-2.4.2

Now to try running on Comet again.


** Running sim

[jwgraham@comet-ln2 eee_net]$ rm eee_net_03-25-2019_03.*
[jwgraham@comet-ln2 eee_net]$ sbatch runeee

Just keeps running, will cancel job

Looking at error and run files, I think I need to make sure all files run.

python cfg.py --> works
python netParams.py --> crashes

	  File "netParams.py", line 88, in <module>
	    'g_e0' : 0.0121 * cfg.PV5_exc_noise_amp, 
	AttributeError: 'SimConfig' object has no attribute 'PV5_exc_noise_amp'

Crap.  The config file was somehow cut off...

Ahh.  The config file Don sent was cut off.  I'm going to git checkout cfg.py and then make Don's changes
by hand (instead of copying and pasting his file).

The diff:

	diff --git a/eee_net/cfg.py b/eee_net/cfg.py
	index 496c826..9f78fca 100644
	--- a/eee_net/cfg.py
	+++ b/eee_net/cfg.py
	@@ -3,7 +3,7 @@ import numpy as np
	 
	 # Show figures? Save figures?
	 showFig = False
	-saveFig = True
	+saveFig = False
	 
	 # Simulation options
	 cfg = specs.SimConfig()       
	@@ -11,9 +11,11 @@ cfg.duration = 1000
	 cfg.dt = 0.025                
	 cfg.verbose = False           
	 cfg.recordStep = 1             
	-cfg.simLabel = 'eee_net'
	-cfg.saveFolder = 'output'
	-cfg.savePickle = False         
	+cfg.simLabel = 'eee_net_20190325'
	+cfg.saveFolder = 'data'
	+cfg.savePickle = False
	+cfg.saveJson = True
	+cfg.saveDataInclude = ['simData', 'simConfig', 'netParams', 'net']         
	 cfg.saveMat = False
	 cfg.seeds = {'conn': 4123,
	                         'stim': 1234, 

Now to try netParams ... aaand it works.  Cool.  Now to try running sim.


** Running sim

It runs!  But it has trouble with the plotting.  I'll have to turn that off next.

*** Output

	[jwgraham@comet-ln2 eee_net]$ cat eee_net_03-25-2019_03.run 
	numprocs=4
	first instance of dp_total_L2
	first instance of dp_total_L5
	--------------------------------------------------------------------------
	An MPI process has executed an operation involving a call to the
	"fork()" system call to create a child process.  Open MPI is currently
	operating in a condition that could result in memory corruption or
	other system errors; your MPI job may hang, crash, or produce silent
	data corruption.  The use of fork() (or system() or other calls that
	create child processes) is strongly discouraged.  

	The process that invoked fork was:

	  Local host:          comet-14-01 (PID 20662)
	  MPI_COMM_WORLD rank: 3

	If you are *absolutely sure* that your application will successfully
	and correctly survive a call to fork(), you may disable this warning
	by setting the mpi_warn_on_fork MCA parameter to 0.
	--------------------------------------------------------------------------

	Reading command line arguments using syntax: python file.py [simConfig=filepath] [netParams=filepath]

	Reading command line arguments using syntax: python file.py [simConfig=filepath] [netParams=filepath]

	Reading command line arguments using syntax: python file.py [simConfig=filepath] [netParams=filepath]
	Note: NeuroML import failed; import/export functions for NeuroML will not be available. 
	  To install the pyNeuroML & libNeuroML Python packages visit: https://www.neuroml.org/getneuroml

	Reading command line arguments using syntax: python file.py [simConfig=filepath] [netParams=filepath]
	Balancing each compartment to -73 mV
	Balancing each compartment to -73 mV
	Balancing each compartment to -73 mV
	Balancing each compartment to -73 mV

	Creating network of 5 cell populations on 4 hosts...
	  Number of cells on node 0: 25 
	  Done; cell creation time = 0.11 s.
	Making connections...
	  Number of cells on node 2: 25 
	  Number of cells on node 3: 25 
	  Number of cells on node 1: 25 
	  Number of connections on node 1: 600 
	  Number of synaptic contacts on node 1: 1080 
	  Number of connections on node 0: 600 
	  Number of synaptic contacts on node 0: 1080 
	  Number of connections on node 2: 600 
	  Number of synaptic contacts on node 2: 1080 
	  Number of connections on node 3: 600 
	  Number of synaptic contacts on node 3: 1080 
	  Done; cell connection time = 0.18 s.
	Adding stims...
	  Number of stims on node 1: 760 
	  Number of stims on node 0: 760 
	  Number of stims on node 3: 760 
	  Done; cell stims creation time = 0.15 s.
	  Number of stims on node 2: 760 
	Recording 0 traces of 0 types on node 3
	Recording 0 traces of 0 types on node 2
	Recording 0 traces of 0 types on node 1
	Recording 17 traces of 4 types on node 0

	Running simulation for 1000 ms...
	  Done; run time = 17.45 s; real-time ratio: 0.06.

	Gathering data...
	  Done; gather time = 1.23 s.

	Analyzing...
	  Cells: 100
	  Connections: 2460 (24.60 per cell)
	  Synaptic contacts: 7360 (73.60 per cell)
	  Spikes: 983 (9.83 Hz)
	   PT5_1 : 14.100 Hz
	   PT5_2 : 12.850 Hz
	   PT5_3 : 9.500 Hz
	   PT5_4 : 9.500 Hz
	   PV5 : 3.200 Hz
	  Simulated time: 1.0 s; 4 workers
	  Run time: 17.45 s
	Saving output as data/eee_net_20190325.json  ... 
	Finished saving!
	  Done; saving time = 1.44 s.
	Plotting raster...
	There was an exception in plotRaster(): 
	 'DataFrame' object has no attribute 'sort_values' 
	(<type 'exceptions.AttributeError'>, AttributeError("'DataFrame' object has no attribute 'sort_values'",), <traceback object at 0x2aaabf4f14d0>)
	Plotting recorded cell traces ...
	There was an exception in plotTraces(): 
	 no display name and no $DISPLAY environment variable 
	(<class '_tkinter.TclError'>, TclError('no display name and no $DISPLAY environment variable',), <traceback object at 0x2aaabeec0950>)
	Plotting 2D representation of network cell locations and connections...
	There was an exception in plot2Dnet(): 
	 no display name and no $DISPLAY environment variable 
	(<class '_tkinter.TclError'>, TclError('no display name and no $DISPLAY environment variable',), <traceback object at 0x2aaabee14320>)
	Plotting connectivity matrix...
	There was an exception in plotConn(): 
	 no display name and no $DISPLAY environment variable 
	(<class '_tkinter.TclError'>, TclError('no display name and no $DISPLAY environment variable',), <traceback object at 0x2aaabed8dea8>)
	  Done; plotting time = 0.29 s

	Total time = 20.88 s
	[jwgraham@comet-ln2 eee_net]$ 


** Turning off plotting

Now it seems to run to completion and end properly.  :)

The following is in the error output from comet, will ask if anything in it is important:

	[jwgraham@comet-ln2 eee_net]$ cat eee_net_03-25-2019_03.err
	Unloading compiler-dependent module mkl/11.1.2.144
	Unloading compiler-dependent module gsl/2.1
	Unloading compiler-dependent module openmpi_ib/1.8.4
	NEURON -- VERSION 7.5 master (6b4c19f) 2017-09-25
	Duke, Yale, and the BlueBrain Project -- Copyright 1984-2016
	See http://neuron.yale.edu/neuron/credits

	Additional mechanisms from files
	 ampa.mod Cad.mod CaDynamics_E2.mod cadyn.mod Ca_HVA.mod ca.mod canin.mod CaT.mod gabaa.mod gabab.mod Gfluctp.mod glutamate.mod hin.mod h_kole.mod h_migliore.mod Ih.mod IKsin.mod IL.mod kadist.mod kapin.mod kaprox.mod kBK.mod kctin.mod kdrin.mod kv.mod MyExp2SynBB.mod nafx.mod na.mod NMDAeee.mod NMDAmajor.mod NMDA.mod PlateauConductance.mod SK_E2.mod vecstim.mod vmax.mod
	[comet-14-02.sdsc.edu:25021] 3 more processes have sent help message help-mpi-runtime.txt / mpi_init:warn-fork
	[comet-14-02.sdsc.edu:25021] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
	>>> >>> 
	>>> 

	fatal: Not a git repository (or any parent up to mount point /home)
	Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
	>>> 


** Running on normal comet

Had been running it on debug to well, debug.

Need to edit runeee

Changing it from:

	#!/bin/bash 
	#SBATCH --job-name=eee_net_03-25-2019_03
	#SBATCH -A shs100
	#SBATCH -t 0:30:00
	#SBATCH --nodes=1
	#SBATCH --ntasks-per-node=4
	#SBATCH -o eee_net_03-25-2019_03.run
	#SBATCH -e eee_net_03-25-2019_03.err
	#SBATCH --mail-user=joe.w.graham@gmail.com
	#SBATCH --mail-type=end
	#SBATCH --partition=debug
	source ~/.bashrc
	cd /home/jwgraham/EEE_network/eee_net/
	ibrun -np 4 nrniv -python -mpi init.py

to:

	#!/bin/bash 
	#SBATCH --job-name=eee_net_03-25-2019_03
	#SBATCH -A shs100
	#SBATCH -t 0:30:00
	#SBATCH --nodes=1
	#SBATCH --ntasks-per-node=10
	#SBATCH -o eee_net_03-25-2019_03.run
	#SBATCH -e eee_net_03-25-2019_03.err
	#SBATCH --mail-user=joe.w.graham@gmail.com
	#SBATCH --mail-type=end
	source ~/.bashrc
	cd /home/jwgraham/EEE_network/eee_net/
	ibrun -np 4 nrniv -python -mpi init.py

Removed debug line and changed tasks per node to 10

	sbatch runeee

Pending.  In the meantime, I need to get the changes I made to this notebook locally as 
well as the changes I made to files on Comet into the repository.

First to commit on comet.

Then committing locally.  Seems to merge automatically.

Sim is still pending.

Now the next day, job is still pending.


* 2019-03-26 -- EEE meeting and batching on Comet

** EEE Meeting

https://docs.google.com/document/d/15Ijjk15i7lQzm7EXXMGHLm4Rm1ZqFkxGG8I9eoM9jZs/edit


** Salvador posted some things about running on Comet

*** .bashrc file

# .bashrc

# Source global definitions
if [ -f /etc/bashrc ]; then
	. /etc/bashrc
fi

# User specific aliases and functionsi
source /projects/ps-nsg/home/nsguser/.bashrc 
module load gsl

module load python
module load scipy

# update scipy
export MODULEPATH=/share/apps/compute/modulefiles/applications:$MODULEPATH
module load python/2.7.13
export PYTHONPATH=/share/apps/compute/python-2.7.13/lib/python/site-packages:$PYTHONPATH

export SITE=/home/lytton/site

# NEURON 7.5
export PATH=/home/salvadord/site/nrniv/local/bin:/projects/ps-nsg/home/nsguser/applications/neuron7.5/installdir/x86_64/bin:$PATH

export NEURON_INIT_MPI=0
export LIBS=-ldl
export CPU=`uname -p`

export MODL_INCLUDE=/home/salvadord/site/nrniv/local/mod
export HOC_LIBRARY_PATH=/home/salvadord/site/nrniv/local/hoc:/home/salvadord/site/nrniv/simctrl/hoc

# NEURON 7.5
export PYTHONPATH=/projects/ps-nsg/home/nsguser/applications/neuron7.5/installdir/lib/python:$PYTHONPATH
export NEURONHOME=/projects/ps-nsg/home/nsguser/applications/neuron7.5/installdir

export PYTHONPATH=/home/salvadord/site/nrniv/local/python:/home/salvadord/site/nrniv/local/python/netpyne:$PYTHONPATH

alias huc='hg pull; hg up -C'
alias lsl='ls -lrtah'
alias upnp='cd ~/site/nrniv/local/python/netpyne/; git pull; cd ~/m1/sim'
alias sq='squeue -u $USER; squeue -u $USER | wc -l'
alias sqr='squeue -u $USER -t RUNNING; squeue -u $USER -t RUNNING | wc -l'
alias sqrr='squeue -u $USER -t RUNNING --reservation=salva1; squeue -u $USER -t RUNNING --reservation=salva1 | wc -l'
alias sqra='squeue -t RUNNING; squeue -t RUNNING | wc -l'
alias sqp='squeue -u $USER -t PENDING; squeue -u $USER -t PENDING | wc -l' 
alias sqpa='squeue -t PENDING --partition=compute -o "%.18i %.9P %.8j %.8u %.2t %.10M %.6D %R %p"; squeue -t PENDING --partition=compute | wc -l'
alias sdetail='scontrol show job'
alias tarc='tar -zcvf'

*** useful alias to copy from Comet

alias cpcm
scp -r comet.sdsc.xsede.org:///home/salvadord/!:1 !:2


* 2019-03-27 -- Working on Comet

To do:

Run some long sims on Comet
Get batching working on Comet
Run batches 

** Run some long sims on Comet

We have lots of compute time left this month, so I'll set up some long sims to run.

First I'm going to rename `runeee` as `sbatch_sim` and also make a copy named `sbatch_batch` to be used 
to run the batch sims.

So this is sbatch_sim:

	#!/bin/bash 
	#SBATCH --job-name=eee_net_03-25-2019_03
	#SBATCH -A shs100
	#SBATCH -t 0:30:00
	#SBATCH --nodes=1
	#SBATCH --ntasks-per-node=10
	#SBATCH -o eee_net_03-25-2019_03.run
	#SBATCH -e eee_net_03-25-2019_03.err
	#SBATCH --mail-user=joe.w.graham@gmail.com
	#SBATCH --mail-type=end
	source ~/.bashrc
	cd /home/jwgraham/EEE_network/eee_net/
	ibrun -np 4 nrniv -python -mpi init.py

It has hard-coded dates. I'll change them manually for now, but it would be cool to find a programmatic
solution.

I'm going to run a sim for 100,000 ms (100 s).  Currently, we run for 1s and Total time = 20.53 s.  
That would be 33 minutes, with the four cores that used.  So leaving maxtime at 30 min should be fine.  

Modifying config file (also has hardcoded date):

	cfg.duration = 100000
	cfg.simLabel = 'eee_net_20190327'

That should do it.  Committing, pushing, then pulling on Comet and running.

Running:

[jwgraham@comet-ln2 eee_net]$ sbatch sbatch_sim
Submitted batch job 22173818
[jwgraham@comet-ln2 eee_net]$ squeue -u jwgraham
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          22173818   compute eee_net_ jwgraham PD       0:00      2 (Priority)

Okay, it's in the queue.  Now to get batches going.


** Get batching working on Comet

Switching to debug queue to make sure it works.

Adding line to sbatch_batch:

#SBATCH --partition=debug

New sbatch_batch:

	#!/bin/bash 
	#SBATCH --job-name=eee_net_03-27-2019_03_batch
	#SBATCH -A shs100
	#SBATCH -t 0:30:00
	#SBATCH --nodes=1
	#SBATCH --ntasks-per-node=4
	#SBATCH -o eee_net_03-27-2019_03_batch.run
	#SBATCH -e eee_net_03-27-2019_03_batch.err
	#SBATCH --mail-user=joe.w.graham@gmail.com
	#SBATCH --mail-type=end
	#SBATCH --partition=debug
	source ~/.bashrc
	cd /home/jwgraham/EEE_network/eee_net/
	ibrun -np 4 nrniv -python -mpi batch.py

Now looking at Salva's batch file to see how he does it for Comet.

    b.runCfg = {'type': 'hpc_slurm',
    'allocation': 'shs100', # bridges='ib4iflp', comet m1='shs100', comet nsg='csd403'
    #'reservation': 'salva1',
    'walltime': '4:00:00',
    'nodes': 5,
    'coresPerNode': 24,  # comet=24, bridges=28
    'email': 'salvadordura@gmail.com',
    'folder': '/home/salvadord/m1/sim/',  # comet='/salvadord', bridges='/salvi82'
    'script': 'init.py', 
    'mpiCommand': 'ibrun', # comet='ibrun', bridges='mpirun'
    'skip': True}

I'll set mine up thusly:

	b.runCfg = {'type': 'hpc_slurm',
				'allocation': 'shs100', 
				'walltime': '0:30:00',
				'nodes': 1,
				'coresPerNode': 4,
				'email': 'joe.w.graham@gmail.com',
				'folder': '/home/jwgraham/EEE_network/eee_net',
				'script': 'init.py', 
				'mpiCommand': 'ibrun',
				'skip': True}

And try running it.  Committing pushing pulling.

	[jwgraham@comet-ln2 eee_net]$ sbatch sbatch_batch
	Submitted batch job 22187699
	[jwgraham@comet-ln2 eee_net]$ 
	[jwgraham@comet-ln2 eee_net]$ squeue -u jwgraham
	             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
	          22187699     debug eee_net_ jwgraham PD       0:00      1 (None)
	          22173818   compute eee_net_ jwgraham PD       0:00      2 (Priority)

Aaaaand waiting.

Seems to be running:

	[jwgraham@comet-ln2 eee_net]$ squeue -u jwgraham
	             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
	          22173818   compute eee_net_ jwgraham PD       0:00      2 (Priority)
	          22187762   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187763   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187765   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187766   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187768   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187769   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187770   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187771   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187772   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187773   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187774   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187775   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187776   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187777   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187778   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187779   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187780   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187781   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187782   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187783   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187784   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187785   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187786   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187787   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187791   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187792   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187793   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187794   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187795   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187796   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187797   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187798   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187799   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187800   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187801   compute batch_te jwgraham PD       0:00      1 (Priority)
	          22187802   compute batch_te jwgraham PD       0:00      1 (Priority)
	[jwgraham@comet-ln2 eee_net]$ 

Although using it on the debug queue might be a mistake, as Netpyne seems to have farmed it out
to far more cores than the debug queue allows.  Waiting to see.


* 2019-04-01 -- Journal club and working on Comet

** Journal club

Distinct descending motor cortex pathways and their roles in movement

https://www.nature.com/articles/s41586-018-0642-9
https://paperpile.com/view/663a416c-3da7-05e9-9219-0559d53d1698


** Working on Comet

Looking into what happened with my last batch run.

cat eee_net_03-27-2019_03_batch.run

Odd thing near the beginning:

	first instance of dp_total_L2
	first instance of dp_total_L5

The rest of the file looks fine, and the input files were generated:

	ls batch_data
	batch_test_0_0_cfg.json  batch_test_0_2_cfg.json  batch_test_1_1_cfg.json  batch_test_2_0_cfg.json  batch_test_2_2_cfg.json
	batch_test_0_0.err	 batch_test_0_2.err	  batch_test_1_1.err	   batch_test_2_0.err	    batch_test_2_2.err
	batch_test_0_0.run	 batch_test_0_2.run	  batch_test_1_1.run	   batch_test_2_0.run	    batch_test_2_2.run
	batch_test_0_0.sbatch	 batch_test_0_2.sbatch	  batch_test_1_1.sbatch    batch_test_2_0.sbatch    batch_test_2_2.sbatch
	batch_test_0_1_cfg.json  batch_test_1_0_cfg.json  batch_test_1_2_cfg.json  batch_test_2_1_cfg.json  batch_test_batch.json
	batch_test_0_1.err	 batch_test_1_0.err	  batch_test_1_2.err	   batch_test_2_1.err	    batch_test_batchScript.py
	batch_test_0_1.run	 batch_test_1_0.run	  batch_test_1_2.run	   batch_test_2_1.run	    batch_test_netParams.py
	batch_test_0_1.sbatch	 batch_test_1_0.sbatch	  batch_test_1_2.sbatch    batch_test_2_1.sbatch

But there don't seem to be output files.  Looking at the error output.

	cat eee_net_03-27-2019_03_batch.err
	cp: cannot create regular file `batch_data/batch_test_batchScript.py': File exists
	cp: cannot create regular file `batch_data/batch_test_netParams.py': File exists
	[comet-14-01.sdsc.edu:27618] 3 more processes have sent help message help-mpi-runtime.txt / mpi_init:warn-fork
	[comet-14-01.sdsc.edu:27618] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages

Doesn't seem to be anything crashing...  Looking into files in the batch_data dir.

	cat batch_test_0_0.err
	Unloading compiler-dependent module mkl/11.1.2.144
	Unloading compiler-dependent module gsl/2.1
	Unloading compiler-dependent module openmpi_ib/1.8.4


	**********************************************************

	Open MPI does not support recursive

	**********************************************************

	Open MPI does not support recursive

	***************************************************

	**********************************************************

	Open MPI does not support recursive calls of orterun

	**********************************************************

The .run files all seem to be empty...

I did run this on the debug queue.  I'm going to try running it normally and see what we get for output.


** Running batch on normal queue

Updating batch.py

	# Set output folder, grid method (all param combinations), and run configuration
	b.batchLabel = 'batch_test_20190401'
	b.saveFolder = 'batch_data_20190401'
	b.method = 'grid'
	b.runCfg = {'type': 'hpc_slurm',
				'allocation': 'shs100', 
				'walltime': '0:30:00',
				'nodes': 1,
				'coresPerNode': 24,
				'email': 'joe.w.graham@gmail.com',
				'folder': '/home/jwgraham/EEE_network/eee_net',
				'script': 'init.py', 
				'mpiCommand': 'ibrun',
				'skip': True}

Wondering if I even need an sbatch file if I'm running a batch...  It seems like Netpyne might handle it all?

Modifying sbatch_batch

Deleting debuq queue line: #SBATCH --partition=debug

Update:

	#!/bin/bash 
	#SBATCH --job-name=eee_net_20190401_batch
	#SBATCH -A shs100
	#SBATCH -t 0:30:00
	#SBATCH --nodes=1
	#SBATCH --ntasks-per-node=24
	#SBATCH -o eee_net_20190401_batch.run
	#SBATCH -e eee_net_20190401_batch.err
	#SBATCH --mail-user=joe.w.graham@gmail.com
	#SBATCH --mail-type=end
	source ~/.bashrc
	cd /home/jwgraham/EEE_network/eee_net/
	ibrun -np 4 nrniv -python -mpi batch.py

I'm curious if the `ibrun -np 4 etc` sets it to 4 processors?  Will have to ask about this.

In the meantime, committing pushing, pulling to Comet.

Running:

	[jwgraham@comet-ln2 eee_net]$ sbatch sbatch_batch 
	Submitted batch job 22273839

Now to wait for it to finish.


** Looking into long sim I ran 

Looks like it worked fine.  Output data is here:
/home/jwgraham/EEE_network/eee_net/data

	eee_net_20190325.json  
	eee_net_20190327.json

Need to copy output to my local machine to analyze

https://haydenjames.io/linux-securely-copy-files-using-scp/

SCP examples

	Copy file from a remote host to local host SCP example:
	$ scp username@from_host:file.txt /local/directory/
	 

	Copy file from local host to a remote host SCP example:
	$ scp file.txt username@to_host:/remote/directory/
	 

	Copy directory from a remote host to local host SCP example:
	$ scp -r username@from_host:/remote/directory/  /local/directory/
	 

	Copy directory from local host to a remote hos SCP example:
	$ scp -r /local/directory/ username@to_host:/remote/directory/
	 

	Copy file from remote host to remote host SCP example:
	$ scp username@from_host:/remote/directory/file.txt username@to_host:/remote/directory/


I'll copy over the whole dir.

	scp -r jwgraham@comet.sdsc.xsede.org:///home/jwgraham/EEE_network/eee_net/data /Users/graham/EEE_network/eee_net/data

That worked.  Now to figure out how to analyze and plot.


** Plotting sims after the fact

Looking at Salva's tutorial 8 analysis file: http://www.netpyne.org/_downloads/6cc61d30b2a441dc5534db9b58e62a71/tut8_analysis.py

Will get back to analysis.  First I'll try to run Netpyne tutorial 8 (batching).



** Netpyne batch tutorial

Commenting out figure lines in the cfg file.

First to copy over sbatch_batch and rename it sbatch_tut8.  Now to edit.

New version:

	#!/bin/bash 
	#SBATCH --job-name=tut8_batch
	#SBATCH -A shs100
	#SBATCH -t 0:30:00
	#SBATCH --nodes=1
	#SBATCH --ntasks-per-node=24
	#SBATCH -o tut8.run
	#SBATCH -e tut8.err
	#SBATCH --mail-user=joe.w.graham@gmail.com
	#SBATCH --mail-type=end
	source ~/.bashrc
	cd /home/jwgraham/EEE_network/batch_tut/
	ibrun -np 4 nrniv -python -mpi tut8_batch.py

Updating tut8_batch.py:

	b.runCfg = {'type': 'hpc_slurm',
				'allocation': 'shs100', 
				'walltime': '0:30:00',
				'nodes': 1,
				'coresPerNode': 24,
				'email': 'joe.w.graham@gmail.com',
				'folder': '/home/jwgraham/EEE_network/batch_tut',
				'script': 'tut8_init.py', 
				'mpiCommand': 'ibrun',
				'skip': True}

	# b.runCfg = {'type': 'mpi_bulletin', 
	# 			'script': 'tut8_init.py', 
	# 			'skip': True}


That should be it.  Now to commit and run.

Running:

	[jwgraham@comet-ln2 EEE_network]$ cd batch_tut/
	[jwgraham@comet-ln2 batch_tut]$ sbatch sbatch_tut8
	Submitted batch job 22275809

	[jwgraham@comet-ln2 batch_tut]$ squeue -u jwgraham
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          22273839   compute eee_net_ jwgraham PD       0:00      1 (Priority)
          22275809   compute tut8_bat jwgraham PD       0:00      1 (Priority)

Now to wait for that to run.

Back to analyzing the long sim I ran.


** Plotting sims after the fact

Looking at Salva's tutorial 8 analysis file: http://www.netpyne.org/_downloads/6cc61d30b2a441dc5534db9b58e62a71/tut8_analysis.py



* 2019-04-02 -- EEE meeting and working on Comet

** TODO 

Prepare meeting agenda
Fix Netpyne data loading
Analyze and plot completed sims
Analyze and plot batch sims
Get rid of need for password to login to Comet
Add aliases to Comet and home machine


** Current sims

Still pending.  :|


** Analyze and plot completed sims

Looking at Salva's tutorial 8 analysis file: http://www.netpyne.org/_downloads/6cc61d30b2a441dc5534db9b58e62a71/tut8_analysis.py

Turns out the tutorial just loads batches, not individual sim data.

Looking at the Netpyne package reference:
http://www.netpyne.org/reference.html#package-reference

	Saving and loading:

	sim.saveData(filename)
	sim.loadSimCfg(filename)
	sim.loadNetParams(filename)
	sim.loadNet(filename)
	sim.loadSimData(filename)
	sim.loadAll(filename)

Running:

	cd EEE_network/eee_net/data
	ipython
	from netpyne import sim, specs  
	longsim = sim.loadAll('eee_net_20190327.json')

Error:

	Loading file eee_net_20190327.json ... 
	Loading simConfig...
	Loading netParams...
	---------------------------------------------------------------------------
	AttributeError                            Traceback (most recent call last)
	<ipython-input-2-342987761975> in <module>
	----> 1 longsim = sim.loadAll('eee_net_20190327.json')

	~/Applications/netpyne/netpyne/sim/load.py in loadAll(filename, data, instantiate, createNEURONObj)
	    278     loadSimCfg(filename, data=data)
	    279     sim.cfg.createNEURONObj = createNEURONObj  # set based on argument
	--> 280     loadNetParams(filename, data=data)
	    281     if hasattr(sim.cfg, 'compactConnFormat'):
	    282         connFormat = sim.cfg.compactConnFormat

	~/Applications/netpyne/netpyne/sim/load.py in loadNetParams(filename, data, setLoaded)
	    162     if 'net' in data and 'params' in data['net']:
	    163         if setLoaded:
	--> 164             setup.setNetParams(data['net']['params'])
	    165         else:
	    166             return specs.NetParams(data['net']['params'])

	~/Applications/netpyne/netpyne/sim/setup.py in setNetParams(params)
	     94     elif params and isinstance(params, dict):
	     95         params = utils.replaceKeys(params, 'popLabel', 'pop')  # for backward compatibility
	---> 96         sim.net.params = specs.NetParams(params)
	     97     else:
	     98         sim.net.params = specs.NetParams()

	AttributeError: module 'netpyne.sim' has no attribute 'net'


I'll try sim.loadSimData(filename) instead...

	cd EEE_network/eee_net/data
	ipython
	from netpyne import sim, specs  
	longsim = sim.loadSimData('eee_net_20190327.json')

That worked, but nothing is assigned to `longsim` and analysis.function doesn't work...

	analysis.plotRaster()                                                                               
	Plotting raster...
	There was an exception in plotRaster(): 
	 module 'netpyne.sim' has no attribute 'net' 
	(<class 'AttributeError'>, AttributeError("module 'netpyne.sim' has no attribute 'net'"), <traceback object at 0x121498cc8>)

Maybe I need to load the network first...  sim.loadNet(filename)

	cd ~/EEE_network/eee_net/data
	ipython
	from netpyne import sim, specs  
	longsimnet = sim.loadNet('eee_net_20190327.json')

Error:

	Loading file eee_net_20190327.json ... 
	---------------------------------------------------------------------------
	AttributeError                            Traceback (most recent call last)
	<ipython-input-2-9d01245bfe76> in <module>
	----> 1 longsimnet = sim.loadNet('eee_net_20190327.json')

	~/Applications/netpyne/netpyne/sim/load.py in loadNet(filename, data, instantiate, compactConnFormat)
	    179     if not data: data = _loadFile(filename)
	    180     if 'net' in data and 'cells' in data['net'] and 'pops' in data['net']:
	--> 181         if sim.rank == 0:
	    182             sim.timing('start', 'loadNetTime')
	    183             print('Loading net...')

	AttributeError: module 'netpyne.sim' has no attribute 'rank'


** Looking into Netpyne data loading

When using loadAll, Netpyne does the following:

	loadSimCfg
	loadNetParams
	loadNet
	loadSimData

I'll try to run these in order to see what errors pop up.

*** loadSimCfg worked:

	cd ~/EEE_network/eee_net/data; ipython
	from netpyne import sim, specs  
	sim.loadSimCfg('eee_net_20190327.json')
	Loading file eee_net_20190327.json ... 
	Loading simConfig...

*** loadNetParams didn't work:

	sim.loadNetParams('eee_net_20190327.json')

	---------------------------------------------------------------------------
	AttributeError                            Traceback (most recent call last)
	<ipython-input-8-1353a2171b2d> in <module>
	----> 1 sim.loadNetParams('eee_net_20190327.json')

	~/Applications/netpyne/netpyne/sim/load.py in loadNetParams(filename, data, setLoaded)
	    158 #------------------------------------------------------------------------------
	    159 def loadNetParams (filename, data=None, setLoaded=True):
	--> 160     if not data: data = _loadFile(filename)
	    161     print('Loading netParams...')
	    162     if 'net' in data and 'params' in data['net']:

	~/Applications/netpyne/netpyne/sim/load.py in _loadFile(filename)
	     57         return data
	     58 
	---> 59     if hasattr(sim, 'cfg') and sim.cfg.timing: sim.timing('start', 'loadFileTime')
	     60     ext = os.path.basename(filename).split('.')[1]
	     61 

	~/Applications/netpyne/netpyne/sim/utils.py in timing(mode, processName)
	     92     from .. import sim
	     93 
	---> 94     if sim.rank == 0 and sim.cfg.timing:
	     95         if mode == 'start':
	     96             sim.timingData[processName] = time()

	AttributeError: module 'netpyne.sim' has no attribute 'rank'

*** loadNet gets the same error with rank as above

	sim.loadNet('eee_net_20190327.json')
	AttributeError: module 'netpyne.sim' has no attribute 'rank'

*** loadSimData has the same error with rank

	sim.loadNet('eee_net_20190327.json') 
	AttributeError: module 'netpyne.sim' has no attribute 'rank'

*** Possible solutions

Temporary

	1) set sim.rank = 0 
	2) set sim.cfg.timing = False

Permanent

	Add checking for existence of sim.rank in Netpyne

	Some parts of Netpyne code already do this (e.g. line 131 in netpyne/sim/load.py)

	if hasattr(sim, 'rank') and sim.rank == 0 and hasattr(sim, 'cfg') and sim.cfg.timing:
        sim.timing('stop', 'loadFileTime')
        print(('  Done; file loading time = %0.2f s' % sim.timingData['loadFileTime']))


*** Temp solution for now: set sim.cfg.timing = False

Setting timing to false

	cd ~/EEE_network/eee_net/data; ipython
	from netpyne import sim, specs  
	sim.loadSimCfg('eee_net_20190327.json')
	sim.cfg.timing = False
	sim.loadNetParams('eee_net_20190327.json')

	AttributeError: module 'netpyne.sim' has no attribute 'net'

Hmmm.  Maybe I need to load the net before the netParams?

	cd ~/EEE_network/eee_net/data; ipython
	from netpyne import sim, specs  
	sim.loadSimCfg('eee_net_20190327.json')
	sim.cfg.timing = False
	sim.loadNet('eee_net_20190327.json')

Now we're back to the `rank` error...

	--> 181         if sim.rank == 0:
	    182             sim.timing('start', 'loadNetTime')
	    183             print('Loading net...')

	AttributeError: module 'netpyne.sim' has no attribute 'rank'

Perhaps I should fix this in Netpyne.  Will ask in meeting and update Netpyne first.


** Plotting long sim

Just to have a figure for the meeting

	import json
	with open("eee_net_20190327.json", "r") as read_file:
	    data = json.load(read_file)

	V_soma = data['simData']['V_soma']
	time = data['simData']['t']

Hmmm.  V_soma and all the V_dend_#s are empty.

Looks like the problem is that I commented out the plotting, which specified the cells to
record... so no cells got recorded.


** EEE Meeting

https://docs.google.com/document/d/1IYYKPRcUwd6JMRnRQcC3ozayVF0IUbf9r4bTOwTGOeI/edit

Discussion

We got a six month extension for Comet, so still run sims, but not so desperately
EEE should automatically get no-cost extension
Bill is now “distinguished professor”
Srdjan and Bill attend BRAIN meeting
BRAIN posters not scheduled yet
Srdjan will print poster today
Still waiting to hear back from article submission
Remember existence of Comet debug queue
For batch sims, just use `python batch.py`, not sbatch
Crank up number of cells and time (we are on a supercomputer after all)
Test small jobs on Neurosim or debug queue
To run on Neurosim, just need to change a couple lines (MPI vs SLURM)
Try just sim.load instead of sim.loadAll
Make sure cfg.saveCellSecs and cfg.saveCellConns = True
Bill and Srdjan probably miss meeting next week

Action items for next week

Joe updates BRAIN poster today
Joe updates README for eee repo
Analysis and figures to show off 
Big batch exploration



** Getting batch sims running

All of my batch sims are still pending.

Turns out I was double-queueing: no need to run sbatch to start batch sims, because Netpyne
sets up all sbatch files needed.

Instead of `sbatch sbatch_batch` it's now just `python batch.py`

I am going to adjust all filenames for today's date, crank up the number of cells and sim length,
push, and run on Comet.

cfg.simLabel = 'eee_net_20190402'
cfg.duration = 100000           
cfg.numPT5cells = 800
cfg.numPV5cells = 200
cfg.recordCells = {'include': [('PT5_1', 0), ('PT5_2', 0), ('PT5_3', 0), ('PT5_4', 0), ('PV5', 0)]}

Also deleting the file sbatch_batch

Running: cd ~/EEE_network/eee_net ; python batch.py

And waiting.


* 2019-04-03 -- Batching on Comet

** TODO 

Fix Netpyne data loading
Analyze and plot completed sims
Analyze and plot batch sims
Get rid of need for password to login to Comet
Add aliases to Comet and home machine


** Looking at completed batches

Looks like it crashed.  Seems to be because of the recording options.  I'm going to comment out that 
stuff and re-run the sim.  Also need to redo the dates in all the files.

[jwgraham@comet-ln3 eee_net]$ squeue -u jwgraham
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          22329490   compute batch_20 jwgraham PD       0:00      1 (Priority)
          22329491   compute batch_20 jwgraham PD       0:00      1 (Priority)
          22329492   compute batch_20 jwgraham PD       0:00      1 (Priority)
          22329494   compute batch_20 jwgraham PD       0:00      1 (Priority)
          22329495   compute batch_20 jwgraham PD       0:00      1 (Priority)
          22329496   compute batch_20 jwgraham PD       0:00      1 (Priority)
          22329497   compute batch_20 jwgraham PD       0:00      1 (Priority)
          22329498   compute batch_20 jwgraham PD       0:00      1 (Priority)
          22329499   compute batch_20 jwgraham PD       0:00      1 (Priority)

And now waiting for that.

Ugh.  Timed out.

	slurmstepd: *** JOB 22329490 ON comet-26-28 CANCELLED AT 2019-04-04T03:18:47 DUE TO TIME LIMIT ***
	orterun: Forwarding signal 18 to job


* 2019-04-05 -- Batching on Comet

** Increasing time and changing dates

'walltime': '1:30:00',

Submitted at 11:10 am AZ time.

	[jwgraham@comet-ln3 eee_net]$ squeue -u jwgraham
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          22377640   compute batch_20 jwgraham PD       0:00      1 (Priority)
          22377642   compute batch_20 jwgraham PD       0:00      1 (None)
          22377644   compute batch_20 jwgraham PD       0:00      1 (None)
          22377645   compute batch_20 jwgraham PD       0:00      1 (None)
          22377646   compute batch_20 jwgraham PD       0:00      1 (None)
          22377647   compute batch_20 jwgraham PD       0:00      1 (None)
          22377648   compute batch_20 jwgraham PD       0:00      1 (None)
          22377667   compute batch_20 jwgraham PD       0:00      1 (Priority)
          22377670   compute batch_20 jwgraham PD       0:00      1 (None)


* 2019-04-08 -- Batching on Comet

** Downloading apparently successful batch run

scp -r jwgraham@comet.sdsc.xsede.org:///home/jwgraham/EEE_network/eee_net/batch_data_20190405 /Users/graham/EEE_network/eee_net/batch_data_20190405

Looks like the longest runtime was just a bit under 1:30, so that was a good time choice for these 
sims.

01:11:33
01:02:48
00:50:54
00:50:50
00:50:42
00:50:39
00:50:35
00:50:12
00:49:33

** Looking at output data

So no traces were recorded, but spktimes were.  

The output json files average about 150 MB, pretty big, considering there's not even any
traces recorded...

I am going to set up a run which will include a trace from each cell pop.

cfg.recordTraces = {'V_soma': {'sec':'soma', 'loc':0.5, 'var':'v'}}
cfg.recordTraces['V_dend_8'] = {'sec':'basal_8', 'loc':0.5, 'var':'v'}
cfg.recordCells = {'include': [0, 200, 400, 600, 800]}

This may take longer, so I'll increase the timout as well.

Pushing and submitting to Comet.

	[jwgraham@comet-ln3 eee_net]$ squeue -u jwgraham
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          22452692   compute batch_20 jwgraham PD       0:00      1 (None)
          22452694   compute batch_20 jwgraham PD       0:00      1 (None)
          22452695   compute batch_20 jwgraham PD       0:00      1 (None)
          22452697   compute batch_20 jwgraham PD       0:00      1 (None)
          22452698   compute batch_20 jwgraham PD       0:00      1 (None)
          22452699   compute batch_20 jwgraham PD       0:00      1 (None)
          22452700   compute batch_20 jwgraham PD       0:00      1 (None)

Seems like there was an error.  Looking into it.

	Traceback (most recent call last):
	  File "init.py", line 27, in <module>
	    sim.setupRecording()          # setup variables to record (spikes, V traces, etc)
	  File "/home/jwgraham/.local/lib/python2.7/site-packages/netpyne/sim/setup.py", line 264, in setupRecording

	File "/home/jwgraham/.local/lib/python2.7/site-packages/netpyne/sim/utils.py", line 70, in getCellsList
    cellsRecord = utils.getCellsList(sim.cfg.recordCells)+cellsPlot

    File "/home/jwgraham/.local/lib/python2.7/site-packages/netpyne/specs/dicts.py", line 184, in __getitem__
    cellGids.extend(list(sim.net.pops[condition].cellGids))


	>>>     return super(ODict, self).__getitem__(k)
	KeyError: u'include'



It looks like the problem is with the "include" in cfg.recordCells...  Maybe it uses a different
word now?

It looks like the problem is that recordCells should be a list instead of a dict like most of 
the other settings.  See here: http://netpyne.org/reference.html#simulation-configuration

	cfg.recordCells = [0, 200, 400, 600, 800]

Pushing and trying again.

	[jwgraham@comet-ln3 eee_net]$ squeue -u jwgraham
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          22455411   compute batch_20 jwgraham PD       0:00      1 (None)
          22455412   compute batch_20 jwgraham PD       0:00      1 (None)
          22455413   compute batch_20 jwgraham PD       0:00      1 (None)
          22455415   compute batch_20 jwgraham PD       0:00      1 (None)
          22455418   compute batch_20 jwgraham PD       0:00      1 (None)
          22455421   compute batch_20 jwgraham PD       0:00      1 (None)
          22455424   compute batch_20 jwgraham PD       0:00      1 (None)
          22455425   compute batch_20 jwgraham PD       0:00      1 (None)
          22455427   compute batch_20 jwgraham PD       0:00      1 (None)



** Missed some messages on Slack

*** What to record

Salva says to record at least cfg.saveDataInclude['net', 'simData'], in order to be able to plot 
a raster, but he also records simConfig and netParams, because they are small files.

To save space we should also set cfg.saveCellSecs = False and cfg.saveCellConns = False, which I 
will add to my config file now.


	billl [7:08 AM]
	i mean raster data rather than plot ....
	gues it's in the cfg.recordCells
	then if that's only thing ask for that will be all of simData
	if running the same architecture then don't need to save the rest of it mutiple times
	guess just the above and then just `cfg.saveDataInclude = ['simData']` ; so only save that

	salvadord [7:10 AM]
	recordCells is for traces (eg voltage)
	You'd be missing eg the population information

	billl [10:42 AM]
	oh which to just get raster

	salvadord [10:47 AM]
	plotRaster func requires at least `cfg.saveDataInclude['net', 'simData']` , since the plotting options can include eg. ordering by cell yfrac or selecting cells by gids etc

	salvadord [10:52 AM]
	but if you set `cfg.saveCellSecs = False` and cfg.saveCellConns = False` , it will just save the basic metadata of each cell (type, location, etc), which occupies very little... Kbs
	I also think useful to save `simConfig` and `netParams` for each sim, for reproduciblity… and also occupies very little

*** Where to save data

We shouldn't be saving data to home, but to scratch and then moving it

Here's scratch: /oasis/scratch/comet/
Here's longer term: /oasis/projects/nsf/shs100


	billl [7:00 AM]
	ok this is where our account's data goes: 
	/oasis/projects/nsf/shs100
	co$ ls
	ddoherty  jcarre  jwgraham  lytton  msherif  nsguser  salvadord  samnemo  sangulo
	@don @joe -- make sure you're writing to here and not to your home dir
	joe -- from the batch file i got from you looks like you are writing to home

	don [7:02 AM]
	okay. yes, we’ve been writing to home

	salvadord [7:08 AM]
	I also write to home, I think thats fine... you can then move data to the Oasis disk for long term storage

	billl [7:08 AM]
	oh is it faster to write to home?

	salvadord [7:09 AM]
	I believe so

	billl [7:09 AM]
	note that there is also a scratch -- i think those should be faster and won't risk filing up something that would piss people off

	salvadord [7:09 AM]
	We can confirm with subha

	billl [7:10 AM]
	co$ cd /oasis/scratch/comet
	co$ ls salvadord lytton ddoherty jwgraham
	eg for checkpointing
	this is  7 petabytes of 200 GB/second performance storage and 6 petabytes of 100 GB/second durable storage
	faster is limited number of nodes in the "compute" partition have larger SSDs with a total of 1464 GB available in local scratch. They can be accessed by adding the following to the Slurm script:  #SBATCH --constraint="large_scratch"
	but we don't do any checkpointing yet anyway
	what is a globus place? -- acccessible via the Globus endpoint "xsede#comet"
	bbl

	subha [8:58 PM]
	Bill you are right. Writing to scratch is preferred. /oasis/scratch/comet/ . and then you can move the files you want to the /oasis/projects/nsf/shs100.  Writing to home is not a good practice at all and will be caught by sys admins if the load goes high.


** Changing save location on Comet

Here's scratch: /oasis/scratch/comet/
Here's longer term: /oasis/projects/nsf/shs100/jwgraham/

So I need to change the output to the scratch drive and then after each run, transfer the 
output to our longer term storage.

	b.runCfg = {'type': 'hpc_slurm',
				'allocation': 'shs100', 
				'walltime': '2:00:00',
				'nodes': 1,
				'coresPerNode': 24,
				'email': 'joe.w.graham@gmail.com',
				'folder': '/oasis/scratch/comet/', #'/home/jwgraham/EEE_network/eee_net',
				'script': 'init.py', 
				'mpiCommand': 'ibrun',
				'skip': True}

So it should save to scratch.  Once I get one completed, I'll figure out how to scp the output
into the right place.

Pushing to comet to run batch_data_20190408_3

	[jwgraham@comet-ln3 eee_net]$ squeue -u jwgraham
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          22455411   compute batch_20 jwgraham PD       0:00      1 (Priority)
          22455412   compute batch_20 jwgraham PD       0:00      1 (Priority)
          22455413   compute batch_20 jwgraham PD       0:00      1 (Priority)
          22455415   compute batch_20 jwgraham PD       0:00      1 (Priority)
          22455418   compute batch_20 jwgraham PD       0:00      1 (Priority)
          22455421   compute batch_20 jwgraham PD       0:00      1 (Priority)
          22455424   compute batch_20 jwgraham PD       0:00      1 (Priority)
          22455425   compute batch_20 jwgraham PD       0:00      1 (Priority)
          22455427   compute batch_20 jwgraham PD       0:00      1 (Priority)
          22455810   compute batch_20 jwgraham PD       0:00      1 (None)
          22455811   compute batch_20 jwgraham PD       0:00      1 (None)
          22455812   compute batch_20 jwgraham PD       0:00      1 (None)
          22455813   compute batch_20 jwgraham PD       0:00      1 (None)
          22455814   compute batch_20 jwgraham PD       0:00      1 (None)
          22455816   compute batch_20 jwgraham PD       0:00      1 (None)
          22455817   compute batch_20 jwgraham PD       0:00      1 (None)
          22455819   compute batch_20 jwgraham PD       0:00      1 (None)
          22455820   compute batch_20 jwgraham PD       0:00      1 (None)

** Moving stuff from my home dir to our shared space

Here are the dirs I need to transfer:

	[jwgraham@comet-ln3 eee_net]$ ls -lh
	total 371K
	drwxr-xr-x 2 jwgraham shs100    6 Apr  1 17:54 archive
	drwxr-xr-x 2 jwgraham shs100   41 Mar 28 20:53 batch_data
	drwxr-xr-x 2 jwgraham shs100   41 Apr  2 23:54 batch_data_20190401
	drwxr-xr-x 2 jwgraham shs100   42 Apr  3 04:47 batch_data_20190402
	drwxr-xr-x 2 jwgraham shs100   42 Apr  4 02:48 batch_data_20190403
	drwxr-xr-x 2 jwgraham shs100   51 Apr  6 05:06 batch_data_20190405
	drwxr-xr-x 2 jwgraham shs100   42 Apr  8 16:19 batch_data_20190408

So the commands will be:

	mkdir /oasis/projects/nsf/shs100/jwgraham/EEE_network
	mkdir /oasis/projects/nsf/shs100/jwgraham/EEE_network/eee_net

	cp -r /home/jwgraham/EEE_network/eee_net/archive /oasis/projects/nsf/shs100/jwgraham/EEE_network/eee_net/archive

	cp -r /home/jwgraham/EEE_network/eee_net/batch_data /oasis/projects/nsf/shs100/jwgraham/EEE_network/eee_net/batch_data

	cp -r /home/jwgraham/EEE_network/eee_net/batch_data_20190401 /oasis/projects/nsf/shs100/jwgraham/EEE_network/eee_net/batch_data_20190401

	cp -r /home/jwgraham/EEE_network/eee_net/batch_data_20190402 /oasis/projects/nsf/shs100/jwgraham/EEE_network/eee_net/batch_data_20190402

	cp -r /home/jwgraham/EEE_network/eee_net/batch_data_20190403 /oasis/projects/nsf/shs100/jwgraham/EEE_network/eee_net/batch_data_20190403

	cp -r /home/jwgraham/EEE_network/eee_net/batch_data_20190405 /oasis/projects/nsf/shs100/jwgraham/EEE_network/eee_net/batch_data_20190405

	cp -r /home/jwgraham/EEE_network/eee_net/batch_data_20190408 /oasis/projects/nsf/shs100/jwgraham/EEE_network/eee_net/batch_data_20190408

	rm -rf /home/jwgraham/EEE_network/eee_net/archive
	rm -rf /home/jwgraham/EEE_network/eee_net/batch_data
	rm -rf /home/jwgraham/EEE_network/eee_net/batch_data_20190401
	rm -rf /home/jwgraham/EEE_network/eee_net/batch_data_20190402
	rm -rf /home/jwgraham/EEE_network/eee_net/batch_data_20190403
	rm -rf /home/jwgraham/EEE_network/eee_net/batch_data_20190405
	rm -rf /home/jwgraham/EEE_network/eee_net/batch_data_20190408

Done.


** Things to discuss in meeting tomorrow

Work flow

	Naming sims / files
	Running sims
	Getting data
	Analyzing data

Where to edit files?  Locally or on Comet?  

What data to save

	cfg.saveDataInclude = ['simData', 'simConfig', 'netParams', 'net'] 

Where to save data

	Not to home?
	To home and then transfer to oasis?
	There is also a scratch 

How to get data

What data to store

How to analyze data

Problems with Raster plot

what's the sweet spot for number of nodes and tasks/node to get relatively shorter queue wait time?


** Updating the README

I'll update the README with my workflow on Comet



* 2019-04-09 -- Batching on Comet, EEE meeting

** Running sims to scratch drive

From the COMET login screen, I see info about file systems:

	[2] Filesystems:

	     (a) Lustre scratch filesystem : /oasis/scratch/comet/$USER/temp_project
	         (Preferred: Scalable large block I/O)
	            *** Meant for storing data required for active simulations
	            *** Not backed up and should not be used for storing data long term
	            *** Periodically clear old data not required for active simulations

	     (b) Compute/GPU node local SSD storage: /scratch/$USER/$SLURM_JOBID
	         (Meta-data intensive jobs, high IOPs)

	     (c) Lustre projects filesystem: /oasis/projects/nsf
	     
	     (d) /home/$USER : Only for source files, libraries, binaries.
	         *Do not* use for I/O intensive jobs.

So I shouldn't just dump work into scratch, it should go into:

	/oasis/scratch/comet/jwgraham/temp_project

My new runCfg:

	b.runCfg = {'type': 'hpc_slurm',
				'allocation': 'shs100', 
				'walltime': '2:00:00',
				'nodes': 1,
				'coresPerNode': 24,
				'email': 'joe.w.graham@gmail.com',
				'folder': '/oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net', #'/home/jwgraham/EEE_network/eee_net',
				'script': 'init.py', 
				'mpiCommand': 'ibrun',
				'skip': True}

Pushing and running on Comet.

Getting a different squeue output than normal:

	[jwgraham@comet-ln3 eee_net]$ squeue -u jwgraham
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          22462644   compute batch_20 jwgraham CG       0:04      1 comet-15-71
          22462656   compute batch_20 jwgraham PD       0:00      1 (Priority)	

What does CG mean?

Nothing shows up in /oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/, 
instead output still shows up in /home/jwgraham/EEE_network/eee_net/

Need to figure out how to specify output location

Getting an error in the .err file:

	>>> Could not open init.py


So it seems like setting b.runCfg.folder is not the way to set up the output location...

** Changing folder back to home and running batch of sims

And it's already running!

	[jwgraham@comet-ln3 eee_net]$ squeue -u jwgraham
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          22465059   compute batch_20 jwgraham  R       5:26      1 comet-25-13
          22465062   compute batch_20 jwgraham  R       5:26      1 comet-25-14
          22465052   compute batch_20 jwgraham  R       5:33      1 comet-25-11
          22465056   compute batch_20 jwgraham  R       5:33      1 comet-25-12
          22465048   compute batch_20 jwgraham  R       5:38      1 comet-19-38
          22465050   compute batch_20 jwgraham  R       5:38      1 comet-25-02
          22465037   compute batch_20 jwgraham  R       5:40      1 comet-19-34
          22465041   compute batch_20 jwgraham  R       5:40      1 comet-19-35
          22465042   compute batch_20 jwgraham  R       5:40      1 comet-19-36
          22465045   compute batch_20 jwgraham  R       5:40      1 comet-19-37
          22465022   compute batch_20 jwgraham  R       5:50      1 comet-05-30
          22465024   compute batch_20 jwgraham  R       5:50      1 comet-05-38
          22465027   compute batch_20 jwgraham  R       5:50      1 comet-05-49
          22465030   compute batch_20 jwgraham  R       5:50      1 comet-05-60
          22465033   compute batch_20 jwgraham  R       5:50      1 comet-05-62
          22465020   compute batch_20 jwgraham  R       5:58      1 comet-14-69


** Updating README

# EEE_network

## Commands to run sims on Comet

### To run a batch of simulations

1. cd EEE_network/eee_net
2. python batch.py

### To run a single sim

1. cd EEE_network/eee_net
2. sbatch sbatch_sim

## Commands to run sim on Neurosim 

### Steps to run the network simulation:

1. cd ~
2. git clone https://github.com/Neurosim-lab/EEE_network.git
3. cd EEE_network/
4. cd mod
5. nrnivmodl
6. cd ../eee_net
7. ln -s "../mod/x86_64" x86_64
8. ./runsim

### One-liner to run sim from scratch:

cd ~ ; rm -rf eee_temp ; mkdir eee_temp ; cd eee_temp ; git clone https://github.com/Neurosim-lab/EEE_network.git ; cd EEE_network/mod ; nrnivmodl ; cd ../eee_net ; ln -s "../mod/x86_64" x86_64 ; ./runsim



** EEE Meeting

https://docs.google.com/document/d/1XDcS61HzDLXsRI94x9z6_ej27TUd8XBAhI4-ROBXo1o/edit?usp=sharing

*** Discussion notes

When is poster presentation for BRAIN
How to install software for Comet
Default NEURON in comet (7.5) (Salva and Joe)
Install Netpyne locally (Salva and Joe)
Talked about using latest Python, NEURON and Netpyne
Bill is working on this, should have suggestions
Don installed Netpyne saving branch (saves data on the fly)
Don uses default NEURON
Don tried to use py3 on Stampede, had issues with future package
Subha: these should have py3 already
Salva: if you install Netpyne from pip, it will install all dependencies also (if clone from Github repo, need to install deps separately)
Mike Hines: is there a problem with multiple Python compilations in parallel?
Subha: shouldn’t be a problem unless the compilation has been explicitly parallelized
All .pyc files are shared
Work flow
File naming
Joe names by date, has to change names in multiple files
Best practice?
Salva: use version number of netParams (for major changes) e.g. v1, v2, v54
Then underscore batch name (e.g. batch1, batch2)
Make changes in cfg file or in batch.py file
Internal variable for netParams version
Cfg simLabel etc. is overwritten by batch.py settings
   b.batchLabel = 'v54_batch6'
   b.saveFolder = '../data/'+b.batchLabel
Where to save data
Home directory space is shared by all users (hurts others to use too much)
Run to scratch, won’t impact other users
Comet uses NSG’s NEURON
Bill’s paths were originally still pointing to NSG
Subha: purge all modules, do Python install, do NEURON install, then do Netpyne install
b.saveFolder is where to specify scratch drive
Move from scratch to oasis before too long
Temp: /oasis/scratch/comet/user_name/temp_project
Long term: /oasis/projects/nsf/shs100/user_name
shs100 is for this allocation, may have to use another for other projects
What's the sweet spot for number of nodes and tasks/node to get relatively shorter queue wait time?
No magic number
Debug queue is best for small jobs (max time 30 min, don’t wait long)
Subha: join newslist for Comet, will tell about downtime and delays
Push and pull is fine for each batch or sim
Getting and analyzing data
Salva does most analysis locally
On comet, he runs raster plot
Sometime spike histogram, LFP spectrogram
Salva working with Google cloud to start doing analysis online
Histogram/raster
Shouldn’t be a problem -- Salva
Don has problems
Joe tries histograms and rasters today, posts error
May have to install a missing package
Should show up in error
May be a version error with Pandas
https://github.com/Neurosim-lab/netpyne/issues/406


Individual sims on Comet overwrite prior ones (Don)
Can use batch.py to set folders, etc.
Would include all info from cfg.py
Don runs long sims, needs HPC for analysis (e.g. graph analysis)
There are many tools available on XSEDE
Easy to fire up Jupyter notebooks on 
Don will post info
Data to save
cfg.saveDataInclude = ['simData', 'simConfig', 'netParams', 'net']
cfg.saveCellSecs = False
cfg.saveCellConns = False
How to analyze data after the fact?
Salva posts some code
/u/salvadord/Models/m1/analysis/batchAnalysis.py (and others…)

Action items for next week

Bill pulls together HOWTO for custom install on Comet
Don posts info on how to use XSEDE analysis tools
Joe makes histogram on Comet, posts any errors
Salva posts some analysis code for post-sim analysis
Joe runs, analyzes and plots batches of sims
Start Google doc explaining how to do all this stuff


** TODOs from meeting

Set output location in batch.py to scratch
Change filenames to netParams version underscore batch number
Internal variable for netParams version
Set .run and .err files to go to scratch as well
Prepare alias to easily copy from scratch to oasis
Look into analyzing data after the fact


** Set output location in batch.py to scratch

Salva's:

   b.batchLabel = 'v54_batch6'
   b.saveFolder = '../data/'+b.batchLabel

My new:

	b.batchLabel = 'v01_batch01'
	b.saveFolder = '/oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/' + b.batchLabel


** Running a batch

[jwgraham@comet-ln2 eee_net]$ squeue -u jwgraham
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          22489366   compute v01_batc jwgraham PD       0:00      1 (Resources)
          22489369   compute v01_batc jwgraham PD       0:00      1 (Resources)
          22489370   compute v01_batc jwgraham PD       0:00      1 (Resources)
          22489372   compute v01_batc jwgraham PD       0:00      1 (Resources)
          22489374   compute v01_batc jwgraham PD       0:00      1 (Resources)
          22489378   compute v01_batc jwgraham PD       0:00      1 (Resources)
          22489380   compute v01_batc jwgraham PD       0:00      1 (Resources)
          22489382   compute v01_batc jwgraham PD       0:00      1 (Resources)
          22489383   compute v01_batc jwgraham PD       0:00      1 (Resources)
          22489384   compute v01_batc jwgraham PD       0:00      1 (Resources)
          22489385   compute v01_batc jwgraham PD       0:00      1 (Priority)
          22489386   compute v01_batc jwgraham PD       0:00      1 (Priority)
          22489387   compute v01_batc jwgraham PD       0:00      1 (Priority)
          22489388   compute v01_batc jwgraham PD       0:00      1 (Priority)
          22489389   compute v01_batc jwgraham PD       0:00      1 (Priority)
          22489390   compute v01_batc jwgraham PD       0:00      1 (Priority)


* 2019-04-10 -- Batching on Comet, plotting

** Looking at last batch sim

Nothing showed up in eee_net, so moving the output seems to have worked.

Want to move from:

	/oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/v01_batch01

To:

	/oasis/projects/nsf/shs100/jwgraham/EEE_network/eee_net/v01_batch01

Commands: 

	cp -r /oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/v01_batch01 /oasis/projects/nsf/shs100/jwgraham/EEE_network/eee_net/v01_batch01

	rm -rf /oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/v01_batch01

Also to copy it to my local machine to play around with analysis:

	scp -r jwgraham@comet.sdsc.xsede.org:///oasis/projects/nsf/shs100/jwgraham/EEE_network/eee_net/v01_batch01 /Users/graham/EEE_network/eee_net/v01_batch01


** Running batch sim that produces plots

In cfg.py:

	saveFig = True

	cfg.analysis['plotRaster'] = {'orderBy': 'gid', 'orderInverse': True,'saveFig': saveFig, 'labels':'overlay','showFig': showFig} #'timeRange':[0,500], 'popColors': {'PT5':'red','PV5': 'blue'}}

	cfg.analysis['plotTraces'] = {'include': [('PT5_1',0), ('PT5_2', 0), ('PT5_3', 0), ('PT5_4', 0), ('PV5', 0)], 'saveFig': saveFig, 'showFig': showFig, 'ylim': [-80, 30]}  

Pushing to Comet and running.

Whoops, forgot to update the batch number.  Doing that now.

And running: python batch.py

	[jwgraham@comet-ln2 eee_net]$ squeue -u jwgraham
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          22508269   compute v01_batc jwgraham  R       0:15      1 comet-06-72
          22508270   compute v01_batc jwgraham  R       0:15      1 comet-11-26
          22508271   compute v01_batc jwgraham  R       0:15      1 comet-11-33
          22508272   compute v01_batc jwgraham  R       0:15      1 comet-11-35
          22508273   compute v01_batc jwgraham  R       0:15      1 comet-11-38
          22508274   compute v01_batc jwgraham  R       0:15      1 comet-11-41
          22508275   compute v01_batc jwgraham  R       0:15      1 comet-20-28
          22508276   compute v01_batc jwgraham  R       0:15      1 comet-20-31
          22508277   compute v01_batc jwgraham  R       0:15      1 comet-20-32
          22508278   compute v01_batc jwgraham  R       0:15      1 comet-20-35
          22508280   compute v01_batc jwgraham  R       0:15      1 comet-20-36
          22508282   compute v01_batc jwgraham  R       0:15      1 comet-20-57
          22508283   compute v01_batc jwgraham  R       0:15      1 comet-20-58
          22508284   compute v01_batc jwgraham  R       0:15      1 comet-20-61
          22508267   compute v01_batc jwgraham  R       0:45      1 comet-01-50
          22508268   compute v01_batc jwgraham  R       0:45      1 comet-06-40

Looks successful, but there was errors in plotting:

	Plotting raster...
	There was an exception in plotRaster(): 
	 'DataFrame' object has no attribute 'sort_values' 
	(<type 'exceptions.AttributeError'>, AttributeError("'DataFrame' object has no attribute 'sort_values'",), <traceback object at 0x2aaac4a3add0>)
	Plotting recorded cell traces ...
	There was an exception in plotTraces(): 
	 no display name and no $DISPLAY environment variable 
	(<class '_tkinter.TclError'>, TclError('no display name and no $DISPLAY environment variable',), <traceback object at 0x2aaac4a3ab90>)
	  Done; plotting time = 0.53 s

Posting errors in Slack.

** Misc stuff to do

Get rid of password for Comet
Add aliases to Comet and local (squeue, etc.)
Look into Salva's analysis routines


** Get rid of password for Comet

https://www.sdsc.edu/support/user_guides/comet.html

	Please feel free to append your public RSA key to your ~/.ssh/authorized_keys file to enable access from authorized hosts without having to enter your password. Make sure you have a password on the private key on your local machine. You can use ssh-agent or keychain to avoid repeatedly typing the private key password.

https://www.linode.com/docs/security/authentication/use-public-key-authentication-with-ssh/

Ugh.  I'll have to ask someone how to do this.


** Add aliases to Comet and local

Other people's aliases:

	alias huc='hg pull; hg up -C'
	alias lsl='ls -lrtah'
	alias upnp='cd ~/site/nrniv/local/python/netpyne/; git pull; cd ~/m1/sim'
	alias sq='squeue -u $USER; squeue -u $USER | wc -l'
	alias sqr='squeue -u $USER -t RUNNING; squeue -u $USER -t RUNNING | wc -l'
	alias sqrr='squeue -u $USER -t RUNNING --reservation=salva1; squeue -u $USER -t RUNNING --reservation=salva1 | wc -l'
	alias sqra='squeue -t RUNNING; squeue -t RUNNING | wc -l'
	alias sqp='squeue -u $USER -t PENDING; squeue -u $USER -t PENDING | wc -l' 
	alias sqpa='squeue -t PENDING --partition=compute -o "%.18i %.9P %.8j %.8u %.2t %.10M %.6D %R %p"; squeue -t PENDING --partition=compute | wc -l'
	alias sdetail='scontrol show job'
	alias tarc='tar -zcvf'
	alias cpcm scp -r comet.sdsc.xsede.org:///home/salvadord/!:1 !:2

Will get back to this.


* 2019-04-11 -- Batching on Comet, plotting

** Running using Bill's install

Bill's .bashrc:

	# .bashrc

	# Source global definitions
	if [ -f /etc/bashrc ]; then
	        . /etc/bashrc
	fi

	module purge
	export PATH=/home/lytton/anaconda3/bin:/home/lytton/anaconda3/condabin:/home/lytton/nrn/x86_64/bin:/home/lytton/site/bin:/home/lytton/site/scripts:/opt/gnu/gcc/bin:/opt/gsl/2.1/gnu/bin:/opt/ibutils/bin:/opt/openmpi/gnu/ib/bin:/opt/pdsh/bin:/opt/rocks/bin:/opt/rocks/sbin:/opt/sdsc/bin:/opt/sdsc/sbin:/bin:/sbin:/usr/bin:/usr/sbin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/local/sbin:/usr/X11R6/bin
	module load gnu
	module load openmpi_ib
	module load gsl
	module load gnutools/2.69
	# module load gnubase/2.69

	export NEURONHOME=/home/lytton/nrn/share/nrn
	export PYTHONPATH=  # clear it
	export LD_LIBRARY_PATH=/opt/intel/composer_xe_2013_sp1.2.144/compiler/lib/intel64:/home/lytton/anaconda3/lib
	. /home/lytton/anaconda3/etc/profile.d/conda.sh
	conda activate
	export PS1="co$ "
	export PYTHONPATH=/home/lytton/netpyne:/home/lytton/nrn/lib/python:$PYTHONPATH:/home/lytton/site/nrniv/local/python

I'll copy it into my Comet home dir as bashrc_bill
I'll rename my own .bashrc as .bashrc_joe
Then copy bashrc_bill as .bashrc
Then try running a sim.

Locally:
	scp /Users/graham/EEE_network/bashrc_bill jwgraham@comet.sdsc.xsede.org:/home/jwgraham/

On Comet:
	mv .bashrc bashrc_joe
	cp bashrc_bill .bashrc

Now to run a sim.  Modifying batch.py.  Pushing and running.

Got an error when connecting to Comet:

	: command not found
	-bash: /home/jwgraham/.bashrc: line 24: syntax error: unexpected end of file
	-bash-4.1$

Got a copy from Bill:

[jwgraham@comet-ln3 ~]$ cp /home/lytton/.bashrc /home/jwgraham/bashrc_bill_comet
[jwgraham@comet-ln3 ~]$ rm bashrc_bill .bashrc
[jwgraham@comet-ln3 ~]$ cp bashrc_bill_comet .bashrc

Logging into Comet.

Haha!  My [jwgraham@comet-ln3 EEE_network]$  shrunk to  co$

Got an error:

	co$ python batch.py
	Warning: no DISPLAY environment variable.
	--No graphics will be displayed.
	Mechanism AMPA needs to be re-translated.
	It's version 6.2.0 "c" code is incompatible with this neuron version.

Bill helped fix all errors in compiling.

Running a batch:

	co$ cd EEE_network/eee_net
	co$ python batch.py
	co$ squeue -u jwgraham
	             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
	          22547248   compute bill_bat jwgraham PD       0:00      1 (None)
	          22547249   compute bill_bat jwgraham PD       0:00      1 (None)
	          22547250   compute bill_bat jwgraham PD       0:00      1 (None)
	          22547251   compute bill_bat jwgraham PD       0:00      1 (None)
	          22547252   compute bill_bat jwgraham PD       0:00      1 (None)
	          22547253   compute bill_bat jwgraham PD       0:00      1 (None)
	          22547254   compute bill_bat jwgraham PD       0:00      1 (None)
	          22547255   compute bill_bat jwgraham PD       0:00      1 (None)
	          22547256   compute bill_bat jwgraham PD       0:00      1 (None)
	          22547257   compute bill_bat jwgraham PD       0:00      1 (None)
	          22547258   compute bill_bat jwgraham PD       0:00      1 (None)
	          22547260   compute bill_bat jwgraham PD       0:00      1 (None)
	          22547261   compute bill_bat jwgraham PD       0:00      1 (None)
	          22547262   compute bill_bat jwgraham PD       0:00      1 (None)
	          22547263   compute bill_bat jwgraham PD       0:00      1 (None)
	          22547264   compute bill_bat jwgraham PD       0:00      1 (None)

To get to Python 2:

	conda create -n python2 python=2.7 anaconda
	source activate python2

Bill's setup seems to have run successfully.  I'll take a look at the data in a little bit.


* 2019-04-15 -- Batching on Comet, plotting

** Setting up RSA key

So i don't have to type my password into Comet every time.

https://www.cyberciti.biz/faq/how-to-set-up-ssh-keys-on-linux-unix/

	#1: Create the key pair
	On the computer (such as client1.cyberciti.biz), generate a key pair for the protocol.

	ssh-keygen -t rsa

	#2: Install the public key in remote server
	Use scp or ssh-copy-id command to copy your public key file (e.g., $HOME/.ssh/id_rsa.pub) to your account on the remote server/host (e.g., nixcraft@server1.cyberciti.biz). To do so, enter the following command on your client1.cyberciti.biz:

	ssh-copy-id -i $HOME/.ssh/id_rsa.pub user@server1.cyberciti.biz
	OR just copy the public key in remote server as authorized_keys in ~/.ssh/ directory:

	scp $HOME/.ssh/id_rsa.pub user@server1.cyberciti.biz:~/.ssh/authorized_keys

ssh-keygen -t rsa
ssh-copy-id -i $HOME/.ssh/id_rsa.pub jwgraham@comet.sdsc.edu

Okay, that worked.  :)  No more password on Comet.


** Need to set up Comet SSH with display

Changing the alias in my .bash_profile:

alias sshc='ssh -X jwgraham@comet.sdsc.edu'


** Running a batch using Bill's setup

graham-mac:~ graham$ sshc
Warning: untrusted X11 forwarding setup failed: xauth key data not generated

Hmmm.  But when I do:

	ssh -Y jwgraham@comet.sdsc.edu

I get:

	Warning: No xauth data; using fake authentication data for X11 forwarding.

Asking on Slack about best way to do this.

For now I'll change the sshc alias to use -Y

	co$ cd EEE_network/eee_net
	co$ python batch.py
	co$ squeue -u jwgraham
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          22606469   compute bill_bat jwgraham PD       0:00      1 (None)
          22606470   compute bill_bat jwgraham PD       0:00      1 (None)
          22606471   compute bill_bat jwgraham PD       0:00      1 (None)
          22606472   compute bill_bat jwgraham PD       0:00      1 (None)
          22606474   compute bill_bat jwgraham PD       0:00      1 (None)
          22606475   compute bill_bat jwgraham PD       0:00      1 (None)
          22606476   compute bill_bat jwgraham PD       0:00      1 (None)
          22606477   compute bill_bat jwgraham PD       0:00      1 (None)
          22606485   compute bill_bat jwgraham PD       0:00      1 (None)
          22606492   compute bill_bat jwgraham PD       0:00      1 (None)
          22606494   compute bill_bat jwgraham PD       0:00      1 (None)
          22606502   compute bill_bat jwgraham PD       0:00      1 (None)
          22606509   compute bill_bat jwgraham PD       0:00      1 (None)
          22606517   compute bill_bat jwgraham PD       0:00      1 (None)
          22606525   compute bill_bat jwgraham PD       0:00      1 (None)
          22606532   compute bill_bat jwgraham PD       0:00      1 (None)


** I overwrote my RSA key for Neurosim

Need to fix that so I don't need a password there.

But of course I forgot my password.  Requesting a new one:

	http://www.neurosimlab.com/user/password

Needed to ask for password change (website uses diff password).  But got it changed.

Now to get an RSA key working on Neurosim again.

graham-mac:.ssh graham$ ssh-keygen -t rsa
Generating public/private rsa key pair.
Enter file in which to save the key (/Users/graham/.ssh/id_rsa): /Users/graham/.ssh/id_rsa_suny
Enter passphrase (empty for no passphrase): 
Enter same passphrase again: 
Your identification has been saved in /Users/graham/.ssh/id_rsa_suny.
Your public key has been saved in /Users/graham/.ssh/id_rsa_suny.pub.

Then tried two different ways:

	ssh-copy-id -i $HOME/.ssh/id_rsa_suny.pub graham@no.neurosim.downstate.edu

	scp $HOME/.ssh/id_rsa_suny.pub graham@no.neurosim.downstate.edu:~/.ssh/authorized_keys

I still have to use my password...  Will have to try to fix this later.


** Looking into batch analysis

Salva's analysis stuff here:

/u/salvadord/Models/m1/analysis/batchAnalysis.py

cd
scp -r no.neurosim.downstate.edu:///u/salvadord/Models/m1/analysis/ /Users/graham/batch_analysis


* 2019-04-16 -- Batching on Comet, EEE meeting

** Looking into batch analysis

Salva's code is here: /u/salvadord/Models/m1/analysis/



** Copying over data from scratch to long-term

co$ cd /oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/
co$ ls -l
total 138
drwxr-xr-x 3 jwgraham shs100 57856 Apr 11 18:45 bill_batch
drwxr-xr-x 3 jwgraham shs100 41472 Apr 15 10:58 bill_batch_02
drwxr-xr-x 2 jwgraham shs100 41472 Apr 10 08:02 v01_batch02

Commands:

	cp -r /oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/v01_batch02 /oasis/projects/nsf/shs100/jwgraham/EEE_network/eee_net/v01_batch02

	scp -r jwgraham@comet.sdsc.xsede.org:///oasis/projects/nsf/shs100/jwgraham/EEE_network/eee_net/v01_batch02 /Users/graham/EEE_network/eee_net/v01_batch02

	rm -rf /oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/v01_batch02


	cp -r /oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/bill_batch /oasis/projects/nsf/shs100/jwgraham/EEE_network/eee_net/bill_batch

	scp -r jwgraham@comet.sdsc.xsede.org:///oasis/projects/nsf/shs100/jwgraham/EEE_network/eee_net/bill_batch /Users/graham/EEE_network/eee_net/bill_batch

	rm -rf /oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/bill_batch


	cp -r /oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/bill_batch_02 /oasis/projects/nsf/shs100/jwgraham/EEE_network/eee_net/bill_batch_02

	scp -r jwgraham@comet.sdsc.xsede.org:///oasis/projects/nsf/shs100/jwgraham/EEE_network/eee_net/bill_batch_02 /Users/graham/EEE_network/eee_net/bill_batch_02

	rm -rf /oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/bill_batch_02


** Looking at output of sims

Hmmm.  Hard to see much in rasters and traces when the sim lasts 100 seconds.

file:nb_gif/20190416_063243.png


** Setting up shorter sim (2 s)

Pushing to Comet and running.

	co$ squeue -u jwgraham
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          22622953   compute bill_bat jwgraham  R       0:50      1 comet-29-53
          22622954   compute bill_bat jwgraham  R       0:50      1 comet-29-56
          22622955   compute bill_bat jwgraham  R       0:50      1 comet-17-63
          22622956   compute bill_bat jwgraham  R       0:50      1 comet-17-67
          22622957   compute bill_bat jwgraham  R       0:50      1 comet-17-69
          22622936   compute bill_bat jwgraham  R       1:03      1 comet-29-65
          22622938   compute bill_bat jwgraham  R       1:03      1 comet-17-01
          22622939   compute bill_bat jwgraham  R       1:03      1 comet-17-27
          22622941   compute bill_bat jwgraham  R       1:03      1 comet-17-30
          22622943   compute bill_bat jwgraham  R       1:03      1 comet-17-37
          22622948   compute bill_bat jwgraham  R       1:03      1 comet-17-38
          22622951   compute bill_bat jwgraham  R       1:03      1 comet-17-39
          22622952   compute bill_bat jwgraham  R       1:03      1 comet-17-52
          22622932   compute bill_bat jwgraham  R       1:19      1 comet-04-55
          22622934   compute bill_bat jwgraham  R       1:19      1 comet-04-57
          22622935   compute bill_bat jwgraham  R       1:19      1 comet-04-58
          22622928   compute bill_bat jwgraham  R       1:26      1 comet-04-40
          22622931   compute bill_bat jwgraham  R       1:26      1 comet-04-41
          22622986   compute bill_bat jwgraham  R       0:39      1 comet-23-43
          22622988   compute bill_bat jwgraham  R       0:39      1 comet-23-44
          22622968   compute bill_bat jwgraham  R       0:42      1 comet-23-38
          22622975   compute bill_bat jwgraham  R       0:42      1 comet-23-39
          22622982   compute bill_bat jwgraham  R       0:42      1 comet-23-40
          22622961   compute bill_bat jwgraham  R       0:48      1 comet-23-37
          22622958   compute bill_bat jwgraham  R       0:50      1 comet-17-71

Running already.  :)

** Back to own setup

Using Bill's setup didn't produce figures. I'm going to change back to my own setup and run the batch.

co$ rm .bashrc
co$ cp bashrc_joe .bashrc

Changing batch name, pushing and running.

Got an error or warning:

	loading membrane mechanisms from x86_64/.libs/libnrnmech.so
	dlopen failed - 
	x86_64/.libs/libnrnmech.so: undefined symbol: hoc_reg_nmodl_text

We'll see if it works.


             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          22623224   compute v01_batc jwgraham  R       1:15      1 comet-14-68
          22623225   compute v01_batc jwgraham  R       1:15      1 comet-14-72
          22623226   compute v01_batc jwgraham  R       1:15      1 comet-17-67
          22623227   compute v01_batc jwgraham  R       1:15      1 comet-17-69
          22623229   compute v01_batc jwgraham  R       1:15      1 comet-17-71
          22623230   compute v01_batc jwgraham  R       1:15      1 comet-03-20
          22623254   compute v01_batc jwgraham  R       0:41      1 comet-23-46
          22623255   compute v01_batc jwgraham  R       0:41      1 comet-23-47
          22623253   compute v01_batc jwgraham  R       0:43      1 comet-23-44
          22623250   compute v01_batc jwgraham  R       0:47      1 comet-05-06
          22623251   compute v01_batc jwgraham  R       0:47      1 comet-23-43
          22623245   compute v01_batc jwgraham  R       0:51      1 comet-23-37
          22623247   compute v01_batc jwgraham  R       0:51      1 comet-23-38
          22623248   compute v01_batc jwgraham  R       0:51      1 comet-23-39
          22623249   compute v01_batc jwgraham  R       0:51      1 comet-23-40
          22623232   compute v01_batc jwgraham  R       0:58      1 comet-03-24
          22623234   compute v01_batc jwgraham  R       0:58      1 comet-03-57
          22623235   compute v01_batc jwgraham  R       0:58      1 comet-03-62
          22623236   compute v01_batc jwgraham  R       0:58      1 comet-04-41
          22623238   compute v01_batc jwgraham  R       0:58      1 comet-04-53
          22623239   compute v01_batc jwgraham  R       0:58      1 comet-04-55
          22623243   compute v01_batc jwgraham  R       0:58      1 comet-04-58
          22623244   compute v01_batc jwgraham  R       0:58      1 comet-04-60
          22623231   compute v01_batc jwgraham  R       1:15      1 comet-03-22


Looked at the error file, and it's not working and getting huge.  Canceling jobs.

Need to recompile mods to use with different NEURON version, I think.

Switching back to use Bill's setup.

[jwgraham@comet-ln2 ~]$ rm .bashrc 
[jwgraham@comet-ln2 ~]$ cp bashrc_bill_comet .bashrc


** Running short sim on Bill's setup

And adding plotSpikeHist to bill_batch_05

cfg.analysis['plotSpikeHist'] = {'saveFig': saveFig,'showFig': showFig}



* 2019-04-23 -- Aliases and batch analysis


** Adding aliases

*** Local aliases

alias gs='git status'
alias ga='git add -u'
alias gc='git commit -m'
alias gsh='git push'
alias gll='git pull'


*** Comet aliases

ls, cd, and du (disk usage)

For scratch storage:

	alias lssc="echo 'Contents of /oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net:' ; ls -l /oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/"
	alias cdsc="cd /oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/ && echo 'Changed to dir: /oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/'"
	alias dusc="du -h --max-depth=1 /oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/ | sort -k 2"

For longterm storage:

	alias lslt="echo 'Contents of /oasis/projects/nsf/shs100/jwgraham/EEE_network/eee_net/:' ; ls -l /oasis/projects/nsf/shs100/jwgraham/EEE_network/eee_net/"
	alias cdlt="cd /oasis/projects/nsf/shs100/jwgraham/EEE_network/eee_net/ && echo 'Changed to dir: /oasis/projects/nsf/shs100/jwgraham/EEE_network/eee_net/'"
	alias dult="du -h --max-depth=1 /oasis/projects/nsf/shs100/jwgraham/EEE_network/eee_net/ | sort -k 2"

I need an alias to move dirs over from scratch to longterm storage.  

mvlt() {
    if [ -d "/oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/$1" ]; then
        echo "Moving: /oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/$1/"
        mv /oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/$1 /oasis/projects/nsf/shs100/jwgraham/EEE_network/eee_net/
        echo "To    : /oasis/projects/nsf/shs100/jwgraham/EEE_network/eee_net/$1/"
    else
        echo "$1 is not a directory in /oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/"
    fi
}



* 2019-04-24 -- Batch analysis

** Needs for batch analysis

Ensure last batch was good
Load batch data
Analyze data
Plot figures


** Ensure last batch was good

Last batch was bill_batch_05 and it seems to have worked.


** Load batch data

Looking at my old batch analysis code

Copying batch_utils.py and batch_analysis.py from no.neurosim.downstate.edu//u/graham/projects/eee/sim
to EEE_network/eee_net/

Updating the files for Python 3.

Committing now before I make too many changes.

*** Problem with basestring (no longer works in py3):

	~/EEE_network/eee_net/batch_utils.py in readBatchData(dataFolder, batchLabel, loadAll, saveAll, vars, maxCombs, listCombs)
	     74         return params, data
	     75 
	---> 76     if isinstance(listCombs, basestring):
	     77         filename = str(listCombs)
	     78         with open(filename, 'r') as fileObj:

	NameError: name 'basestring' is not defined

Looking into solution.

It looks like I can either rename all 'basestr' as 'str' (which then will only work in py3):

	https://docs.python.org/3.0/whatsnew/3.0.html

	The builtin basestring abstract type was removed. Use str instead. The str and bytes types don’t have functionality enough in common to warrant a shared base class. The 2to3 tool (see below) replaces every occurrence of basestring with str.

Or I can try to make it py2 and py3 compatible with:

https://stackoverflow.com/questions/11301138/how-to-check-if-variable-is-string-with-python-2-and-3-compatibility

	The most terse approach I've found without relying on packages like six, is:

		try:
		  basestring
		except NameError:
		  basestring = str
	
	then, assuming you've been checking for strings in Python 2 in the most generic manner,

		isinstance(s, basestring)
	
	will now also work for Python 3+.

I'll try the second option.  

It worked.

*** The data is not being loaded

Output of running dev.py:

	ipython -i dev.py
	Reading data...
	25 files missing

Looking into solution.  First committing py2/3 compatibility changes.

Got rid of try/except in batch_utils readBatchData, and got this error:

	~/EEE_network/eee_net/batch_utils.py in readBatchData(dataFolder, batchLabel, loadAll, saveAll, vars, maxCombs, listCombs)
	    110                 outFile = b['saveFolder']+'/'+simLabel+'.json'
	    111                 # try:
	--> 112                 with open(outFile, 'r') as fileObj:
	    113                     output = json.load(fileObj, object_pairs_hook=specs.OrderedDict)
	    114 

	FileNotFoundError: [Errno 2] No such file or directory: '/oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/bill_batch_05/bill_batch_05_0_0.json'

So the problem is that the files have been moved from scratch to my local machine, and are 
no longer at b['saveFolder']

Looking into what's all in b 

	In [1]: b                                                                                                
	Out[1]: 
	{'batchLabel': 'bill_batch_05',
	 'cfgFile': 'cfg.py',
	 'evolCfg': {'fitnessFunc': 'removed'},
	 'initCfg': {},
	 'method': 'grid',
	 'netParamsFile': 'netParams.py',
	 'params': [{'label': 'EEconv', 'values': [0.0, 1.5, 3.0, 4.5, 6.0]},
	  {'label': 'IEconv', 'values': [0.0, 6.0, 12.0, 18.0, 24.0]}],
	 'runCfg': {'allocation': 'shs100',
	  'coresPerNode': 24,
	  'email': 'joe.w.graham@gmail.com',
	  'folder': '/home/jwgraham/EEE_network/eee_net/',
	  'mpiCommand': 'ibrun',
	  'nodes': 1,
	  'script': 'init.py',
	  'skip': True,
	  'type': 'hpc_slurm',
	  'walltime': '00:30:00'},
	 'saveFolder': '/oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/bill_batch_05',
	 'seed': None}

So yeah, outFile coming from saveFolder is the only problem.  

I'll change outFile to use dataFolder, batchLabel, batchLabel instead.

Old:

	outFile = b['saveFolder']+'/'+simLabel+'.json'

New:

	outFile = dataFolder+'/'+batchLabel+'/'+simLabel+'.json'

Now getting a Netpyne error.

*** Netpyne Error

Error:

	~/EEE_network/eee_net/batch_utils.py in readBatchData(dataFolder, batchLabel, loadAll, saveAll, vars, maxCombs, listCombs)
	    113 
	    114                 with open(outFile, 'r') as fileObj:
	--> 115                     output = json.load(fileObj, object_pairs_hook=specs.OrderedDict)
	    116 
	    117                 # save output file in data dict

	AttributeError: module 'netpyne.specs' has no attribute 'OrderedDict'

Looking at Salva's code to see if it's been updated.  Not in his code, but on the Netpyne
documents, it looks like it should be 'ODict' now instead of 'OrderedDict'.

That seems to have worked.  Changing all to ODict.

*** Looks like batch data loads now

Currently working in dev.py:

	import batch_utils
	import batch_analysis
	batchLabel = "bill_batch_05"
	params, data = batch_utils.load_batch(batchLabel, "data")

Which produces:

	graham$ ipython -i dev.py

	Reading data...
	0 files missing

	In [1]: whos                                                                                             
	Variable         Type      Data/Info
	------------------------------------
	batchLabel       str       bill_batch_05
	batch_analysis   module    <module 'batch_analysis' <...>e_net/batch_analysis.py'>
	batch_utils      module    <module 'batch_utils' fro<...>/eee_net/batch_utils.py'>
	data             dict      n=25
	params           list      n=2

Committing.


** Analyze and plot data

I recorded traces in bill_batch_05.  Trying to get and plot those now.

Here's how I plotted batch traces before:

    vtraces = get_vtraces(params, data)
    fig = plot_relation(**vtraces)
    fig.savefig(os.path.join(batchfigdir, batch + "_vtrace_soma.png"))
    fig = plot_relation(swapaxes=True, **vtraces)
    fig.savefig(os.path.join(batchfigdir, batch + "_vtrace_soma_2.png"))

    vtraces = get_vtraces(params, data, section="Bdend1")
    fig = plot_relation(**vtraces)
    fig.savefig(os.path.join(batchfigdir, batch + "_vtrace_Bdend1.png"))
    fig = plot_relation(swapaxes=True, **vtraces)
    fig.savefig(os.path.join(batchfigdir, batch + "_vtrace_Bdend1_2.png"))

So I will need to figure out how to pull cell IDs that have traces

	def get_vtraces(params, data, cellID=0, section="soma", stable=None):

Looking into `data` to see if I can pull out traces automatically.

datum = data['_0_0']                                                                               
datum.keys()                                                                                       
Out: dict_keys(['paramValues', 'net', 'netParams_version', 'netpyne_changeset', 'netpyne_version', 'simConfig', 'simData'])
datum['simData'].keys()                                                                                   
Out: odict_keys(['V_dend_8', 'V_soma', 'avgRate', 'spkid', 'spkt', 't'])
datum['simData']['V_soma'].keys()                                                                
Out: odict_keys(['cell_0', 'cell_216', 'cell_408', 'cell_600', 'cell_816'])
datum['simData']['V_dend_8'].keys()                                                             
Out: odict_keys(['cell_0', 'cell_216', 'cell_408', 'cell_600'])

Actually, I'll just add the following line to the end of dev.py:

	vtraces = batch_analysis.get_vtraces(params, data)

It should plot the soma trace for cell 0.

Error:

	~/EEE_network/eee_net/batch_analysis.py in get_vtraces(params, data, cellID, section, stable)
	    621     For use with plot_relation()."""
	    622 
	--> 623     if data[data.keys()[0]]['net']['cells'][cellID]['gid'] != cellID:
	    624         raise Exception("Problem in batch_analysis.get_vtraces: cellID doesn't match gid.")
	    625 

	TypeError: 'dict_keys' object does not support indexing

This is an unnecessary error check. Commenting them out.

Error:

	~/EEE_network/eee_net/batch_analysis.py in get_vtraces(params, data, cellID, section, stable)
	    624     #     raise Exception("Problem in batch_analysis.get_vtraces: cellID doesn't match gid.")
	    625 
	--> 626     cellType = str(data[data.keys()[0]]['net']['cells'][cellID]['tags']['cellType'])
	    627 
	    628     seckey = "V_" + section

	TypeError: 'dict_keys' object does not support indexing

Need a different way to get cellType into the output.

Need to change .iteritems to .items for py2 -> py3

It works.  I get vtraces out.  Now to plot.

fig = batch_analysis.plot_relation(**vtraces)

It works. :)

file:nb_gif/20190424_210153.png

Committing.


* 2019-04-25 -- Batch analysis

** Fixing problems with indexing dicts

Deleting old error-checking (no longer needed):

    if data[data.keys()[0]]['net']['cells'][cellID]['gid'] != cellID:
        raise Exception("Problem in batch_analysis.meas_batch_time_to_spike: cellID doesn't match gid.")

Old way to get cellType from the data:

	cellType = str(data[data.keys()[0]]['net']['cells'][cellID]['tags']['cellType'])

Doesn't work, and really want the cellPop anyway, so here's how:

    cellPop = None

    for key, datum in data.items():
        ...
        if not cellPop:
            cellPop = datum['net']['cells'][cellID]['tags']['pop']

Replacing all `data.keys()[0]` with `list(data.keys())[0]`

Because: TypeError: 'dict_keys' object does not support indexing

That works.  Having a problem with plot_vtraces...

** Fixing problem with plot_vtraces

Error:

	---------------------------------------------------------------------------
	IndexError                                Traceback (most recent call last)
	~/EEE_network/eee_net/dev.py in <module>
	     11 #fig = batch_analysis.plot_relation(**vtraces)
	     12 
	---> 13 fig2 = batch_analysis.plot_vtraces(batchLabel)
	     14 
	     15 plt.show()

	~/EEE_network/eee_net/batch_analysis.py in plot_vtraces(batchname, cellIDs, secs, param_labels, title, filename, save, outputdir)
	   1047             output = get_vtraces(params, data, cellID=cellID, section=sec)
	   1048             if ind == 0:
	-> 1049                 fig1 = plot_relation(param_labels=param_labels, title=title, swapaxes=False, **output)
	   1050                 fig2 = plot_relation(param_labels=param_labels, title=title, swapaxes=True, **output)
	   1051             else:

	~/EEE_network/eee_net/batch_analysis.py in plot_relation(yarray, xvector, params, swapaxes, param_labels, title, xlabel, ylabel, marker, shareyall, color, fig, **kwargs)
	    950                 axes.append(ax)
	    951 
	--> 952                 plt.plot(xvector, yarray[p1ind][p2ind], marker=marker, color=color, label=legendlabel)
	    953 
	    954                 plt.setp(ax.get_xticklabels()[0], visible=False)

	IndexError: index 0 is out of bounds for axis 0 with size 0


It tries to plot traces from every cell, whether it has traces or not.

Need to check for each cell whether it has traces.  Looking at it.

Finally got it working.  Still need to allow "params, data" as an input instead of just "batch_name".

But committing for now.

Also need to allow choice of time period plotted.

** Improvements to plot_vtraces

Allow input of (params, data) tuple as well as just "batch_name", which reloads the batch data every
time.

    if type(batchname) == str:
        params, data = batch_utils.load_batch(batchname)
    elif type(batchname) == tuple:
        params, data = batchname

Allow time period choice

Looks like I should implement it in get_vtraces.  I'll get rid of `stable` int (which just cuts off the 
beginning) and instead have `timerange` list pair which cuts off beginning and end.

Actually, I'll leave stable, but have timerange override it if both are not None.

    if timerange is not None:
        time = time[timerange[0]:timerange[1]]
    elif stable is not None:
        time = time[stable:]

New error:

	---------------------------------------------------------------------------
	TypeError                                 Traceback (most recent call last)
	~/EEE_network/eee_net/dev.py in <module>
	     11 
	     12 batch = (params, data)
	---> 13 batch_analysis.plot_vtraces(batch, timerange=[0, 1000])
	     14 
	     15 

	~/EEE_network/eee_net/batch_analysis.py in plot_vtraces(batchname, cellIDs, secs, timerange, param_labels, title, filename, save, outputdir)
	   1056                 os.mkdir(outputdir)
	   1057             if filename is None:
	-> 1058                 fig1.savefig(os.path.join(outputdir, batchname + "_" + cellLabel + "_vtrace_1.png"))
	   1059                 fig2.savefig(os.path.join(outputdir, batchname + "_" + cellLabel + "_vtrace_2.png"))
	   1060             else:

	TypeError: can only concatenate tuple (not "str") to tuple

Still need batchname to be a string... so:

	batch = (batchLabel, params, data)
	batch_analysis.plot_vtraces(batch)

and

	if type(batchname) == str:
        params, data = batch_utils.load_batch(batchname)
    elif type(batchname) == tuple:
        batchname, params, data = batchname
    else:
        raise Exception()

That works.  Now trying out timerange.

That works, but the xlabels are off by a power of ten.

Committing.

Will also want to be able to set the lineWidth (too thick right now).  That's a task for later.

* 2019-04-26 -- Batch analysis

** Weird cell numbers chosen

I set plotTraces as [('PT5_1',0), ('PT5_2', 0), ('PT5_3', 0), ('PT5_4', 0), ('PV5', 0)], which I think
would come out as 0, 200, 400, 600, and 800, instead I see:

	In [5]: data['_0_0']['simData']['V_dend_8'].keys()                                                       
	Out[5]: odict_keys(['cell_0', 'cell_216', 'cell_408', 'cell_600'])

	In [6]: data['_0_0']['simData']['V_soma'].keys()                                                         
	Out[6]: odict_keys(['cell_0', 'cell_216', 'cell_408', 'cell_600', 'cell_816'])

I'll have to look into this.  Later.  Synchrony for now.

** Looking into synchrony measures

Want to compare synchrony among:

1) plateau neurons during plateau
2) plateau neurons without plateau
3) non-plateau neurons during plateau
4) non-plateau neurons without plateau

From netpyne.org/reference:

	analysis.plotSpikeStats (include = [‘allCells’, ‘eachPop’], timeRange = None, graphType=’boxplot’, stats = [‘rate’, ‘isicv’], popColors = [], figSize = (6,8), saveData = None, saveFig = None, showFig = True)

	Plot spike histogram. Optional arguments:

	include: List of data series to include. Note: one line per item, not grouped ([‘all’|,'allCells'|,’allNetStims’|,120|,’L4’|,('L2', 56)|,(‘L5’,[4,5,6])])
	timeRange: Time range of spikes shown; if None shows all ([start:stop])
	graphType: Type of graph to use (‘boxplot’)
	stats: List of types measure to calculate stats over: cell firing rates, interspike interval coefficient of variation (ISI CV), pairwise synchrony, and/or overall synchrony (sync measures calculated using PySpike SPIKE-Synchrony measure) ([‘rate’, |'isicv'| ‘pairsync’ |'sync'|])
	popColors: Dictionary with color (value) used for each population/key
	figSize: Size of figure ((width, height))
	saveData: File name where to save the final data used to generate the figure (None|’fileName’)
	saveFig: File name where to save the figure (None|’fileName’)
	showFig: Whether to show the figure or not (True|False)
	Returns figure handle


But actually for now, I think I'll try to run my simpler measures on the data.

** Running Joe's old batch analysis stuff

batch_analysis.plot_num_spikes(batchLabel) works! Although, without specifying, it generates a plot
for every cell.  I'd like to improve this to generate a combined plot for all cells specified, with 
mean and stdv bars overlaying gray lines...


* 2019-04-29 -- Batch analysis and synchrony

** Try plotting existing analyses

First thing, I want to try using the existing analyses/plots.  It should be possible to run them 
after the fact.

From the documentation: http://netpyne.org/reference.html#analysis-related-functions

It looks like once I have a `sim` loaded, I can then: sim.analysis.FUNCTIONNAME()

	.plotRaster (include = [‘allCells’], timeRange = None, maxSpikes = 1e8, orderBy = ‘gid’, orderInverse = False, labels = ‘legend’, popRates = False, spikeHist = None, spikeHistBin = 5, syncLines = False, figSize = (10,8), saveData = None, saveFig = None, showFig = True)

	.plotSpikeHist (include = [‘allCells’, ‘eachPop’], timeRange = None, binSize = 5, overlay=True, graphType=’line’, yaxis = ‘rate’, figSize = (10,8), saveData = None, saveFig = None, showFig = True)

	.plotSpikeStats (include = [‘allCells’, ‘eachPop’], timeRange = None, graphType=’boxplot’, stats = [‘rate’, ‘isicv’], popColors = [], figSize = (6,8), saveData = None, saveFig = None, showFig = True)

	.plotConn (include = [‘all’], feature = ‘strength’, orderBy = ‘gid’, figSize = (10,10), groupBy = ‘pop’, saveData = None, saveFig = None, showFig = True)


I'll try loading the sim data from one batch sim and then plotting.

Looks like I have to use netpyne's load function (from Salva's analysis code):

	sim.load(dataFolder+simLabel+'.json', instantiate=False)

    # plot param grids
    fig = sim.analysis.plotTraces(include=[0,1], colors=[[0,0,0], [0,0,0]], oneFigPer= 'trace', overlay=0, figSize=(7,5), timeRange=[0,5000], ylim=[-90, 25], saveFig=False, showFig=0)

This is what I put in dev.py:

	batchdatadir = "data"
	batchLabel = "bill_batch_05"

	curSim = "_0_0"

	# params, data = batch_utils.load_batch(batchLabel, batchdatadir=batchdatadir)

	sim.load(batchdatadir + '/' + batchLabel + '/' + batchLabel + curSim + '.json', instantiate=False)

	fig = sim.analysis.plotTraces()

And that succesfully plots traces (though not all of them).

The other plotting functions seem to work as well.

** To do now

Synchrony measures
Pop plotting measures
Batch plotting existing analyses



** Batch plotting existing analyses?

What I'd like is to be able to plot any existing analyses in batch format (grid of plots).
Looking into how to do this.

Transplanting axes from Netpyne figures to batch figure is not going to work well.

Better to adjust Netpyne plotting functions to accept an axis, e.g.:

	def plotRaster(..., altAx=None, ...):
		
		if not altAx:
			new figure and axis
		else:
			plot into altAx

Copying my batch_analysis/plot_relation to plot_batch_raster

It's coming along nicely!

file:nb_gif/20190429_201238.png

Committing now.

Need to add options like lineWidth...

From netpyne:

	analysis.plotRaster (include = [‘allCells’], timeRange = None, maxSpikes = 1e8, orderBy = ‘gid’, orderInverse = False, labels = ‘legend’, popRates = False, spikeHist = None, spikeHistBin = 5, syncLines = False, figSize = (10,8), saveData = None, saveFig = None, showFig = True)

Options I want in plot_batch_raster

	include = [‘allCells’], 
	timeRange = None, 
	maxSpikes = 1e8, 
	orderBy = ‘gid’, 
	orderInverse = False, 
	syncLines = False, 
	figSize = (10,8), 
	lw = 2, 
	marker = '|', 
	markerSize=5,


Options I want to set internal to plot_batch_raster (i.e. in analysis.plotRaster inside plot_batch_raster)

	labels = False, (unless it's subplotind 1, in which case put in the labels='legend')
	popRates = False,
	spikeHist = None, 
	spikeHistBin = 5, 
	saveData = None, 
	saveFig = None, 
	showFig = False



** Pop plotting measures

Currently I can plot a variety of measures for individual cells.  I want a "master plot" which overlays
all the individual plots with a population mean and standard deviation bars.

Getting back to later.

** Synchrony measures

We want to measure synchrony in pops with and without plateaus.

Getting back to later.


** plot_batch_raster functional

And working well!

file:nb_gif/20190429_211144.png

But it does require some changes to Netpyne.  

*** Here's my diff:

diff --git a/netpyne/analysis/spikes.py b/netpyne/analysis/spikes.py
index f0e808c..5433e18 100644
--- a/netpyne/analysis/spikes.py
+++ b/netpyne/analysis/spikes.py
@@ -294,7 +294,7 @@ def plotSyncs (include =['allCells', 'eachPop'], timeRanges = None, timeRangeLab
 @exception
 def plotRaster (include = ['allCells'], timeRange = None, maxSpikes = 1e8, orderBy = 'gid', orderInverse = False, labels = 'legend', popRates = False,
         spikeHist = None, spikeHistBin = 5, syncLines = False, lw = 2, marker = '|', markerSize=5, popColors = None, figSize = (10,8), dpi = 100, saveData = None, saveFig = None,
-        showFig = True):
+        showFig = True, altAx=None):
     '''
     Raster plot of network cells
         - include (['all',|'allCells',|'allNetStims',|,120,|,'E1'|,('L2', 56)|,('L5',[4,5,6])]): Cells to include (default: 'allCells')
@@ -422,8 +422,13 @@ def plotRaster (include = ['allCells'], timeRange = None, maxSpikes = 1e8, order
         histo = np.histogram(sel['spkt'].tolist(), bins = np.arange(timeRange[0], timeRange[1], spikeHistBin))
         histoT = histo[1][:-1]+spikeHistBin/2
         histoCount = histo[0]
+    
     # Plot spikes
-    fig,ax1 = plt.subplots(figsize=figSize)
+    if not altAx:
+        fig,ax1 = plt.subplots(figsize=figSize)
+    else:
+        ax1 = altAx
+        spikeHist = False
     fontsiz = 12
 
     if spikeHist == 'subplot':
@@ -432,6 +437,8 @@ def plotRaster (include = ['allCells'], timeRange = None, maxSpikes = 1e8, order
     sel['spkt'] = sel['spkt'].apply(pd.to_numeric)
     sel.plot.scatter(ax=ax1, x='spkt', y='spkind', lw=lw, s=markerSize, marker=marker, c=sel['spkgidColor'].tolist()) # Create raster
     ax1.set_xlim(timeRange)
+    ax1.set_xlabel(None)
+    ax1.set_ylabel(None)
 
     # Plot stats
     gidPops = df['pop'].tolist()
@@ -459,12 +466,13 @@ def plotRaster (include = ['allCells'], timeRange = None, maxSpikes = 1e8, order
     if syncLines:
         for spkt in sel['spkt'].tolist():
             ax1.plot((spkt, spkt), (0, len(cells)+numNetStims), 'r-', linewidth=0.1)
-        plt.title('cells=%i syns/cell=%0.1f rate=%0.1f Hz sync=%0.2f' % (numCells,connsPerCell,firingRate,syncMeasure()), fontsize=fontsiz)
+        if not altAx: plt.title('cells=%i syns/cell=%0.1f rate=%0.1f Hz sync=%0.2f' % (numCells,connsPerCell,firingRate,syncMeasure()), fontsize=fontsiz)
     else:
-        plt.title('cells=%i syns/cell=%0.1f rate=%0.1f Hz' % (numCells,connsPerCell,firingRate), fontsize=fontsiz)
+        if not altAx: plt.title('cells=%i syns/cell=%0.1f rate=%0.1f Hz' % (numCells,connsPerCell,firingRate), fontsize=fontsiz)
     # Axis
-    ax1.set_xlabel('Time (ms)', fontsize=fontsiz)
-    ax1.set_ylabel(ylabelText, fontsize=fontsiz)
+    if not altAx:
+        ax1.set_xlabel('Time (ms)', fontsize=fontsiz)
+        ax1.set_ylabel(ylabelText, fontsize=fontsiz)
     ax1.set_xlim(timeRange)
     ax1.set_ylim(-1, len(cells)+numNetStims+1)
 
@@ -476,10 +484,11 @@ def plotRaster (include = ['allCells'], timeRange = None, maxSpikes = 1e8, order
         for ipop,popLabel in enumerate(popLabels):
             label = popLabelRates[ipop] if popRates else popLabel
             plt.plot(0,0,color=popColors[popLabel],label=label)
-        plt.legend(fontsize=fontsiz, bbox_to_anchor=(1.04, 1), loc=2, borderaxespad=0.)
-        maxLabelLen = max([len(l) for l in popLabels])
-        rightOffset = 0.85 if popRates else 0.9
-        plt.subplots_adjust(right=(rightOffset-0.012*maxLabelLen))
+            plt.legend(fontsize="x-small")
+        #plt.legend(fontsize=fontsiz, bbox_to_anchor=(1.04, 1), loc=2, borderaxespad=0.)
+        #maxLabelLen = max([len(l) for l in popLabels])
+        #rightOffset = 0.85 if popRates else 0.9
+        #plt.subplots_adjust(right=(rightOffset-0.012*maxLabelLen))
 
     elif labels == 'overlay':
         ax = plt.gca()
@@ -515,7 +524,8 @@ def plotRaster (include = ['allCells'], timeRange = None, maxSpikes = 1e8, order
         ax2.set_ylabel('Spike count', fontsize=fontsiz)
         ax2.set_xlim(timeRange)
 
-    if orderInverse: plt.gca().invert_yaxis()
+    #if orderInverse: plt.gca().invert_yaxis()
+    if orderInverse: ax1.invert_yaxis()
 
     # save figure data
     if saveData:
@@ -535,7 +545,10 @@ def plotRaster (include = ['allCells'], timeRange = None, maxSpikes = 1e8, order
     # show fig
     if showFig: _showFigure()
 
-    return fig, {'include': include, 'spkts': spkts, 'spkinds': sel['spkind'].tolist(), 'timeRange': timeRange}
+    if not altAx:
+        return fig, {'include': include, 'spkts': spkts, 'spkinds': sel['spkind'].tolist(), 'timeRange': timeRange}
+    else:
+        return ax1
 
 
 # -------------------------------------------------------------------------------------------------------------------






Committing now



** Running a few batches to explore

Switching back to v01batch# naming strategy.

v01_batch03

	params['EEconv'] = [0.0, 3.0, 6.0] # Default 3.0
	params['IEconv'] = [0.0, 12.0, 24.0] # Default 12.0

v01_batch04

	params['PT5_exc_noise_amp'] = [0.0, 0.5, 1.0, 2.0] # Default 1.0
	params['PT5_inh_noise_amp'] = [0.0, 0.5, 1.0, 2.0] # Default 1.0

v01_batch05

	params['PV5_exc_noise_amp'] = [0.0, 0.5, 1.0, 2.0] # Default 1.0
	params['PV5_inh_noise_amp'] = [0.0, 0.5, 1.0, 2.0] # Default 1.0

Will commit and push to Comet, then run:

	python batch03.py
	python batch04.py
	python batch05.py


* 2019-04-30 -- Batch analysis and synchrony, EEE meeting

** Moving batch outputs

It looks like the batches succesfully completed last night.

Now to move that data from scratch to long-term and to download locally.

graham$ cpsc v01_batch03
graham$ cpsc v01_batch04
graham$ cpsc v01_batch05

Once that's done I can `sshc` and then `mvlt` each of those dirs.


** Analyzing batch outputs

Here's my current dev.py:

	import batch_utils
	import batch_analysis
	import matplotlib.pyplot as plt
	from netpyne import sim
	plt.ion()

	batchdatadir = "data"

	def analyze_batch(batchLabel, batchdatadir=batchdatadir):

		params, data = batch_utils.load_batch(batchLabel, batchdatadir=batchdatadir)
		batch = (batchLabel, params, data)

		batch_analysis.plot_batch_raster(batch, timeRange=[100, 1000], markerSize=0.5)
		batch_analysis.plot_vtraces(batch, timerange=[100, 1000])

	analyze_batch('v01_batch03')
	analyze_batch('v01_batch04')
	analyze_batch('v01_batch05')

Trace figures are properly saved (although I think I should disable the automatic swapAxes)

I need to get raster figures to save.

** Disabling auto axes swap in plot traces

Will do this later.


** Saving raster figures

Saving rasters works now.  Committing.


** Running new batch

v01_batch06

	params['noisePT5'] = [True, False] 
	params['noisePV5'] = [True, False] 

Committ/push/run.


** EEE Meeting

Agenda:
https://docs.google.com/document/d/16b0js-DPFVRSmGRo0DB8AiAyoQ0QgxSNS0VKX7snGHA/edit


Discussion

SfN abstract
See last year’s abstract below
Just submitting for network simulations
Joe pulls together preliminary abstract today
Penny can’t attend, Srdjan can’t

Article resubmission
Declined by J Neurosci
Went over changes from reviewers
Will submit elsewhere (Nature Communications?)
Still debating Nature or Science

Simulations
Batch analysis and figures
Joe’s batch_utils.py and batch_analysis.py now allow plotting of voltage traces and raster plots
Requires minor changes to Netpyne (plotting funcs must accept axis)
Sample code:
params, data = batch_utils.load_batch(batchLabel, batchdatadir)
batch = (batchLabel, params, data)
batch_analysis.plot_batch_raster(batch, timeRange=[100, 1000])
batch_analysis.plot_vtraces(batch, timerange=[100, 1000])
Joe is now working on synchrony measures, histograms, various spike measures
Will apply measurements to plateau and non-plateau portions of data
Connectivity
Convergence has less effect than Joe expected (see Fig 1 and 2 below)
Is convergence the best way to set connectivity?
Joe wants to analyze output connectivity from convergence batches
Noise 
Noise to PT cells
Noise to PV cells
Noise on/off altogether
Others items?
Srdjan concerned about size of soma plateau
With noise on, it’s not as clear
With noise off, we see 20 mV somatic 
Maybe need to explore noise to find balance
Explore synaptic strengths
Want a cleaner plateau
What do traces look like in vivo?
Which matches most closely?
Bill: not much available?
Bill: explore long sims without stimulation
Record soma from all cells
Search for plateaus
Don can help dumping data
Try with 10,000 cells
Need to balance EI
Need to play with noise
Start with short sims
Then go into seconds range



Other items?


Action items for next week

Explore reducing noise to improve plateaus
Explore connectivity (measure and plot)
Explore synaptic strengths 
Run bigger, longer sims without stim (look for plateau emergence)
SfN abstracts due May 2



* 2019-05-03 -- SfN abstract

** 2018 SfN abstract

https://docs.google.com/document/d/1bxVlVp5ykAzpdzXNkHsPCV7fPs8I9WAygM7inXWenJo/edit


** 2019 SfN abstract

https://docs.google.com/document/d/1OX31jQmSIdxC3oC6L0mkAI4mlYzQtKuG2OfEaLFUrdc/edit


Modeling network effects of dendritic plateau potentials in cortical pyramidal neurons

Joe W Graham1, Peng P Gao2, Salvador Dura-Bernal1, Subhashini Sivagnanam1,3, Michael L Hines4, Srdjan D Antic2, William W Lytton1,5

1 Physiology & Pharmacology Dept., SUNY Downstate, Brooklyn NY 11203, USA
2 Neuroscience Dept., Univ. of Connecticut Health, Farmington CT 06030, USA
3 San Diego SuperComputer Center, UCSD, La Jolla CA 92093, USA 
4 Neuroscience Dept., Yale School of Medicine, New Haven CT 06510, USA
5 Neurology Dept., Kings County Hospital Center, Brooklyn NY 11203, USA

It has been demonstrated in brain slices that releasing glutamate near the basal dendrites of cortical pyramidal neurons can generate dendritic plateau potentials—long-lasting depolarizations of the dendritic membrane mediated by activation of synaptic NMDA and AMPA receptors and extrasynaptic NMDA receptors.  Depending on the location and strength of the glutamate stimulus, as well as on local dendritic morphology and activity, the depolarization from dendritic plateaus can spread into the soma, reducing membrane time constant and bringing the cell closer to the spiking threshold.  Using data from voltage-sensitive dye imaging in dendrites and whole-cell patch measurements in somata of prefrontal cortex pyramidal neurons from rat brain slices, we developed a morphologically-detailed cortical pyramidal neuron model with active dendrites that reproduced experimental observations: a threshold for activation of the plateau, saturation of plateau amplitude but increasing plateau duration with increasing glutamate application, depolarization of the soma by approximately 20 mV, and back-propagating action potential amplitude attenuation and time delay.  For use in network modeling, this cell model was then simplified morphologically while maintaining overall electrophysiological and plateau behavior.  Network simulations demonstrated increased synchrony between cells during induced dendritic plateaus. These results support our hypothesis that dendritic plateaus provide a 200-500 ms time window during which a neuron is particularly excitable. At the network level, this predicts that sets of cells with simultaneous plateaus would provide an activated ensemble of responsive cells with increased firing. Synchronously spiking subsets of these cells would then create an embedded ensemble. This embedded ensemble would demonstrate a temporal code, at the same time as the activated (embedded) ensemble showed rate coding.  This line of research may help to understand the implications of dendritic plateaus at the cellular and network level, and may lead to a better understanding of ensemble synchronization and multimodal cortical information processing. 



* 2019-05-06 -- Batch connectivity analyses, big simulation

** Big simulation

I'm going to set up to run a 10,000 cell network model

8,000 PT5
2,000 PV5

Run at a few connectivity strengths.

Saving it as batch07.py

Connectivity to vary:

	params['EEconv'] = [0.0, 1.5, 3.0, 4.5, 6.0] # Default 3.0
	params['IEconv'] = [0.0, 6.0, 12.0, 18.0, 24.0] # Default 12.0

Asking for 10 nodes, with a run time of 2:00:00

cfg.duration = 200

cfg.numPT5cells = 8000
cfg.numPV5cells = 2000

cfg.glutamate         = False #True

cfg.addCommonInput1 = False #True
cfg.addCommonInput2 = False #True

Setting to record from all cells, so we can look for plateaus:

cfg.analysis['plotTraces'] = {'include': ['PT5_1', 'PT5_2', 'PT5_3', 'PT5_4'] 'saveFig': saveFig, 'showFig': showFig, 'ylim': [-80, 30]}

Commit, push, Comet.

*** Got an error:

co$ python batch07.py
Note: NeuroML import failed; import/export functions for NeuroML will not be available. 
  To install the pyNeuroML & libNeuroML Python packages visit: https://www.neuroml.org/getneuroml
Saving batch to /oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/v01_batch07/v01_batch07_batch.json ... 
Traceback (most recent call last):
  File "batch07.py", line 44, in <module>
    batchRun() 
  File "batch07.py", line 40, in batchRun
    b.run()
  File "/home/lytton/netpyne/netpyne/batch/batch.py", line 232, in run
    cfgModule = imp.load_source(cfgModuleName, self.cfgFile)
  File "/home/lytton/anaconda3/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "cfg.py", line 117
    cfg.analysis['plotTraces'] = {'include': ['PT5_1', 'PT5_2', 'PT5_3', 'PT5_4'] 'saveFig': saveFig, 'showFig': showFig, 'ylim': [-80, 30]}   
                                                                                          ^
SyntaxError: invalid syntax

*** Fixed error

In the future, I'll run `python cfg.py` and `python netParams.py` locally before committing and pushing.

Cool. Some are already running.

*** Comet jobs

co$ sq
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          23195631   compute v01_batc jwgraham PD       0:00     10 (Resources)
          23195632   compute v01_batc jwgraham PD       0:00     10 (Priority)
          23195633   compute v01_batc jwgraham PD       0:00     10 (Resources)
          23195634   compute v01_batc jwgraham PD       0:00     10 (Resources)
          23195635   compute v01_batc jwgraham PD       0:00     10 (Resources)
          23195636   compute v01_batc jwgraham PD       0:00     10 (Resources)
          23195637   compute v01_batc jwgraham PD       0:00     10 (Resources)
          23195638   compute v01_batc jwgraham PD       0:00     10 (Resources)
          23195639   compute v01_batc jwgraham PD       0:00     10 (Resources)
          23195640   compute v01_batc jwgraham PD       0:00     10 (Resources)
          23195641   compute v01_batc jwgraham PD       0:00     10 (Resources)
          23195642   compute v01_batc jwgraham PD       0:00     10 (Resources)
          23195643   compute v01_batc jwgraham PD       0:00     10 (Resources)
          23195644   compute v01_batc jwgraham PD       0:00     10 (Resources)
          23195645   compute v01_batc jwgraham PD       0:00     10 (Resources)
          23195627   compute v01_batc jwgraham  R       6:07     10 comet-22-[06-10,26-30]
          23195625   compute v01_batc jwgraham  R       8:07     10 comet-15-[28,52-54,56],comet-23-[35,37,39-41]
          23195626   compute v01_batc jwgraham  R       8:07     10 comet-02-[52,54],comet-14-24,comet-17-50,comet-19-32,comet-26-69,comet-27-[39-40,65-66]
          23195622   compute v01_batc jwgraham  R      12:07     10 comet-27-[29-38]


** Connectivity analysis

Since we're scaling up, we'll need to adjust connectivity.  First to measure it.

For that we'll need to add an alternate axis input (altAx) into the Netpyne connectivity
plotting code, like I did for plotRaster

Tomorrow at the EEE meeting I'll talk to Salva about how/if to incorporate these batch 
plots into Netpyne.

Working in plotConn in:

/Users/graham/Applications/netpyne/netpyne/analysis/network.py

Before starting, I'll look at updating Netpyne.

error: Your local changes to the following files would be overwritten by merge:
	netpyne/analysis/spikes.py
Please commit your changes or stash them before you merge.
Aborting

Ugh. I saved a copy of spikes.py to my Desktop so I can reimplement the altAx stuff once
I get Netpyne properly updated.

https://support.beanstalkapp.com/article/1004-how-do-i-undo-things-in-git#1

        git checkout -- path/to/the/file.txt

git checkout -- netpyne/analysis/spikes.py
git pull

Okay, that worked cleanly now. Now to update spikes.py and the network.py

Updated spikes.py attempting to plot batch rasters.


** Big sim

Getting enormous error files.  This is in a run file:

	--------------------------------------------------------------------------
	orterun detected that one or more processes exited with non-zero status, thus causing
	the job to be terminated. The first process to do so was:

	  Process name: [[44793,1],232]
	  Exit code:    255
	--------------------------------------------------------------------------


This is what's in the error file:

	[comet-27-21:19561] *** Process received signal ***
	[comet-27-21:19561] Signal: Segmentation fault (11)
	[comet-27-21:19561] Signal code:  (0)
	[comet-27-21:19561] Failing at address: (nil)
	[comet-27-21:19561] [ 0] /lib64/libc.so.6[0x3948c32570]
	[comet-27-21:19561] [ 1] /opt/openmpi/gnu/ib/lib/libmpi.so.1(+0x113a5e)[0x2b79790d9a5e]
	[comet-27-21:19561] [ 2] /opt/openmpi/gnu/ib/lib/libmpi.so.1(+0x113cbc)[0x2b79790d9cbc]
	[comet-27-21:19561] [ 3] /opt/openmpi/gnu/ib/lib/libmpi.so.1(+0x10b488)[0x2b79790d1488]
	[comet-27-21:19561] [ 4] /lib64/libpthread.so.0[0x3948807aa1]
	[comet-27-21:19561] [ 5] /lib64/libc.so.6(clone+0x6d)[0x3948ce8c4d]
	[comet-27-21:19561] *** End of error message ***

I'm going to try it again as batch08


** Big sim take two

Commit, push, Comet.

python batch08.py



* 2019-05-07 -- Batch connectivity analyses, big simulation

** Big sim

Unfortunately I got timeout errors, as some sims lasted longer than the 3 hours I requested.

But not all timed out... 

I am going to start batch09.py and only have 5000 cells (4000 PT and 1000 PV)

Reducing time of sim to 1000 ms

Commit, push, Comet.

That should be running.  Back to getting connectivity analysis out.

** Connectivity analysis

Want to be able to see connectivity for increasing network sizes

I want a batch figure like the batch rasters.  Working in Netpyne

	/Users/graham/Applications/netpyne/netpyne/analysis/network.py

in plotConn to add altAx and in my batch_analysis.py to add plot_batch_conn


** EEE meeting

https://docs.google.com/document/d/1UMmMwbuBY3mbCfPKWA1GIKO3TjbKi8HAonNz5OUo1k4/edit?usp=sharing

Action items for next week

Report any new findings in Na channel
People (Joe) look into sims not completing -- try to reproduce
Bill gets NEURON onto Stampede
Try running sims on Stampede
Joe tries running on < 96 cores to see if that helps
Hines suggests repo clone with README explaining how to do sim
Hines would like to run big model (M1) on BBP machine at large scale
Joe updates EEE README and sends Mike Hines the repo to run on BBP
Bill and Mike work together to get stuff installed on Marconi
Joe does Netpyne pull request for “altAx” batch plotting


* 2019-05-09 -- Plotting batch figures in Netpyne 

Working on adding altAx to Netpyne plots so that multiple plots can be combined into a batch plot.



* 2019-05-10 -- Working on batches crashing


** Preparing big sim and README

Bill and Mike Hines want to try running the code and seeing if they get the crashes also.

Fixing up README


Adding a runType option to batch file so that it can be used for either hpc_slurm or 
mpi_bulletin.

	runType = 'hpc_slurm' # Either 'hpc_slurm' or 'mpi_bulletin'

		if runType == 'hpc_slurm':
			b.runCfg = {'type': 'hpc_slurm',
						'allocation': 'shs100', 
						'walltime': '03:00:00',
						'nodes': 10,
						'coresPerNode': 24,
						'email': 'joe.w.graham@gmail.com',
						'folder': '/home/jwgraham/EEE_network/eee_net/',
						'script': 'init.py', 
						'mpiCommand': 'ibrun',
						'skip': True}
		elif runType == 'mpi_bulletin':
			b.runCfg = {'type': 'mpi_bulletin', 
						'script': 'init.py', 
						'skip': True}


Will now always use 'batch.py' instead of new files each time.  Will just update batchLabel.

*** New README

# EEE_network

## Prepare for simulations

1. Clone the repo (`git clone https://github.com/Neurosim-lab/EEE_network.git`)
2. Compile the mod files (`cd EEE_network/mod ; nrnivmodl`)
3. Symlink the mod dir (`cd ../eee_net ; ln -s "../mod/x86_64" x86_64`)

## Running simulations using MPI

### To run a single sim using MPI 

1. Change to the 'eee_net' directory (`cd EEE_network/eee_net`)
2. Two options to run sim:
	1. Execute `mpiexec -np #processes nrniv -python -mpi init.py` after replacing #processes with the number of processes you want to use (e.g. `mpiexec -np 4 nrniv -python -mpi init.py`)
	2. Execute `runsim #processes` (e.g. `./runsim 4`)

### To run a batch of sims using MPI 

1. Change to the 'eee_net' directory (`cd EEE_network/eee_net`)
2. Open 'batch.py'
3. Ensure `runType = mpi_bulletin`
4. Update the `batchLabel`
5. Two options to run batch:
	1. Execute `mpiexec -np #processes nrniv -python -mpi batch.py` (e.g. `mpiexec -np 4 nrniv -python -mpi batch.py`)
	2. Execute `runbatch #processes` (e.g. `./runbatch 4`)

## Running simulations on Comet

### To run a single sim on Comet

1. Change to the 'eee_net' directory (`cd EEE_network/eee_net`)
2. Modify the file `runsim_comet` to your settings
3. Execute `sbatch runsim_comet`

### To run a batch of simulations on Comet

1. Change to the 'eee_net' directory (`cd EEE_network/eee_net`)
2. Open 'batch.py'
3. Ensure `runType = hpc_slurm`
4. Update the `batchLabel`
5. Execute `python batch.py`


*** Committing now to test.


** Testing locally

Temp setup:

	cd
	mkdir temp
	cd temp
	git clone https://github.com/Neurosim-lab/EEE_network.git
	cd EEE_network/mod ; nrnivmodl
	cd ../eee_net ; ln -s "../mod/x86_64" x86_64

That worked.

Trying single sim:

	./runsim 4

That worked.

Trying batch sim:

Changing runType to mpi_bulletin.

	./runbatch 4

Error: Could not create batch_data/v01_batch10_local

Adding this to batch.py:

		if not os.path.isdir('batch_data'):
			os.mkdir('batch_data')

Trying again.  Works now.


** Testing on Neurosim

Cranking up number of cells from 10 to 100.

	sshzn
	mkdir temp
	cd temp
	git clone https://github.com/Neurosim-lab/EEE_network.git
	cd EEE_network/mod ; nrnivmodl
	cd ../eee_net ; ln -s "../mod/x86_64" x86_64
	./runsim 20

Apparently there is no pandas on zn.

	joe [11:27 AM]
	Our EEE code is still crashing on Neurosim machines because they don’t have `pandas` installed.  Could someone install Pandas? Or tell me how to do it? :sweat_smile:

	joe [11:28 AM]
	New README for EEE_network: https://github.com/Neurosim-lab/EEE_network/blob/master/README.md
	GitHub
	Neurosim-lab/EEE_network
	Contribute to Neurosim-lab/EEE_network development by creating an account on GitHub.

	billl [11:28 AM]
	thx

	joe [11:28 AM]
	It works on my local machine, crashes on `my` and `no` for lack of Pandas.
	About to make sure it works on Comet, and then I’ll beef it up and share.

	billl [11:29 AM]
	how about seg faults?

	joe [11:29 AM]
	About to run on Comet, and I’ll let you know.  No seg faults locally.

	billl [11:30 AM]
	I'll install pandas. thought came with netpyne

	salvadord [11:30 AM]
	was trying to install but at dmc and can’t ssh into machines from here

	billl [11:30 AM]
	ironic

	salvadord [11:30 AM]
	comes with netpyne if pip install, but I git cloned to have dev

	billl [11:31 AM]
	I've been doing both


** Testing on Comet

Will test two on Comet with 4 x 24 cores

	joe [11:25 AM]
	Question for @salvadord: you were saying that running with <96 cores results in much less crashing.  I was wondering how you divide that between `nodes` and `coresPerNode`?

	salvadord [11:25 AM]
	4*24

	joe [11:26 AM]
	Perfect, thanks.

*** Testing a single sim.

Beefing it up to 1000 cells.

Updating `runsim_comet`

	#!/bin/bash 
	#SBATCH --job-name=eee_net_01_comet
	#SBATCH -A shs100
	#SBATCH -t 2:00:00
	#SBATCH --nodes=4
	#SBATCH --ntasks-per-node=24
	#SBATCH -o eee_net_01_comet.run
	#SBATCH -e eee_net_01_comet.err
	#SBATCH --mail-user=joe.w.graham@gmail.com
	#SBATCH --mail-type=end
	source ~/.bashrc
	cd /home/jwgraham/EEE_network/eee_net/
	ibrun -np 4 nrniv -python -mpi init.py

Commit, push, Comet.

	mkdir temp ; cd temp ; git clone https://github.com/Neurosim-lab/EEE_network.git ; cd EEE_network/mod ; nrnivmodl ; cd ../eee_net ; ln -s "../mod/x86_64" x86_64

	co$ sbatch runsim_comet
	Submitted batch job 23263730
	co$
	co$ squeue -u jwgraham
	             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
	          23263730   compute eee_net_ jwgraham PD       0:00      4 (Priority)

*** Testing a batch of sims

python batch.py

	co$ sq
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          23263747   compute v01_batc jwgraham PD       0:00      4 (None)
          23263749   compute v01_batc jwgraham PD       0:00      4 (None)
          23263750   compute v01_batc jwgraham PD       0:00      4 (None)
          23263751   compute v01_batc jwgraham PD       0:00      4 (None)
          23263752   compute v01_batc jwgraham PD       0:00      4 (None)
          23263754   compute v01_batc jwgraham PD       0:00      4 (None)
          23263755   compute v01_batc jwgraham PD       0:00      4 (None)
          23263757   compute v01_batc jwgraham PD       0:00      4 (None)
          23263758   compute v01_batc jwgraham PD       0:00      4 (None)
          23263730   compute eee_net_ jwgraham  R       2:26      4 comet-12-51,comet-14-[69-71]


** Single sim results

eee_net_01_comet Ended, Run time 00:23:08, COMPLETED, ExitCode 0

*** .run file

	co$ cat eee_net_01_comet.run
	numprocs=4
	Note: NeuroML import failed; import/export functions for NeuroML will not be available. 
	  To install the pyNeuroML & libNeuroML Python packages visit: https://www.neuroml.org/getneuroml

	Reading command line arguments using syntax: python file.py [simConfig=filepath] [netParams=filepath]

	Reading command line arguments using syntax: python file.py [simConfig=filepath] [netParams=filepath]

	Reading command line arguments using syntax: python file.py [simConfig=filepath] [netParams=filepath]

	Reading command line arguments using syntax: python file.py [simConfig=filepath] [netParams=filepath]
	Balancing each compartment to -73 mV
	Balancing each compartment to -73 mV
	Balancing each compartment to -73 mV
	Balancing each compartment to -73 mV

	Creating network of 5 cell populations on 4 hosts...
	  Number of cells on node 0: 1250 
	  Number of cells on node 3: 1250 
	  Number of cells on node 2: 1250 
	  Done; cell creation time = 4.82 s.
	Making connections...
	  Number of cells on node 1: 1250 
	  Number of connections on node 0: 30000 
	  Number of synaptic contacts on node 0: 54000 
	  Number of connections on node 1: 30000 
	  Number of synaptic contacts on node 1: 54000 
	  Number of connections on node 3: 30000 
	  Number of synaptic contacts on node 3: 54000 
	  Done; cell connection time = 5.15 s.
	  Number of connections on node 2: 30000 
	  Number of synaptic contacts on node 2: 54000 
	  Number of stims on node 1: 0 
	  Number of stims on node 0: 0 
	  Done; cell stims creation time = 0.00 s.
	  Number of stims on node 2: 0 
	  Number of stims on node 3: 0 
	Recording 2000 traces of 2 types on node 2
	Recording 2000 traces of 2 types on node 3
	Recording 2000 traces of 2 types on node 0
	Recording 2000 traces of 2 types on node 1

	Running simulation for 1000 ms...
	  Done; run time = 1336.48 s; real-time ratio: 0.00.

	Gathering data...
	  Done; gather time = 1.36 s.

	Analyzing...
	  Cells: 5000
	  Connections: 0 (0.00 per cell)
	  Spikes: 39347 (7.87 Hz)
	  Simulated time: 1.0 s; 4 workers
	  Run time: 1336.48 s
	--------------------------------------------------------------------------
	An MPI process has executed an operation involving a call to the
	"fork()" system call to create a child process.  Open MPI is currently
	operating in a condition that could result in memory corruption or
	other system errors; your MPI job may hang, crash, or produce silent
	data corruption.  The use of fork() (or system() or other calls that
	create child processes) is strongly discouraged.  

	The process that invoked fork was:

	  Local host:          comet-12-51 (PID 8292)
	  MPI_COMM_WORLD rank: 0

	If you are *absolutely sure* that your application will successfully
	and correctly survive a call to fork(), you may disable this warning
	by setting the mpi_warn_on_fork MCA parameter to 0.
	--------------------------------------------------------------------------
	Saving output as data/eee_net.json  ... 
	Finished saving!
	  Done; saving time = 19.15 s.
	Plotting raster...
	-------------------------------------------------------
	Primary job  terminated normally, but 1 process returned
	a non-zero exit code.. Per user-direction, the job has been aborted.
	-------------------------------------------------------
	--------------------------------------------------------------------------
	orterun detected that one or more processes exited with non-zero status, thus causing
	the job to be terminated. The first process to do so was:

	  Process name: [[37865,1],0]
	  Exit code:    1
	--------------------------------------------------------------------------

*** .err file

	co$ cat eee_net_01_comet.err
	Unloading compiler-dependent module gsl/2.1
	Unloading compiler-dependent module openmpi_ib/1.8.4
	NEURON -- VERSION 7.7.0-46-ga3a462a master (a3a462a) 2019-04-09
	Duke, Yale, and the BlueBrain Project -- Copyright 1984-2018
	See http://neuron.yale.edu/neuron/credits

	Additional mechanisms from files
	 ampa.mod Cad.mod CaDynamics_E2.mod cadyn.mod Ca_HVA.mod ca.mod canin.mod CaT.mod gabaa.mod gabab.mod Gfluctp.mod glutamate.mod hin.mod h_kole.mod h_migliore.mod Ih.mod IKsin.mod IL.mod kadist.mod kapin.mod kaprox.mod kBK.mod kctin.mod kdrin.mod kv.mod MyExp2SynBB.mod nafx.mod na.mod NMDAeee.mod NMDAmajor.mod NMDA.mod PlateauConductance.mod SK_E2.mod vecstim.mod vmax.mod
	>>> 
	>>> >>> 

	QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-jwgraham'
	qt.qpa.screen: QXcbConnection: Could not connect to display localhost:52.0
	Could not connect to any X display.

*** discussion

The .run and .err files ended up right in the eee_net dir.  

Looking at the .run file, it seems everything ran fine until the end (where there is the 
weird fork error I've seen before and some process exited non-zero).

But I can't find the output file.  It says: "Saving output as data/eee_net.json" but there is no 
"data" dir.  I wonder if it didn't crash somehow because of the lack of the data dir...

I will make a data dir on Comet and re-run the sim.

	co$ sbatch runsim_comet
	Submitted batch job 23264271
	co$ sq
	             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
	          23264271   compute eee_net_ jwgraham PD       0:00      4 (None)
	          23263757   compute v01_batc jwgraham  R      51:52      4 comet-12-[47,49],comet-21-[26,30]

Oddly, one of the batch sims is still running.


** New single sim results

eee_net_01_comet Ended, Run time 00:23:30, COMPLETED, ExitCode 0

Ugh, I ran it in the temp dir.  

*** From the .run file

Analyzing...
  Cells: 5000
  Connections: 0 (0.00 per cell)
  Spikes: 39903 (7.98 Hz)
  Simulated time: 1.0 s; 4 workers
  Run time: 1373.25 s
--------------------------------------------------------------------------
An MPI process has executed an operation involving a call to the
"fork()" system call to create a child process.  Open MPI is currently
operating in a condition that could result in memory corruption or
other system errors; your MPI job may hang, crash, or produce silent
data corruption.  The use of fork() (or system() or other calls that
create child processes) is strongly discouraged.  

The process that invoked fork was:

  Local host:          comet-04-43 (PID 6045)
  MPI_COMM_WORLD rank: 0

If you are *absolutely sure* that your application will successfully
and correctly survive a call to fork(), you may disable this warning
by setting the mpi_warn_on_fork MCA parameter to 0.
--------------------------------------------------------------------------
Saving output as data/eee_net.json  ... 
Finished saving!
  Done; saving time = 18.57 s.
Plotting raster...
-------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code.. Per user-direction, the job has been aborted.
-------------------------------------------------------
--------------------------------------------------------------------------
orterun detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[13087,1],0]
  Exit code:    1
--------------------------------------------------------------------------


*** Discussion

Still no data/output...



** Running single sim locally 

In a temp dir, just to see what happens.

Reducing cells to 100.  Commit, push, then:

cd ; mkdir temp ; cd temp ; git clone https://github.com/Neurosim-lab/EEE_network.git ; cd EEE_network/mod ; nrnivmodl ; cd ../eee_net ; ln -s "../mod/x86_64" x86_64 ; ./runsim 4

So it worked locally.  A data dir was created and filled with data and figs.

I am going to set cfg.saveFigs to False.

Trying to run on zn.  Commit push and then the one-liner above.

Ugh.  Still no Pandas.

Taking a break.



* 2019-05-13 -- Seg faults in batch sims, output from single sims

** Looking at last set of batch sims

v01_batch10_comet

So most of the sims took only around 30 seconds -- something's not right.

But sim _2_1 timed out after two hours -- also not right.

Here are the output files:

	v01_batch10_comet_0_0.json
	v01_batch10_comet_0_2.json
	v01_batch10_comet_1_0.json
	v01_batch10_comet_1_1.json
	v01_batch10_comet_1_2.json
	v01_batch10_comet_2_0.json
	v01_batch10_comet_2_2.json

Some are missing: 

	_0_1
	_2_1


Looking at .run and .err files for _0_0, _0_1, and _2_1

*** _0_0 

Has an output file

**** .run

Everything looks okay until Netpyne analysis, when I get the fork error warning, and I
get a process with exit code 1


	Analyzing...
	  Cells: 1000
	  Connections: 0 (0.00 per cell)
	  Spikes: 7984 (7.98 Hz)
	  Simulated time: 1.0 s; 96 workers
	  Run time: 9.73 s
	--------------------------------------------------------------------------
	An MPI process has executed an operation involving a call to the
	"fork()" system call to create a child process.  Open MPI is currently
	operating in a condition that could result in memory corruption or
	other system errors; your MPI job may hang, crash, or produce silent
	data corruption.  The use of fork() (or system() or other calls that
	create child processes) is strongly discouraged.  

	The process that invoked fork was:

	  Local host:          comet-16-04 (PID 32312)
	  MPI_COMM_WORLD rank: 0

	If you are *absolutely sure* that your application will successfully
	and correctly survive a call to fork(), you may disable this warning
	by setting the mpi_warn_on_fork MCA parameter to 0.
	--------------------------------------------------------------------------
	Saving output as /oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/v01_batch10_comet/v01_batch10_comet_0_0.json  ... 
	Finished saving!
	  Done; saving time = 1.88 s.
	Plotting raster...
	-------------------------------------------------------
	Primary job  terminated normally, but 1 process returned
	a non-zero exit code.. Per user-direction, the job has been aborted.
	-------------------------------------------------------
	--------------------------------------------------------------------------
	orterun detected that one or more processes exited with non-zero status, thus causing
	the job to be terminated. The first process to do so was:

	  Process name: [[6609,1],0]
	  Exit code:    1
	--------------------------------------------------------------------------

**** .err

Looks like there's maybe a display problem:

	QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-jwgraham'
	qt.qpa.screen: QXcbConnection: Could not connect to display localhost:52.0
	Could not connect to any X display.

But that shouldn't affect simulation or saving.


**** Output file

Copying to local so I can take a look:

	scp jwgraham@comet.sdsc.edu://oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/v01_batch10_comet/v01_batch10_comet_0_0.json /Users/graham/comet_transfer/

The output looks fine, so I guess the sims run quite quickly with 96 cores.


*** _0_1

Doesn't have an output file

**** .run

Seems to have crashed during making connections

	Making connections...
	  Number of cells on node 15: 11 
	  Number of cells on node 6: 11 
	  ...
	  ...
	  ...
	-------------------------------------------------------
	Primary job  terminated normally, but 1 process returned
	a non-zero exit code.. Per user-direction, the job has been aborted.
	-------------------------------------------------------
	--------------------------------------------------------------------------
	orterun detected that one or more processes exited with non-zero status, thus causing
	the job to be terminated. The first process to do so was:

	  Process name: [[44242,1],52]
	  Exit code:    255
	--------------------------------------------------------------------------


**** .err

Huge file full of seg faults.


*** _2_1

Doesn't have an output file

**** .run

It just seems to have stopped while making cell connections, without an error in the 
run file.


**** .err

Massive error file with seg faults.


** Running another batch sim

I am going to run another batch sim to see if I get seg faults again.

It looks like the last batch may have only used 100 cells, looking on Comet to ensure

No, it was actually 1000 cells, so I'll bump up to 5000.

I will rename to v01_batch11

I deleted my old EEE_network on Comet and will reclone.

	git clone https://github.com/Neurosim-lab/EEE_network.git
	cd EEE_network/mod ; nrnivmodl
	cd ../eee_net ; ln -s "../mod/x86_64" x86_64

And now run the batch.

	python batch.py
	sq

             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          23407196   compute v01_batc jwgraham PD       0:00      4 (Priority)
          23407199   compute v01_batc jwgraham PD       0:00      4 (Priority)
          23407202   compute v01_batc jwgraham PD       0:00      4 (Priority)
          23407204   compute v01_batc jwgraham PD       0:00      4 (Priority)
          23407205   compute v01_batc jwgraham PD       0:00      4 (Priority)
          23407208   compute v01_batc jwgraham PD       0:00      4 (Priority)
          23407212   compute v01_batc jwgraham PD       0:00      4 (Priority)
          23407217   compute v01_batc jwgraham PD       0:00      4 (Priority)
          23407222   compute v01_batc jwgraham PD       0:00      4 (Priority)

Now to wait and see how these sims turn out.


** Improve README

To include preparation steps

New version:

	# EEE_network

	## Prepare for simulations

	1. Clone the repo (`git clone https://github.com/Neurosim-lab/EEE_network.git`)
	2. Compile the mod files (`cd EEE_network/mod ; nrnivmodl`)
	3. Symlink the mod dir (`cd ../eee_net ; ln -s "../mod/x86_64" x86_64`)

	Single line command:

	`git clone https://github.com/Neurosim-lab/EEE_network.git ; cd EEE_network/mod ; nrnivmodl ; cd ../eee_net ; ln -s "../mod/x86_64" x86_64`
		
	## Running simulations using MPI

	### To run a single sim using MPI 

	1. Change to the *eee_net* directory (`cd EEE_network/eee_net`)
	2. Modify *cfg.py*
		1. Update sim label
		2. Set desired parameter values
	3. Run the simulation (two options):
		1. Execute `runsim #processes` (e.g. `./runsim 4`)
		2. Execute `mpiexec -np #processes nrniv -python -mpi init.py` after replacing #processes with the number of processes you want to use (e.g. `mpiexec -np 4 nrniv -python -mpi init.py`)
		
	### To run a batch of sims using MPI 

	1. Change to the *eee_net* directory (`cd EEE_network/eee_net`)
	2. Open *batch.py*
		1. Ensure `runType = mpi_bulletin`
		2. Update the `batchLabel`
	3. Run the batch of sims (two options):
		1. Execute `runbatch #processes` (e.g. `./runbatch 4`)
		2. Execute `mpiexec -np #processes nrniv -python -mpi batch.py` (e.g. `mpiexec -np 4 nrniv -python -mpi batch.py`)

	## Running simulations on Comet

	### To run a single sim on Comet

	1. Change to the *eee_net* directory (`cd EEE_network/eee_net`)
	2. Modify *cfg.py*
		1. Update sim label
		2. Set desired parameter values
	3. Modify the file *runsim_comet* to desired HPC settings
	4. Execute `sbatch runsim_comet`

	### To run a batch of simulations on Comet

	1. Change to the *eee_net* directory (`cd EEE_network/eee_net`)
	2. Open *batch.py*
		1. Ensure `runType = hpc_slurm`
		2. Update the `batchLabel`
		3. Set desired HPC settings in `runCfg`
	5. Execute `python batch.py`


Committing and pushing to share README.


** Looking at new batch

v01_batch11

So on Friday 2/9 sims were seg faulty, on this batch 1/9 are.

I'll post this to Slack and ask others to run as well.



** Looking for single sim output

Running a single sim to see if I can find output.

label: eee_net_02

I will make a `data` dir in `eee_net` dir to ensure that's not reason for lack of output.

Updating cfg.py and runsim_comet

Commit, push, Comet.

co$ sbatch runsim_comet 
Submitted batch job 23408542


** Single sim

It seems to be only running on four cores

I am going to modify runsim_comet, from:

	ibrun -np 4 nrniv -python -mpi init.py

to:

	ibrun nrniv -python -mpi init.py

Now will run single sim eee_net_03

co$ sbatch runsim_comet 
Submitted batch job 23408828

It completed, and the output showed up in data.  :)

I'm going to increase number of cells to 10,000 and run as 04

co$ sbatch runsim_comet 
Submitted batch job 23409560

That finished.

For eee_net_05, I am increasing time to 10,000 ms

co$ sbatch runsim_comet 
Submitted batch job 23409694

Run time was only 23 minutes.

For eee_net_06, increasing time to 100,000 ms

co$ sbatch runsim_comet 
Submitted batch job 23414394

eee_net_06 timed out.


** Adding an easy number of cells config option

Old: 
cfg.numPT5cells = 8000
cfg.numPV5cells = 2000

New:
cfg.numCells = 10000
cfg.numPT5cells = int(0.8 * cfg.numCells)
cfg.numPV5cells = cfg.numCells - cfg.numPT5cells


** Running a big batch

v01_batch12

	params['EEconv'] = [1.5, 3.0, 6.0] # Default 3.0
	params['IEconv'] = [6.0, 12.0, 24.0] # Default 12.0
	params['numCells'] = [1000, 5000, 10000]

co$ python batch.py

	co$ sq
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          23414436   compute v01_batc jwgraham PD       0:00      4 (Priority)
          23414437   compute v01_batc jwgraham PD       0:00      4 (Priority)
          23414438   compute v01_batc jwgraham PD       0:00      4 (Priority)
          23414442   compute v01_batc jwgraham PD       0:00      4 (Priority)
          23414444   compute v01_batc jwgraham PD       0:00      4 (Priority)
          23414446   compute v01_batc jwgraham PD       0:00      4 (Priority)
          23414447   compute v01_batc jwgraham PD       0:00      4 (Priority)
          23414450   compute v01_batc jwgraham PD       0:00      4 (Priority)
          23414452   compute v01_batc jwgraham PD       0:00      4 (Priority)
          23414453   compute v01_batc jwgraham PD       0:00      4 (Priority)
          23414454   compute v01_batc jwgraham PD       0:00      4 (Priority)
          23414455   compute v01_batc jwgraham PD       0:00      4 (Priority)
          23414456   compute v01_batc jwgraham PD       0:00      4 (Priority)
          23414457   compute v01_batc jwgraham PD       0:00      4 (Priority)
          23414459   compute v01_batc jwgraham PD       0:00      4 (Priority)
          23414460   compute v01_batc jwgraham PD       0:00      4 (Priority)
          23414394   compute eee_net_ jwgraham  R       7:13      4 comet-25-[02,04,10,15]
          23414423   compute v01_batc jwgraham  R       0:22      4 comet-23-[49,56,63-64]
          23414424   compute v01_batc jwgraham  R       0:22      4 comet-25-[03,09,66-67]
          23414425   compute v01_batc jwgraham  R       0:22      4 comet-17-[34,52-53,66]
          23414426   compute v01_batc jwgraham  R       0:22      4 comet-18-[25-28]
          23414427   compute v01_batc jwgraham  R       0:22      4 comet-18-[29-32]
          23414428   compute v01_batc jwgraham  R       0:22      4 comet-18-[33-35,38]
          23414430   compute v01_batc jwgraham  R       0:22      4 comet-21-[04-05,07-08]
          23414432   compute v01_batc jwgraham  R       0:22      4 comet-21-[12,22,26-27]
          23414433   compute v01_batc jwgraham  R       0:22      4 comet-21-[29-31,37]
          23414434   compute v01_batc jwgraham  R       0:22      4 comet-21-[47,54,57,59]
          23414435   compute v01_batc jwgraham  R       0:22      4 comet-11-[35,70-71],comet-13-64

Those batches timed out.

Shortening sim time to 50000 ms
Increasing wall time to 4 hours
Turning glutamate puff back on


* 2019-05-14 -- Working on batch analysis, EEE meeting

** Currently working on 

generate analysis figures individually for sims in batch
altAx for Netpyne batch figures
batch figures

** Ran a big batch yesterday

v01_batch12

None completed.  Seems to be the same error in all sims.

Error:

	terminate called after throwing an instance of 'std::bad_alloc'
	  what():  std::bad_alloc
	[comet-23-15:15017] *** Process received signal ***
	[comet-23-15:15017] Signal: Aborted (6)
	[comet-23-15:15017] Signal code:  (-6)

In the run file, it completes the simulation but crashes while gathering data (similar
message for each sim):

	Running simulation for 50000 ms...
	  Done; run time = 8049.48 s; real-time ratio: 0.01.

	Gathering data...
	--------------------------------------------------------------------------
	orterun noticed that process rank 0 with PID 15017 on node comet-23-15 exited on signal 6 (Aborted).
	--------------------------------------------------------------------------

I'm guessing that there was too much data (this was set up to record from all cell somas).


** Running big batch with less time

v01_batch13

Reducing time to 5000

Batch params:

	params['EEconv'] = [1.5, 3.0, 6.0] # Default 3.0
	params['IEconv'] = [6.0, 12.0, 24.0] # Default 12.0
	params['numCells'] = [1000, 5000, 10000]

Commit, push, Comet.

*** JOBIDs

co$ sq
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          23425604   compute v01_batc jwgraham PD       0:00      4 (None)
          23425605   compute v01_batc jwgraham PD       0:00      4 (None)
          23425607   compute v01_batc jwgraham PD       0:00      4 (None)
          23425608   compute v01_batc jwgraham PD       0:00      4 (None)
          23425609   compute v01_batc jwgraham PD       0:00      4 (None)
          23425610   compute v01_batc jwgraham PD       0:00      4 (None)
          23425611   compute v01_batc jwgraham PD       0:00      4 (None)
          23425612   compute v01_batc jwgraham PD       0:00      4 (None)
          23425613   compute v01_batc jwgraham PD       0:00      4 (None)
          23425614   compute v01_batc jwgraham PD       0:00      4 (None)
          23425615   compute v01_batc jwgraham PD       0:00      4 (None)
          23425616   compute v01_batc jwgraham PD       0:00      4 (None)
          23425617   compute v01_batc jwgraham PD       0:00      4 (None)
          23425618   compute v01_batc jwgraham PD       0:00      4 (None)
          23425619   compute v01_batc jwgraham PD       0:00      4 (None)
          23425620   compute v01_batc jwgraham PD       0:00      4 (None)
          23425621   compute v01_batc jwgraham PD       0:00      4 (None)
          23425622   compute v01_batc jwgraham PD       0:00      4 (None)
          23425624   compute v01_batc jwgraham PD       0:00      4 (None)
          23425626   compute v01_batc jwgraham PD       0:00      4 (None)
          23425627   compute v01_batc jwgraham PD       0:00      4 (None)
          23425628   compute v01_batc jwgraham PD       0:00      4 (None)
          23425629   compute v01_batc jwgraham PD       0:00      4 (None)
          23425630   compute v01_batc jwgraham PD       0:00      4 (None)
          23425631   compute v01_batc jwgraham PD       0:00      4 (None)
          23425632   compute v01_batc jwgraham PD       0:00      4 (None)
          23425633   compute v01_batc jwgraham PD       0:00      4 (None)


** Running big long single sim

Trying to get a reproducible seg fault.

eee_net_07

cfg.duration = 10000
cfg.numCells = 10000    

co$ sbatch runsim_comet 
Submitted batch job 23425728


** Plotting analyses

Here are the batch outputs:

	co$ cdsc
	Changed to dir: /oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/
	co$ ls
	drwxr-xr-x 3 jwgraham shs100 41472 Apr 29 21:43 v01_batch03
	drwxr-xr-x 3 jwgraham shs100 41472 Apr 29 21:43 v01_batch04
	drwxr-xr-x 3 jwgraham shs100 41472 Apr 29 21:46 v01_batch05
	drwxr-xr-x 3 jwgraham shs100 33280 Apr 30 06:20 v01_batch06
	drwxr-xr-x 3 jwgraham shs100 41472 May  6 18:00 v01_batch07
	drwxr-xr-x 3 jwgraham shs100 41472 May  6 19:20 v01_batch08
	drwxr-xr-x 3 jwgraham shs100 41472 May  7 08:41 v01_batch09
	drwxr-xr-x 3 jwgraham shs100 41472 May 10 11:54 v01_batch10_comet
	drwxr-xr-x 3 jwgraham shs100 41472 May 13 10:07 v01_batch11
	drwxr-xr-x 3 jwgraham shs100 41472 May 13 20:14 v01_batch12
	drwxr-xr-x 3 jwgraham shs100 41472 May 14 07:10 v01_batch13

Batches that completed:

	v01_batch03
	v01_batch04
	v01_batch05
	v01_batch06
	v01_batch13

Batches with missing sims:

	v01_batch07 (only has _2_2, _3_2, _4_2)
	v01_batch08 (only has _0_0, _0_1, _2_0, _2_1)
	v01_batch09 (none completed)
	v01_batch10_comet (only has _0_0, _0_2, _1_0, _1_1, _1_2, _2_0, _2_2)
	v01_batch11 (missing _2_1)
	v01_batch12 (all missing)

Working in dev.py


** EEE Meeting

Sodium channel
Only difference is temperature dependence
Penny doesn’t see other diffs
Looks fine to Penny, Srdjan and Bill should weigh in
Simulation updates
Joe updated EEE README, shows how to run single sims and batches using MPI or Comet (please try!)
Pip install netpyne handles all dependencies
Netpyne needs: install_requires=[‘numpy’, ‘scipy’, ‘matplotlib’, ‘matplotlib-scalebar’, ‘future’, ‘pandas>=0.23’]
Can install local versions using pip install --target
Works for Joe locally and on Comet (Neurosim machines still need Pandas)
To switch to py3
py3env
Decreased number of processors to 96
Still getting some seg faults in batches (2/9, 1/9, 0/12)
Ran batch of big, long sims, got error:
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
[comet-23-15:15017] *** Process received signal ***
[comet-23-15:15017] Signal: Aborted (6)
[comet-23-15:15017] Signal code:  (-6)
Due to too much data? Salva: yes

Other items?

Pandas still not installed on Neurosim (check if works on py3: use py3env)
Google cloud is up and running
Salva: if you re-run batches with seg faults, Netpyne will re-try failed sims
Article submission
Srdjan: Busy teaching, not much time for paper
Back to working on paper
Reviewer concerns:
Effect on Tau driven by membrane voltage?
How does moving plateau potential along dendrite affect tau?
Wants to simplify figures -- only include most important stuff
Srdjan and Penny discuss figures today

Action items for next week

Salva gets Joe and Don onto Google cloud
Batch analyses to explore


** Re-running batches with missing sims

I'll try it with v01_batch07 (only has _2_2, _3_2, _4_2)

I'll need the original batch.py file...

Looking at the git log

	commit ea8360a5bc1cda2fd4b80f4a410f439f3c4e49a6
	Author: graham <joe.w.graham@gmail.com>
	Date:   Mon May 6 15:56:44 2019 -0700

	    Running big Comet sim v01_batch07 take 2

I think I'll clone the repo at that commit in a temp dir and try re-running the batch.



* 2019-06-03 -- Batch analysis

** Currently working on 

generate analysis figures individually for sims in batch
altAx for Netpyne batch figures
batch figures


** Updating password

New password works on no.  Trying to connect to my

	ssgraham-mac:~ graham$ sshmy
	graham@no.neurosim.downstate.edu's password: 
	Warning: No xauth data; using fake authentication data for X11 forwarding.
	@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
	@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @
	@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
	IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!
	Someone could be eavesdropping on you right now (man-in-the-middle attack)!
	It is also possible that a host key has just been changed.
	The fingerprint for the ECDSA key sent by the remote host is
	SHA256:NKciHzkThCn7HaOw0/etMLQWsPvCtn4eG76eGKo6i3E.
	Please contact your system administrator.
	Add correct host key in /u/graham/.ssh/known_hosts to get rid of this message.
	Offending ECDSA key in /u/graham/.ssh/known_hosts:5
	  remove with:
	  ssh-keygen -f "/u/graham/.ssh/known_hosts" -R "my"
	ECDSA host key for my has changed and you have requested strict checking.
	Host key verification failed.
	Connection to no.neurosim.downstate.edu closed.
	graham-mac:~ graham$ 

	graham-mac:~ graham$ ssh-keygen -f "/u/graham/.ssh/known_hosts" -R "my"
	mkstemp: No such file or directory

Ah, have to do it on `no`

	no% ssh-keygen -f "/u/graham/.ssh/known_hosts" -R "my"
	# Host my found: line 5
	/u/graham/.ssh/known_hosts updated.
	Original contents retained as /u/graham/.ssh/known_hosts.old
	no% 

Now I can connect to `my`

	graham-mac:~ graham$ sshmy
	graham@no.neurosim.downstate.edu's password: 
	Warning: No xauth data; using fake authentication data for X11 forwarding.
	The authenticity of host 'my (138.5.101.142)' can't be established.
	ECDSA key fingerprint is SHA256:NKciHzkThCn7HaOw0/etMLQWsPvCtn4eG76eGKo6i3E.
	Are you sure you want to continue connecting (yes/no)? yes
	Warning: Permanently added 'my' (ECDSA) to the list of known hosts.
	Warning: the ECDSA host key for 'my' differs from the key for the IP address '138.5.101.142'
	Offending key for IP in /u/graham/.ssh/known_hosts:5
	Are you sure you want to continue connecting (yes/no)? yes
	graham@my's password: 
	my%

Now to connect to `zn`.  It works.


** Starting by analyzing v01_batch03

Param values:

	params['EEconv'] = [0.0, 3.0, 6.0] # Default 3.0
	params['IEconv'] = [0.0, 12.0, 24.0] # Default 12.0

I'll create some code that generates a figure for each sim.

Working in dev.py

There's a problem with connectivity... plotConn shows all 0 matrix...

Looking into if there is any connectivity...

Maybe because in my cfg file: cfg.saveCellConns = False

Setting it to true and preparing to run v01_batch14

** v01_batch14

co$ sq
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          23805947   compute v01_batc jwgraham  R       0:03      4 comet-20-[25,29,31,35]
          23805948   compute v01_batc jwgraham  R       0:03      4 comet-12-[01-02,04-05]
          23805941   compute v01_batc jwgraham  R       0:07      4 comet-22-[08-09,43,49]
          23805942   compute v01_batc jwgraham  R       0:07      4 comet-13-[31,36-37,40]
          23805944   compute v01_batc jwgraham  R       0:07      4 comet-13-[44-45,47-48]
          23805945   compute v01_batc jwgraham  R       0:07      4 comet-20-[01,06,10,15]
          23805939   compute v01_batc jwgraham  R       0:14      4 comet-14-[09,12,26,30]
          23805940   compute v01_batc jwgraham  R       0:14      4 comet-19-[02,67-69]
          23805937   compute v01_batc jwgraham  R       0:18      4 comet-10-[10,13,20,34]


** v01_batch15

Will run v01_batch15 overnight, with params['numCells'] = [1000, 5000, 10000] to see how
number of cells affects connectivity.


** 'v01_batch16'

'v01_batch16' with params['numCells'] = [10000, 20000, 30000]

co$ sq
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          23806547   compute v01_batc jwgraham  R       2:32      4 comet-16-[07,13-14,18]
          23806548   compute v01_batc jwgraham  R       2:32      4 comet-17-[04,18,22,38]
          23806546   compute v01_batc jwgraham  R       2:41      4 comet-29-[01,04,09-10]
          23806561   compute v01_batc jwgraham  R       0:10      4 comet-07-[29,31,34,36]
          23806560   compute v01_batc jwgraham  R       0:18      4 comet-23-[25,54,56,59]
          23806559   compute v01_batc jwgraham  R       0:20      4 comet-21-[11,14,40,46]



* 2019-06-04 -- Batch analysis

** Currently working on 

generate analysis figures individually for sims in batch
altAx for Netpyne batch figures
batch figures

** Downloading and analyzing batch sims

graham-mac:~ graham$ cpsc v01_batch15
Attempting to copy: v01_batch15
  From: comet.sdsc.xsede.org/oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/
  To  : /Users/graham/EEE_network/eee_net/v01_batch15

graham-mac:~ graham$ cpsc v01_batch16
Attempting to copy: v01_batch16
  From: comet.sdsc.xsede.org/oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/
  To  : /Users/graham/EEE_network/eee_net/v01_batch16

graham-mac:~ graham$ cdeee ; ipython -i dev.py

*** Strange error

Which I didn't get before...

	graham-mac:~ graham$ cdeee ; ipython -i dev.py
	Python 3.7.1 (default, Dec 14 2018, 13:28:58) 
	Type 'copyright', 'credits' or 'license' for more information
	IPython 7.2.0 -- An enhanced Interactive Python. Type '?' for help.
	Reading data...
	0 files missing
	(0,) (1000,)
	numCells = 1000
	v01_batch15_0
	Loading file data/v01_batch15/v01_batch15_0.json ... 
	  Done; file loading time = 20.15 s
	Loading simConfig...
	Loading netParams...
	Loading net...
	Loading simData...
	---------------------------------------------------------------------------
	KeyError                                  Traceback (most recent call last)
	~/EEE_network/eee_net/dev.py in <module>
	    114 
	    115 include = ['PT5_1', 'PT5_2', 'PT5_3', 'PT5_4', 'PV5']
	--> 116 plot_batch_ind_conn("v01_batch15") #, includePre=include, includePost=include, saveFig=True)
	    117 #plot_batch_ind_conn("v01_batch15", includePre=include, includePost=include, saveFig=True)
	    118 #plot_batch_ind_conn("v01_batch16", includePre=include, includePost=include, saveFig=True)

	~/EEE_network/eee_net/dev.py in plot_batch_ind_conn(batchLabel, batchdatadir, includePre, includePost, feature, orderBy, figSize, groupBy, groupByIntervalPre, groupByIntervalPost, graphType, synOrConn, synMech, connsFile, tagsFile, clim, fontSize, saveData, saveFig, showFig, save, outputdir, filename, **kwargs)
	     95             simFile = simLabel + ".json"
	     96 
	---> 97             sim.load(batchdatadir + '/' + batchLabel + '/' + simFile, instantiate=False)
	     98 
	     99             if saveFig:

	~/Applications/netpyne/netpyne/sim/wrappers.py in load(filename, simConfig, output, instantiate, createNEURONObj)
	    128         rxd = sim.net.addRxD()                    # add reaction-diffusion (RxD)
	    129 
	--> 130     simData = sim.setupRecording()              # setup variables to record for each cell (spikes, V traces, etc)
	    131 
	    132     if output:

	~/Applications/netpyne/netpyne/sim/setup.py in setupRecording()
	    259         # get list of cells from argument of plotTraces function
	    260         if 'plotTraces' in sim.cfg.analysis and 'include' in sim.cfg.analysis['plotTraces']:
	--> 261             cellsPlot = utils.getCellsList(sim.cfg.analysis['plotTraces']['include'])
	    262         else:
	    263             cellsPlot = []

	~/Applications/netpyne/netpyne/sim/utils.py in getCellsList(include, returnGids)
	     68 
	     69         elif isinstance(condition, basestring):  # entire pop
	---> 70             cellGids.extend(list(sim.net.pops[condition].cellGids))
	     71 
	     72         elif isinstance(condition, tuple) or isinstance(condition, list):  # subset of a pop with relative indices

	~/Applications/netpyne/netpyne/specs/dicts.py in __getitem__(self, k)
	    182 
	    183     def __getitem__(self, k):
	--> 184         return super(ODict, self).__getitem__(k)
	    185 
	    186 

	KeyError: 'PT5_1'


** Looking into error

First, let's see what the data looks like when it's loaded as a batch or from individual
batch sims.

So it looks like readBatchData uses json.load to load each sim output file into a 
dict entry (e.g. '_0_0', '_0_1', etc.)

It looks like sim.load does the same thing.  Let's actually load and compare.



* 2019-06-09 -- Batch analysis

** Currently working on 

generate analysis figures individually for sims in batch
altAx for Netpyne batch figures
batch figures

** Simplify plot_batch_ind_conn

*** Old code

def plot_batch_ind_conn(batchLabel, batchdatadir='data', includePre = ['all'], includePost = ['all'], feature = 'strength', orderBy = 'gid', figSize = (10,10), groupBy = 'pop', groupByIntervalPre = None, groupByIntervalPost = None, graphType = 'matrix', synOrConn = 'syn', synMech = None, connsFile = None, tagsFile = None, clim = None, fontSize = 12, saveData = None, saveFig = None, showFig = True, save=True, outputdir="batch_figs", filename=None, **kwargs):
    """Plots individual raster plots for each parameter combination."""

    if type(batchLabel) == str:
        params, data = batch_utils.load_batch(batchLabel, batchdatadir=batchdatadir)
    elif type(batchLabel) == tuple:
        batchLabel, params, data = batchLabel
    else:
        raise Exception()

    groupedParams = False
    ungroupedParams = False

    for p in params:
        if 'group' not in p: 
            p['group'] = False
            ungroupedParams = True
        elif p['group'] == True: 
            groupedParams = True

    if ungroupedParams:
        labelList, valuesList = zip(*[(p['label'], p['values']) for p in params if p['group'] == False])
        valueCombinations = list(product(*(valuesList)))
        indexCombinations = list(product(*[range(len(x)) for x in valuesList]))
    else:
        valueCombinations = [(0,)] # this is a hack -- improve!
        indexCombinations = [(0,)]
        labelList = ()
        valuesList = ()

    if groupedParams:
        labelListGroup, valuesListGroup = zip(*[(p['label'], p['values']) for p in params if p['group'] == True])
        valueCombGroups = zip(*(valuesListGroup))
        indexCombGroups = zip(*[range(len(x)) for x in valuesListGroup])
        labelList = labelListGroup+labelList
    else:
        valueCombGroups = [(0,)] # this is a hack -- improve!
        indexCombGroups = [(0,)]

    for iCombG, pCombG in zip(indexCombGroups, valueCombGroups):
        for iCombNG, pCombNG in zip(indexCombinations, valueCombinations):
            if groupedParams and ungroupedParams: # temporary hack - improve
                iComb = iCombG+iCombNG
                pComb = pCombG+pCombNG
            elif ungroupedParams:
                iComb = iCombNG
                pComb = pCombNG
            elif groupedParams:
                iComb = iCombG
                pComb = pCombG
            else:
                iComb = []
                pComb = []
                
            print(iComb, pComb)

            for i, paramVal in enumerate(pComb):
                paramLabel = labelList[i]
                print(str(paramLabel)+' = '+str(paramVal))

            simLabel = batchLabel +''.join([''.join('_'+str(i)) for i in iComb])
            print(simLabel)

            simFile = simLabel + ".json"

            sim.load(batchdatadir + '/' + batchLabel + '/' + simFile, instantiate=False)

            if saveFig:
           		saveFig = batchdatadir + '/' + batchLabel + '/' + 'connFig_' + simLabel + '.png'

            sim.analysis.plotConn(includePre=includePre, includePost=includePost, feature=feature, orderBy=orderBy, figSize=figSize, groupBy=groupBy, groupByIntervalPre=groupByIntervalPre, groupByIntervalPost=groupByIntervalPost, graphType=graphType, synOrConn=synOrConn, synMech=synMech, connsFile=connsFile, tagsFile=tagsFile, clim=clim, fontSize=fontSize, saveData=saveData, saveFig=saveFig, showFig=showFig)

*** New code

Will use sim.loadAll in a loop over the sims in the batch.


** Need new batches

v01_batch06 doesn't have the connectivity data, and v01_batch16 doesn't vary connectivity.

Running a new batch.

v01_batch17

	params['EEconv'] = [0.0, 3.0, 6.0] # Default 3.0
	params['IEconv'] = [0.0, 12.0, 24.0] # Default 12.0

	cfg.duration = 10000
	cfg.numCells = 1000        

co$ sq
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          23941944   compute v01_batc jwgraham  R       0:02      4 comet-14-[57-58,60-61]
          23941942   compute v01_batc jwgraham  R       0:06      4 comet-04-[69-72]
          23941943   compute v01_batc jwgraham  R       0:06      4 comet-14-[53-56]
          23941941   compute v01_batc jwgraham  R       0:09      4 comet-04-[59-60,62,68]
          23941938   compute v01_batc jwgraham  R       0:11      4 comet-22-[05,08,30,50]
          23941939   compute v01_batc jwgraham  R       0:11      4 comet-04-[51-52,56-57]
          23941935   compute v01_batc jwgraham  R       0:16      4 comet-20-[07,12-13,37]
          23941936   compute v01_batc jwgraham  R       0:16      4 comet-05-[09,11,15-16]
          23941937   compute v01_batc jwgraham  R       0:16      4 comet-10-[24-25,41,52]


Downloading data

	graham$ cpsc v01_batch17
	Attempting to copy: v01_batch17
	  From: comet.sdsc.xsede.org/oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/
	  To  : /Users/graham/EEE_network/eee_net/data/v01_batch17


** Running v01_batch18

Same as 17, but for only 1000 ms, to have a quick batch to debug analysis with

Downloading.


** Plotting 

Running dev.py right now plots all the various connectivity features for each sim in batch18

It's great to be able to see them all, but comparison is difficult because the scale is 
different on each...  Need to look into how to set scale the same for all sims...

I also want to plot for all sims: raster plot and spike stats

	stats: List of types measure to calculate stats over: cell firing rates, interspike interval coefficient of variation (ISI CV), pairwise synchrony, and/or overall synchrony (sync measures calculated using PySpike SPIKE-Synchrony measure) ([‘rate’, |'isicv'| ‘pairsync’ |'sync'|])

But committing for now.

In particular, I want to measure synchrony during plateaus in plat and non-plat cells.

** Running v01_batch19

Increasing number of cells to 10,000

** Running v01_batch20

Same as 19, except:
cfg.saveCellConns = False #True

To reduce data.


* 2019-06-10 -- Batch analysis

** Currently working on 

generate analysis figures individually for sims in batch
altAx for Netpyne batch figures
batch figures

** Plotting connectivity

It is literally taking all day to plotConn on v01_batch19 (10,000 cells).

I should profile the code and see what is taking so long.  But first I want to get
raster plots and stats plots.

Also, would like to rescale all figs to same limits, so easier to compare.

Also, would like to include batch param labels and values in plot title.

But first to get more analysis going.


** Plotting individual raster plots

Working in dev.py on plot_batch_ind_raster

Got it working. Running dev.py generates raster plots for v01_batch20.

Committing.


** Plotting stats

Working in dev.py on plot_batch_ind_stats

Error: plotSpikeStats() requires the PySpike python package to calculate synchrony (try: pip install pyspike)

Got a strange error with `pip install pyspike`

Installed from git (http://mariomulansky.github.io/PySpike/):

	git clone https://github.com/mariomulansky/PySpike.git
	cd PySpike
	python setup.py build_ext --inplace

	Finally, you should make PySpike’s installation folder known to Python to be able to import pyspike in your own projects. Therefore, add your /path/to/PySpike to the $PYTHONPATH environment variable.

Added the following to my .bash_profile
	export PYTHONPATH="/Users/graham/Applications/PySpike:$PYTHONPATH"

Now it works.  Committing.



* 2019-06-11 -- Batch analysis and EEE meeting

** Currently working on 

generate analysis figures individually for sims in batch
altAx for Netpyne batch figures
batch figures

** Exploring synchrony

Want to plot synchrony for each pop during plateau

Should look at traces to ensure plateaus and choose time window

Plotting traces for v01_batch20

	batch_analysis.plot_vtraces(batchData)

Now to run spike stat synchrony for timerange = [200, 400]

** EEE meeting

https://docs.google.com/document/d/1ic7jF4aou7vLQcL8gHjmkbYtFkeL3IAXjRTp0FVh6Uc/edit

Discussion:

Very slow plotting
	Use neurosim machines for analyzing/plotting
	May not have enough memory
Rate plotting
	Low average with high inds looks like a bug
	Raster plot, show only portion of pops (too much now)
	Check rates myself, compare with Netpyne measures
	A lot more spacing in y-axis
	Raster more interesting with fewer cells (just cells of interest)
Look into numConns
	Check conns in single cell, compare with Netpyne
Synchronization measure in Netpyne
	Odd that 1 and 2 (get plateaus) have lower sync
	Need to look into
Raster and spike stats freq don’t seem to match up


** Currently working on

Get analysis/plotting going on Neurosim machines
Individual plots from batch
	Rescale all figs to same limits, so easier to compare
	Include batch param labels and values in plot title
Batch figures
	Get batch raster plot working
	Implement altAx in Netpyne
	Get conn plot working (all same scale)
Check rates in single cells, compare with Netpyne analysis
Look into numConns, explore in single cells
Look into synchrony measures


* 2019-08-06 -- EEE meeting

** Meeting agenda and notes

Today’s agenda

Upcoming deadlines
SfN meeting poster	
October 19
https://www.sfn.org/Meetings/Neuroscience-2019
Abstract (also copied below)
Network modeling

Single cell article resubmission updates

CNS meeting

Moving forward with network simulations
Need synchronization measures
Joe will work on measuring synchrony in two cell pops: with and without induced plateaus
syncLines option in raster plots
plotSpikeStats options: ‘pairsync’ and ‘sync’
Any other existing synchrony measures?
Other things to work on?

Other items?

Discussion

Single cell article updates
Huge progress
No changes fig 1, 2
Fig 3 -- condensed information
Fig 4 -- improve size and clutter
Fig 5 -- simplified, added cartoon
Fig 6 -- positive pulses smaller during plateau, negative pulses same size
Model doesn’t match precise voltage changes, taus from real neurons
Interesting to Srdjan: positive pulse smaller, reaches amplitude sooner
Some taus slower, some faster during plateau
Why difference between positive and negative pulses?
Ready to deliver manuscript today
Model results pretty good! Qualitative rather than quantitative comparisons.
Supp figures essentially the same -- more detail than article figs
Srdjan would like light editing
Perhaps submit to Nature Communications
	
CNS meeting
Lots of young interest, not too much advice/critiques

Moving forward with network simulations
Synchrony measures
Hoping plats emerge spontaneously with long large sims, requires analysis program to find them
Combine prolonged activity with plateau stims at certain times (random or configured, perhaps this will trigger spontaneous plateaus)
Same set of neurons driving certain cells during plats, others without plats
Srdjan: make as simple as possible, find one network parameter that significantly changes when cells get plateaus, compare with network where cells don’t have plateaus
Question between absolutely same networks versus need for different networks to have plateau differences
Bill: get phenomenology first (gumball machine -- cells lighting up, synching during plateaus)
Srdjan: look for ensembles, compare with and without plateaus
Run for long periods, use up HPC (Comet and Stampede)


* 2019-08-08 -- Aborted reentry into EEE

** Diving back into EEE

Steps to take now:

Commit and push to repo
Pull repo and follow README
Run single sim on Comet
Run batch sims on Comet


*** Commit and push

Done.  Now cloning into Neurosim and copying over nb_gif.

scp -r nb_gif graham@no.neurosim.downstate.edu:/u/graham/EEE_network/nb_gif


*** Pull repo and follow README

cd /u/graham
git clone https://github.com/Neurosim-lab/EEE_network.git
cd EEE_network/mod ; nrnivmodl
cd ../eee_net ; ln -s "../mod/x86_64" x86_64

Everything seems to work.


* 2019-08-09 -- Reentry into EEE

** To do now:

Run single sim on Comet
Run batch sims on Comet

** Run single sim on Comet

Just making sure everything still works.

Running eee_net_08, modified cfg.py and runsim_comet accordingly.

Existing alias:
alias sshc='ssh -Y jwgraham@comet.sdsc.edu'

sshc
mv EEE_network EEE_network_old
git clone https://github.com/Neurosim-lab/EEE_network.git
cd EEE_network/mod ; nrnivmodl
cd ../eee_net ; ln -s "../mod/x86_64" x86_64

Whoops.  Need to commit and push, then pull from Comet.

sshc
cd EEE_network/eee_net
git pull 
sbatch runsim_comet
Submitted batch job 25574184


** Run batch of sims on Comet

Modifying batch.py:
batchLabel = 'v01_batch21'

Committing and pushing, then pulling from Comet and running:

sshc
cd EEE_network/eee_net
git pull
python batch.py

Jobs are all pending:

co$ sq
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          25574184   compute eee_net_ jwgraham PD       0:00      4 (Resources)
          25574244   compute v01_batc jwgraham PD       0:00      4 (Resources)
          25574245   compute v01_batc jwgraham PD       0:00      4 (Resources)
          25574247   compute v01_batc jwgraham PD       0:00      4 (Resources)
          25574248   compute v01_batc jwgraham PD       0:00      4 (Resources)
          25574249   compute v01_batc jwgraham PD       0:00      4 (Resources)
          25574250   compute v01_batc jwgraham PD       0:00      4 (Resources)
          25574251   compute v01_batc jwgraham PD       0:00      4 (Resources)
          25574252   compute v01_batc jwgraham PD       0:00      4 (Resources)
          25574253   compute v01_batc jwgraham PD       0:00      4 (Resources)


** Prepare interesting sim looking for synchrony

While waiting on Comet to complete, I'll start working on a longer sim that does the 
following (4 pops total):

pop 1: nothing
pop 1: 5 inputs
pop 1: plateau
pop 1: plateau + 5 inputs

pops 1+2: same as above

pops 1+2+3: same as above

pops 1+2+3+4: same as above

Then measure synchrony within each pop and across all pops

Working on code in eee_net_09

Increasing sim duration: cfg.duration = 10000



* 2019-08-09 -- Sunday afternoon Comet submissions

** The ind sim and batch sims finally ran

All with exit code 0, average time 3.5 minutes

Except SLURM Job_id=25574251 Name=v01_batch21_2_0 Ended, Run time 00:00:45

Looking into output

*** eee_net_08

Took 3:38 to run

eee_net_08.err and eee_net_08.run show up in EEE_network/eee_net

Can change output location in runsim_comet

eee_net_08.json shows up in /EEE_network/eee_net/data ('data' dir is set in cfg file)

This output file is 395 MB and seems good.


*** v01_batch21

Output appears in /oasis/scratch/comet/jwgraham/temp_project/EEE_network/eee_net/v01_batch21

All sims took about 3.5 minutes to complete, and each has about 395 MB in output json file,
and has small .err files

Except: 
	Name=v01_batch21_2_0 Ended, Run time 00:00:45

	-rw-r--r-- 1 jwgraham shs100      7540 Aug  9 10:57 v01_batch21_2_0_cfg.json
	-rw-r--r-- 1 jwgraham shs100  63931413 Aug 10 00:27 v01_batch21_2_0.err
	-rw-r--r-- 1 jwgraham shs100     43030 Aug 10 00:27 v01_batch21_2_0.run
	-rw-r--r-- 1 jwgraham shs100       764 Aug  9 10:57 v01_batch21_2_0.sbatch

This one had tiny output file and large .err file

Looking at .err file

It's the seg faults that we were getting earlier (before switching to only 96 cores):

	[comet-26-46:15676] *** Process received signal ***
	[comet-26-46:15676] Signal: Segmentation fault (11)
	[comet-26-46:15676] Signal code:  (0)
	[comet-26-46:15676] Failing at address: (nil)
	[comet-26-46:15676] [ 0] /lib64/libc.so.6[0x3328832570]
	[comet-26-46:15676] [ 1] /opt/openmpi/gnu/ib/lib/libmpi.so.1(+0x113a5e)[0x2b66ac0e4a5e]
	[comet-26-46:15676] [ 2] /opt/openmpi/gnu/ib/lib/libmpi.so.1(+0x113cbc)[0x2b66ac0e4cbc]
	[comet-26-46:15676] [ 3] /opt/openmpi/gnu/ib/lib/libmpi.so.1(+0x10b488)[0x2b66ac0dc488]
	[comet-26-46:15676] [ 4] /lib64/libpthread.so.0[0x3329007aa1]
	[comet-26-46:15676] [ 5] /lib64/libc.so.6(clone+0x6d)[0x33288e8c4d]
	[comet-26-46:15676] *** End of error message ***

I am going to submit the same batch again to see if we get seg fault on the same sim

** Submitting batch to see if seg fault happens

Updating batch label: batchLabel = 'v01_batch22'
Dropping wall time to 30 min for quicker queueing

Committing, pushing, submitting to Comet.

Wow, they ran almost immediately.  Weekend queues are short.

This time there was no seg fault, all sims ran fine.



* 2019-08-12 -- Working on sync analyses

** Analysis needs

Need to figure out analyses on Comet -- too slow to download large outputs and
analyze locally

Need synchrony measures
Need plateau detection

Working locally, running small sim, then getting analyses going

Once it works locally, will try on Comet

** Working locally

Running single sim with 100 cells: eee_net_09

	cd EEE_network/eee_net
	./runsim 4

run time = 15.05 s
output size = 4.4 MB

Running sim with 1000 cells: eee_net_10

run time = 266.93 s
output size = 39.9 MB

** Analyzing locally

*** Loading data incorrectly

from netpyne import sim
sim.load('eee_net_09.json')
	
	Loading file eee_net_09.json ... 
	  Done; file loading time = 0.04 s
	Loading simConfig...
	Loading netParams...
	Loading net...
	  Created 100 cells
	  Created 0 connections
	  Created 2880 stims
	---------------------------------------------------------------------------
	AttributeError                            Traceback (most recent call last)
	<ipython-input-10-513f73834fcd> in <module>()
	----> 1 sim.load('eee_net_09.json')

	/usr/site/nrniv/local/python/anaconda3/lib/python3.7/site-packages/netpyne/sim/wrappers.py in load(filename, simConfig, output, instantiate, createNEURONObj)
	     88     sim.initialize()  # create network object and set cfg and net params
	     89     sim.cfg.createNEURONObj = createNEURONObj
	---> 90     sim.loadAll(filename, instantiate=instantiate, createNEURONObj=createNEURONObj)
	     91     if simConfig: sim.setSimCfg(simConfig)  # set after to replace potentially loaded cfg
	     92     if len(sim.net.cells) == 0 and instantiate:

	/usr/site/nrniv/local/python/anaconda3/lib/python3.7/site-packages/netpyne/sim/load.py in loadAll(filename, data, instantiate, createNEURONObj)
	    284         print('Error: no connFormat provided in simConfig')
	    285         sys.exit()
	--> 286     loadNet(filename, data=data, instantiate=instantiate, compactConnFormat=connFormat)
	    287     loadSimData(filename, data=data)
	    288 

	/usr/site/nrniv/local/python/anaconda3/lib/python3.7/site-packages/netpyne/sim/load.py in loadNet(filename, data, instantiate, compactConnFormat)
	    233                     for cell in sim.net.cells:
	    234                         prop = {'secs': cell.secs}
	--> 235                         cell.createNEURONObj(prop)  # use same syntax as when creating based on high-level specs
	    236                         cell.associateGid()  # can only associate once the hSection obj has been created
	    237                     # create all NEURON Netcons, NetStims, etc

	/usr/site/nrniv/local/python/anaconda3/lib/python3.7/site-packages/netpyne/cell/compartCell.py in createNEURONObj(self, prop)
	    400                     if pointpName not in sec['pointps']:
	    401                         sec['pointps'][pointpName] = Dict()
	--> 402                     pointpObj = getattr(h, pointpParams['mod'])
	    403                     loc = pointpParams['loc'] if 'loc' in pointpParams else 0.5  # set location
	    404                     sec['pointps'][pointpName]['hObj'] = pointpObj(loc, sec = sec['hObj'])  # create h Pointp object (eg. h.Izhi2007b)

	AttributeError: 'hoc.HocObject' object has no attribute 'Gfluctp'

*** Loading data incorrectly

Maybe if I load from eee_net, where the mod symlink is...

from netpyne import sim
sim.load('data/eee_net_09.json')

	Loading file data/eee_net_09.json ... 
	  Done; file loading time = 0.04 s
	Loading simConfig...
	Loading netParams...
	Loading net...
	  Created 100 cells
	  Created 0 connections
	  Created 2880 stims
	---------------------------------------------------------------------------
	LookupError                               Traceback (most recent call last)
	<ipython-input-3-2b63cf57ac72> in <module>()
	----> 1 sim.load('data/eee_net_09.json')

	/usr/site/nrniv/local/python/anaconda3/lib/python3.7/site-packages/netpyne/sim/wrappers.py in load(filename, simConfig, output, instantiate, createNEURONObj)
	     88     sim.initialize()  # create network object and set cfg and net params
	     89     sim.cfg.createNEURONObj = createNEURONObj
	---> 90     sim.loadAll(filename, instantiate=instantiate, createNEURONObj=createNEURONObj)
	     91     if simConfig: sim.setSimCfg(simConfig)  # set after to replace potentially loaded cfg
	     92     if len(sim.net.cells) == 0 and instantiate:

	/usr/site/nrniv/local/python/anaconda3/lib/python3.7/site-packages/netpyne/sim/load.py in loadAll(filename, data, instantiate, createNEURONObj)
	    284         print('Error: no connFormat provided in simConfig')
	    285         sys.exit()
	--> 286     loadNet(filename, data=data, instantiate=instantiate, compactConnFormat=connFormat)
	    287     loadSimData(filename, data=data)
	    288 

	/usr/site/nrniv/local/python/anaconda3/lib/python3.7/site-packages/netpyne/sim/load.py in loadNet(filename, data, instantiate, compactConnFormat)
	    233                     for cell in sim.net.cells:
	    234                         prop = {'secs': cell.secs}
	--> 235                         cell.createNEURONObj(prop)  # use same syntax as when creating based on high-level specs
	    236                         cell.associateGid()  # can only associate once the hSection obj has been created
	    237                     # create all NEURON Netcons, NetStims, etc

	/usr/site/nrniv/local/python/anaconda3/lib/python3.7/site-packages/netpyne/cell/compartCell.py in createNEURONObj(self, prop)
	    407                             pointpParamValue = self.gid
	    408                         if pointpParamName not in ['mod', 'loc', 'vref', 'synList'] and not pointpParamName.startswith('_'):
	--> 409                             setattr(sec['pointps'][pointpName]['hObj'], pointpParamName, pointpParamValue)
	    410 
	    411         # set topology

	LookupError: 'hObj' is not a defined hoc variable name.

A different error...

Maybe if I try not instantiating...

*** Loading data incorrectly

sim.load('data/eee_net_09.json', instantiate=False)

	Loading file data/eee_net_09.json ... 
	  Done; file loading time = 0.04 s
	Loading simConfig...
	Loading netParams...
	Loading net...
	Loading simData...
	---------------------------------------------------------------------------
	KeyError                                  Traceback (most recent call last)
	<ipython-input-4-8fa3e8d346d3> in <module>()
	----> 1 sim.load('data/eee_net_09.json', instantiate=False)

	/usr/site/nrniv/local/python/anaconda3/lib/python3.7/site-packages/netpyne/sim/wrappers.py in load(filename, simConfig, output, instantiate, createNEURONObj)
	     97         rxd = sim.net.addRxD()                    # add reaction-diffusion (RxD)
	     98 
	---> 99     simData = sim.setupRecording()              # setup variables to record for each cell (spikes, V traces, etc)
	    100 
	    101     if output:

	/usr/site/nrniv/local/python/anaconda3/lib/python3.7/site-packages/netpyne/sim/setup.py in setupRecording()
	    257         # get list of cells from argument of plotTraces function
	    258         if 'plotTraces' in sim.cfg.analysis and 'include' in sim.cfg.analysis['plotTraces']:
	--> 259             cellsPlot = utils.getCellsList(sim.cfg.analysis['plotTraces']['include'])
	    260         else:
	    261             cellsPlot = []

	/usr/site/nrniv/local/python/anaconda3/lib/python3.7/site-packages/netpyne/sim/utils.py in getCellsList(include, returnGids)
	     68 
	     69         elif isinstance(condition, basestring):  # entire pop
	---> 70             cellGids.extend(list(sim.net.pops[condition].cellGids))
	     71 
	     72         elif isinstance(condition, tuple) or isinstance(condition, list):  # subset of a pop with relative indices

	/usr/site/nrniv/local/python/anaconda3/lib/python3.7/site-packages/netpyne/specs/dicts.py in __getitem__(self, k)
	    182 
	    183     def __getitem__(self, k):
	--> 184         return super(ODict, self).__getitem__(k)
	    185 
	    186 

	KeyError: 'PT5_1'

Nope, then it doesn't know what the populations are.

Ahh, maybe I just need to not instantiate a NEURON object...

*** Loading data correctly

sim.load('data/eee_net_09.json', createNEURONObj=False)

	Loading file data/eee_net_09.json ... 
	  Done; file loading time = 0.04 s
	Loading simConfig...
	Loading netParams...
	Loading net...
	  Created 100 cells
	  Created 0 connections
	  Created 2880 stims
	  Done; re-instantiate net time = 0.09 s
	Loading simData...
	Recording 0 traces of 0 types on node 0

Now it works.  Plotting raster:

sim.analysis.plotRaster()
Plotting raster...

That works, and creates output necessary for plotting (good to pull from Comet, since
can't seem to generate plots there).

*** Getting Raster data out, seeing sync value

rasterData = sim.analysis.plotRaster(orderInverse=True, syncLines=True)

When including synclines, the sync value is included in the plot title

Now to induce plateaus and measure sync with and without plateaus, with and without
external inputs

** Inducing plateaus

Actually, there should be plateaus in PT5_1 and _2 already, but perhaps too much noise.

Turning noise off in PT cells and running sim.

cfg.simLabel = 'eee_net_11'
sim.load('data/eee_net_11.json', createNEURONObj=False)
rasterData = sim.analysis.plotRaster(orderInverse=True, syncLines=True)

There's definitely plateaus under the noise:
file:gif/20190812_205928.png

Reducing number of cells to 100 for easier analysis and reducing noise

cfg.PT5_exc_noise_amp = 0.1 #1.0
cfg.PT5_exc_noise_e   = 0.0
cfg.PT5_exc_noise_tau = 1.0
cfg.PT5_inh_noise_amp = 0.1 #1.0
cfg.PT5_inh_noise_e   = -75.0
cfg.PT5_inh_noise_tau = 1.0

Seems like there is still a lot of noise...
file:gif/20190812_210744.png

Reducing noise by another factor of 10

cfg.PT5_exc_noise_amp = 0.01 #1.0
cfg.PT5_exc_noise_e   = 0.0
cfg.PT5_exc_noise_tau = 1.0
cfg.PT5_inh_noise_amp = 0.01 #1.0
cfg.PT5_inh_noise_e   = -75.0
cfg.PT5_inh_noise_tau = 1.0

cfg.simLabel = 'eee_net_13'

Still a lot of noise. Might have more to do with e values than amplitudes...

But will worry about that later.

Looking at sync:
rasterData = sim.analysis.plotRaster(orderInverse=True, syncLines=True, include=['PT5_1'])
rasterData = sim.analysis.plotRaster(orderInverse=True, syncLines=True, include=['PT5_3'])

file:gif/20190812_211543.png

PT5_1 (w/ plateau) and PT5_3 (w/o plateau) have samy sync...

Will include only time range of plateau... 200 to 400 ms

rasterData = sim.analysis.plotRaster(orderInverse=True, syncLines=True, include=['PT5_1'], timeRange=[200,400])

Sync values are still the same... timeRange must not have an effect.
file:gif/20190812_211951.png

Will have to look into calculating sync myself...

But first, adding in external inputs and looking at sync

** Adding external inputs

cfg.simLabel = 'eee_net_14'

cfg.addCommonInput1 = True
cfg.addCommonInput2 = True 
 
Can't see common inputs.  Turning off noise and running again.

cfg.simLabel = 'eee_net_15'

The inputs are there (see trace):
file:gif/20190813_074510.png

There should be more synchrony (see raster):
file:gif/20190813_074616.png

Total sync = 0.85
Raster with sync lines:
sim.analysis.plotRaster(orderInverse=True, syncLines=True)
file:gif/20190813_074759.png

Looking at just PT5_1 during plateau:
sim.analysis.plotRaster(orderInverse=True, syncLines=True, include=['PT5_1'], timeRange=[200,400])
file:gif/20190813_074959.png

It says sync is still 0.85


* 2019-08-13 -- EEE meeting, Working on sync analyses

** Trying to measure sync in ind pops, specific time ranges

So the sync measure from the raster plot seems to be an overall, but we need to 
measure sync individually in certain pops and certain time ranges

Looking into analysis.plotSpikeStats

	analysis.plotSpikeStats (include = [‘allCells’, ‘eachPop’], timeRange = None, graphType=’boxplot’, stats = [‘rate’, ‘isicv’], popColors = [], figSize = (6,8), saveData = None, saveFig = None, showFig = True)

	Plot spike histogram. Optional arguments:

	include: List of data series to include. Note: one line per item, not grouped ([‘all’|,'allCells'|,’allNetStims’|,120|,’L4’|,('L2', 56)|,(‘L5’,[4,5,6])])
	timeRange: Time range of spikes shown; if None shows all ([start:stop])
	graphType: Type of graph to use (‘boxplot’)
	stats: List of types measure to calculate stats over: cell firing rates, interspike interval coefficient of variation (ISI CV), pairwise synchrony, and/or overall synchrony (sync measures calculated using PySpike SPIKE-Synchrony measure) ([‘rate’, |'isicv'| ‘pairsync’ |'sync'|])
	popColors: Dictionary with color (value) used for each population/key
	figSize: Size of figure ((width, height))
	saveData: File name where to save the final data used to generate the figure (None|’fileName’)
	saveFig: File name where to save the figure (None|’fileName’)
	showFig: Whether to show the figure or not (True|False)
	Returns figure handle

** plotSpikeStats

Trying for all cells

sim.analysis.plotSpikeStats(include = ['allCells'], timeRange = None, graphType='boxplot', stats = ['sync'], popColors = [], figSize = (6,8), saveData = None, saveFig = None, showFig = True)

0.5393

Trying for eachPop

sim.analysis.plotSpikeStats(include = ['eachPop'], timeRange = None, graphType='boxplot', stats = ['sync'], popColors = [], figSize = (6,8), saveData = None, saveFig = None, showFig = True)

Output with raster:
file:gif/20190813_080128.png

Seems problematic: PT5_1 has very low sync (0.1038), while all the other pops have high 
sync (near 1.0)

Perhaps its a problem because of the low number of spikes.

First I'll check 'pairsync', then try for plateau timeRange, then try with noise turned 
on

*** pairsync

sim.analysis.plotSpikeStats(include = ['eachPop'], timeRange = None, graphType='boxplot', stats = ['pairsync'], popColors = [], figSize = (6,8), saveData = None, saveFig = None, showFig = True)

pairsync and pairSync don't work:

There was an exception in plotSpikeStats(): 
 'pairsync' 
(<class 'KeyError'>, KeyError('pairsync'), <traceback object at 0x119550288>)

There was an exception in plotSpikeStats(): 
 'pairSync' 
(<class 'KeyError'>, KeyError('pairSync'), <traceback object at 0x1197fb408>)


*** plateau timeRange

sim.analysis.plotSpikeStats(include = ['eachPop'], timeRange = [200,400], graphType='boxplot', stats = ['sync'], popColors = [], figSize = (6,8), saveData = None, saveFig = None, showFig = True)

Sync data without timeRange:

 {'include': ['PT5_1', 'PT5_2', 'PT5_3', 'PT5_4', 'PV5'],
  'statData': 
  [[0.1038135593220339],
   [1.0],
   [0.9873417721518988],
   [0.9889538661468485],
   [0.963244176013805]],
  'gidsData': [],
  'ynormsData': []})

Sync data during plateau (timeRange=[200,400]):

 {'include': ['PT5_1', 'PT5_2', 'PT5_3', 'PT5_4', 'PV5'],
  'statData': 
  [[0.125],
   [1.0],
   [0.9830508474576272],
   [1.0],
   [0.9744360902255639]],
  'gidsData': [],
  'ynormsData': []})

Only very slight differences.  It seems there is a problem with sync measurements.

Making a figure for the EEE meeting: don't invert raster so easier to compare with sync 
plot

	rasterData = sim.analysis.plotRaster()
	sim.analysis.plotSpikeStats(include = ['eachPop'], timeRange = None, graphType='boxplot', stats = ['sync'], figSize = (6,8), saveData = None, saveFig = None, showFig = True)

Figure:
file:gif/20190813_081343.png

Comparing rasterplot sync value with boxplot sync value

Raster plot: 0.85
Boxplot    : 0.54

Figure:
file:gif/20190813_081617.png

Clearly a problem here...


** EEE meeting

Discussion

Single cell article updates
Should be almost ready to submit
	
Measuring synchrony
Working on measuring synchrony in four populations (Fig 1: old sims, Fig 2, 3: latest sims):
PT5_1: induced plateau and external inputs
PT5_2: induced plateau
PT5_3: external inputs
PT5_4: nothing
Netpyne synchrony measurements don’t seem to work as expected
rasterPlot sync measure doesn’t change with specific pop or time range (see Fig 4 and Fig 5)
plotSpikeStats gives odd results (see Fig 6)
overall sync measures don’t match up between rasterPlot (0.85) and spikeStats (0.54) (see Fig 7)
Discussion
Get synchrony going first, then worry about synchrony measures
Work with plotSpikeStats synchrony measures
More important to get interesting sims going
Automatically find regions of high synchrony? Don may be able to help
Interesting things may only show up in massive sims

Using Stampede
Bill’s error (different ones)
Problems with both sims, seems to be setup error
Use ControlMaster -- avoids double authentication
Stampede may allow larger scales

Other items
Contrib section for Netpyne?  Allows user contributions of new analyses, etc.
Random seg faults still an issue on Comet
Google batch sims don’t get seg faults
Joe updates Netpyne, Bill and Joe look at plotSpikeStats sync issues
Reduce plateau amplitude so less spiking solely due to plateau

** TACC Stampede

Got my TACC username -- tg856217 -- from XSEDE portal and was able to use TACC Android 
app to scan QR code for multifactor authentication

Can now logon with: ssh tg856217@stampede2.tacc.xsede.org

Copying Bill's .bashrc file to take a look:
scp tg856217@stampede2.tacc.xsede.org:/home1/03337/wwlytton/.bashrc bill_tacc_bashrc

That worked.  :)

*** Chat about using Stampede

billl 4:33 PM
this is on stampede now
i've got stampede all setup if you want to use that

joe 4:34 PM
Cool, I’ll get details during meeting tomorrow.

billl 4:34 PM
i won't know details to speak them but can give them to you anytime
basically should ("should") work from the paths set up in my .bashrc
/home1/03337/wwlytton/.bashrc

joe 4:40 PM
How do I request access to Stampede?

billl 4:55 PM
via tacc ?  -- thought we all got both stampede and comet -- lms our allocation
logon to xsede 1st
you are on stampede2 according to the alloc
try to logon -- this will set up a controlmaster to make easy to send files back and forth:
setenv STANAME jwgraham
alias stacon ssh ${STANAME}@stampede2.tacc.xsede.org -fNxTMS /tmp/sta:+home1+03337+${STANAME}:22
you may have to go to the TACC website to set/reset your passwd
portal.tacc.utexas.edu
i'm very happy with the ControlMaster connects now especially for stampede since they have 2 factor authentication so without ControlMaster end up having to enter a 6 digit number from my phone each time i want to scp or rsync or hg pull or otherwise send files back and forth
adding those connectors to csh_defaults

don 7:35 PM
@joe did you get onto Stampede?

use:
ssh [your-xsede-username]@stampede2.tacc.xsede.org
password is your xsede password plus the TACC Token Code from a TACC Token app (for iOS and Android)


* 2019-08-15 -- Converting FS3 from hoc to Python

** Changing FS3 cell from hoc to Python

The EEE network sims are crashing on Stampede in FS3.hoc cell

*** Chat from yesterday

billl 2:54 PM
** getting seg faults traced back to
printf("Balancing each compartment to %d mV\n", $1) in (EEE_network/cells/FS3.hoc:140)
better if we just calculate the e_pas once and set it i think?
also looks like FS3 is a simple sort of cell -- soma,axon,dend   ; wy not make this a .py file as did with the PV cell?
joe 3:39 PM
Sergio found FS3 somewhere and we’ve just been using it as is.
But I agree, can be much simpler and would be better in Python.
I’ll get on that.

*** Preparing to switch

First I'll set to record from FS3 cells and run a sim, then switch to Python version 
and run another to see differences

cfg.simLabel = 'eee_net_16'

cfg.analysis['plotTraces'] = {'include': ['PT5_1', 'PT5_2', 'PT5_3', 'PT5_4'], 'saveFig': saveFig, 'showFig': showFig, 'ylim': [-80, 30]}   

-->

cfg.analysis['plotTraces'] = {'include': ['PT5_1', 'PT5_2', 'PT5_3', 'PT5_4', 'PV5'], 'saveFig': saveFig, 'showFig': showFig, 'ylim': [-80, 30]}   

Raster before: 
file:gif/20190815_133718.png

Sample traces: 
file:gif/20190815_133939.png


*** Making the switch

Committing first.

Finished converting FS3.hoc to FS3.py, now to try it out.

Changes in netParams.py:

	#PV_path   = os.path.join(cellpath, 'FS3.hoc')
	PV_path   = os.path.join(cellpath, 'FS3.py')

	#cellRule = netParams.importCellParams(label='PV5', conds={'cellType':'PV5'}, fileName=PV_path, cellName='FScell1', cellInstance=True)
	cellRule = netParams.importCellParams(label='PV5', conds={'cellType':'PV5'}, fileName=PV_path, cellName='MakeCell', cellInstance=True)

cfg.simLabel = 'eee_net_17'

Had to add `from neuron import h` to FS3.py but then it worked.  :)

Raster output: 
file:gif/20190815_160339.png

Looks very similar, good sign.

Sample traces: 
file:gif/20190815_160819.png

Also very similar.  Calling this translation a success.

Cleaning up cfg and netParams and committing.


* 2019-08-19 -- Synchrony and simulation improvements

** To do today

Update Netpyne
Look into plotSpikeStats synchrony measure
Look into synchrony measures
Measure synchrony in specific timeRanges
Compare synchrony across pops
Reduce plateau amplitudes to eliminate plateau-driven spiking?


** Updating Netpyne

Updating Netpyne locally before looking into synchrony measures

Local version of Netpyne: 0.9.1.1
Checking version of Netpyne on Comet: 0.9.1.1
Github development version: 0.9.4
Github release version: 0.9.3.1

I see that the latest Netpyne commit "Fixed bug in plotSpikeStats pop order", this 
may explain the problem discussed in last week's meeting, where the sync measures
were obviously wrong... (see file:gif/20190813_081343.png)

It looks like the labeling was just wrong.

Updating Netpyne locally:

	graham$ cd ~/Applications/netpyne
	graham$ git pull
	graham$ pip install -e .

That worked.  Now to play around with plotSpikeStats.

** Creating subdirs for each sim's data

Adding to cfg.py:

	import os
	...
	cfg.saveFolder = os.path.join('data', cfg.simLabel)


** Adding auto loading and analysis to dev.py

simLabel = 'eee_net_18'
simPath = os.path.join('data', simLabel, simLabel + '.json')
sim.load(simPath, createNEURONObj=False)
rasterData = sim.analysis.plotRaster()
sim.analysis.plotSpikeStats(include = ['eachPop'], timeRange = None, graphType='boxplot', stats = ['sync'], figSize = (6,8), saveData = None, saveFig = None, showFig = True)


** plotSpikeStats

Need to see if plotSpikeStats measures synchrony only within timeRange

cfg.simLabel = 'eee_net_18'

Turning noise to PT5 cells back on and running sim.

	cd /u/graham/EEE_network/eee_net/
	./runsim

Then to analyze:

	cd /u/graham/EEE_network/eee_net/
	ipython -i dev.py

Looks good:
file:gif/20190819_201450.png

In [1]: syncData
Out[1]: 
{'include': ['PT5_1', 'PT5_2', 'PT5_3', 'PT5_4', 'PV5'],
 'statData': [
  [0.502123730378578],
  [0.5152954588637659],
  [0.41847380143007856],
  [0.39760159893404395],
  [0.11555555555555555]],
 'gidsData': [],
 'ynormsData': []}

Now to check on timeRange.  Setting timeRange = [200, 400] to center on plateau.

In [1]: syncDataPlat
Out[1]: 
{'include': ['PT5_1', 'PT5_2', 'PT5_3', 'PT5_4', 'PV5'],
 'statData': [
  [0.6366723259762309],
  [0.6720969089390142],
  [0.4750110570544007],
  [0.45519203413940257],
  [0.25]],
 'gidsData': [],
 'ynormsData': []}

Good, timeRange seems to work with the sync calculations.


** Adding ability to induce multiple plateaus

I want to induce one plateau without external inputs and one with the inputs.

Currently the code only allows induction of one plateau.

Did a bunch of work in cfg.py and netParams.py...

Testing after setting up new experiment ('eee_net_19')



** Comparing sync in different pops/conditions

Now to compare nonPlat timeRange with plat timeRange.

Increasing sim time to 1800 ms, shifting plateau to 2400 ms
(Each 200 ms timeRange will be in the middle of 600 ms)

pre-everything timeRange  : [200, 400]
plateau timeRange         : [800, 1000]
input alone timeRange     : [1400, 1600]
plateau + input timeRange : [2000, 2200]

cfg.simLabel = 'eee_net_20'

Whoops.  Needed to change second common input time...

cfg.simLabel = 'eee_net_21'

It runs, but I need to look into why second plateau doesn't seem to be appearing...

Committing for now.

** Turning noise off

cfg.simLabel = 'eee_net_22'

Everything looks okay, though PT cells may not be getting enough IPSP effect
(will look into this tomorrow)


** Turning noise back on

Running sim to analyze synchrony
cfg.simLabel = 'eee_net_23'


* 2019-08-20 -- EEE meeting and synchrony measures

** To work on today

Plotting synchrony
Noise exploration
Look into IPSPS or lack thereof
Connectivity exploration 

** First common input was at wrong time

Re-running sim without noise 
cfg.simLabel = 'eee_net_24'

Re-running sim with noise
cfg.simLabel = 'eee_net_25'

Raster comparisons: 
file:gif/20190820_064430.png

Sync (with noise):
file:gif/20190820_070227.png


** Plotting synchrony

Got synchrony plot working in dev.py:
file:gif/20190820_072838.png

Looks great!

Committing.

** Add to list 

Running a batch of sims varying noise seed
Analyze batch to get sync means with stdev
Running a batch of sims to explore noise amplitude
Reducing plateau amplitude below spike threshold
Getting dev.py to automatically analyze latest sim

	list.sort()
	list[-1]

** Plotting batch synchrony

Need to look into Gfluctp to see how seeds work for noise

batchLabel = 'v01_batch23'

The batch ran successfully.  Let's see if we have different noise now...

Committing.

Now to analyze...

Got a batch plotting routine done in dev.py.

Running dev.py right now produces the mean +- stdv sync measures for the four 
pops and four conditions.

Committing.


* 2019-08-21 -- 

** Working on:

Getting sync batch plot (mean +- stdv)
Running a batch of sims to explore noise amplitude
Reducing plateau amplitude below spike threshold
Developing plateau-detector
Running large, long sims
Looking into IPSPs

** Running batch of 10 with different noise seeds

batchLabel = 'v01_batch24'

Looks good:
file:gif/20190821_141847.png


** Running batch of 10 with same noise seeds

I think that even with the same noise seeds, sims get different noise

batchLabel = 'v01_batch25'

Varying a dummy variable:
cfg.dummy    = 0       

file:gif/20190821_144908.png

Yeah, our noise seeds don't allow us to reproduce the same noise inputs.

* 2019-08-23 -- batch sims

Running a batch of sims varying 

cfg.PT5_noise_scaling = 1.0
cfg.PT5_exc_noise_amp = 0.01 * cfg.PT5_noise_scaling
cfg.PT5_inh_noise_amp = 0.01 * cfg.PT5_noise_scaling

batchLabel = 'v01_batch26'
params['PT5_noise_scaling'] = [0.0, 0.00001, 0.0001, 0.001, 0.1, 1.0]


* 2019-09-10 -- Detecting plateaus

** To do 

Run batch of sims looking at radius of synapses (i.e. clustered vs distributed)
Detect plateaus from voltage traces
Detect plateaus from spike timing
Look into IPSPs!

** Radius of synapses batch of sims

i.e. clustered vs distributed inputs

batchLabel = 'v01_batch27'

	params['synLocRadius'] = [0.01, 0.1, 0.15, 0.25, 0.5]
	params['glutAmp'] = [1.5, 2.0, 2.5]

Turning off common inputs

	e.g. cfg.addCommonInput1 = False

cfg.duration = 1000 #2400
cfg.glutTimes         = [300.0] #[800.0, 2000.0]

Done, analyzing:

eee_net graham$ ipython -i dev.py
In [1]: batch_analysis.plot_vtraces('v01_batch27')

radius of 0.5 didn't work, reducing to 0.49
also turning off noise to PT cells: cfg.noisePT5 = False #True

batchLabel = 'v01_batch28'

Radius of 0.49 doesn't work either... Need to look into this...

Running a single sim with print statements about synaptic locations
cfg.simLabel = 'eee_net_26'

branch_length = 
166.25942491682142

glutLocs = 
[0.15, 0.16304347826086957, 0.1760869565217391, 0.1891304347826087, 0.20217391304347826, 0.2152173913043478, 0.22826086956521738, 0.24130434782608695, 0.2543478260869565, 0.26739130434782604, 0.2804347826086956, 0.2934782608695652, 0.3065217391304348, 0.3195652173913043, 0.3326086956521739, 0.3456521739130434, 0.35869565217391297, 0.37173913043478257, 0.3847826086956521, 0.39782608695652166, 0.41086956521739126, 0.42391304347826086, 0.43695652173913035, 0.44999999999999996]

Changing radius to 0.5 
cfg.simLabel = 'eee_net_27'

glutLocs = 
[-0.2, -0.1565217391304348, -0.11304347826086958, -0.06956521739130436, -0.026086956521739146, 0.01739130434782607, 0.060869565217391286, 0.10434782608695653, 0.14782608695652172, 0.1913043478260869, 0.23478260869565215, 0.2782608695652174, 0.3217391304347826, 0.36521739130434777, 0.40869565217391307, 0.45217391304347826, 0.49565217391304345, 0.5391304347826087, 0.5826086956521739, 0.6260869565217391, 0.6695652173913043, 0.7130434782608694, 0.7565217391304349, 0.8]

Ahhh, the problem is that the middle is set at 0.3, so the maximum radius is also 0.3

Setting up a new batch:

batchLabel = 'v01_batch30'

	params['synLocRadius'] = [0.0, 0.1, 0.15, 0.3]

0.3 doesn't work

batchLabel = 'v01_batch31'

	params['synLocRadius'] = [0.0, 0.1, 0.15, 0.29]
	params['glutAmp'] = [0.5, 2.0, 4.0]

0.29 doesn't work either
file:gif/20190910_061234.png

** Exploring radius and location in a batch:

batchLabel = 'v01_batch32'
	params['synLocRadius'] = [0.0, 0.1, 0.149, 0.249]
	params['synLocMiddle'] = [0.3, 0.5, 0.7]


Looking into the nsegs in basal_8
self.basal[8].nseg = 3

Good figure of radius and locs:
file:gif/20190910_061947.png


** Plateau detection

Looking at old code to see if I've already done something similar...

Nothing really useful, all the code in batch_analysis.py assumes we know the time of
the glutamate puff.

Will wait for v01_batch28 to finish and then analyze it to detect plateaus (by comparing 
voltage traces and spiking with and without plateau)

cfg.simLabel = 'eee_net_28'
cfg.noisePT5 = True
cfg.glutTimes         = [200.0, 1000.0, 1800.0] #[800.0, 2000.0]
#cfg.analysis['plotTraces'] = {'include': [('PT5_1', [0,1,2,3,4]), ('PT5_2', [0,1,2,3,4]), ('PT5_3', [0,1,2,3,4]), ('PT5_4', [0,1,2,3,4])], 'saveFig': saveFig, 'showFig': showFig, 'ylim': [-80, 30]} 
cfg.analysis['plotTraces'] = {'include': ['PT5_1', 'PT5_2', 'PT5_3', 'PT5_4'], 'saveFig': saveFig, 'showFig': showFig, 'ylim': [-80, 30]}  

Loading a sim:
simLabel = 'eee_net_28'
simPath = 'data'
simPath = os.path.join(simPath, simLabel, simLabel + '.json')
sim.load(simPath, createNEURONObj=False)

sim.analysis.plotRaster()
file:gif/20190910_072150.png

sim.analysis.plotTraces()
file:gif/20190910_072645.png

Looks pretty good. Now to develop code that reads in a voltage trace, determines when a plateau
occurs (running voltage average?) and plots that plateau on the trace.

Here's what the data structure looks like:

In [6]: sim.allSimData.keys()
Out[6]: dict_keys(['V_soma', 'avgRate', 'spkid', 'spkt', 't'])

In [7]: sim.allSimData['V_soma'].keys()
Out[7]: dict_keys(['cell_0', 'cell_1', 'cell_10', 'cell_11', 'cell_12', 'cell_13', 'cell_14', 'cell_15', 'cell_16', 'cell_17', 'cell_18', 'cell_19', 'cell_2', 'cell_20', 'cell_21', 'cell_22', 'cell_23', 'cell_24', 'cell_25', 'cell_26', 'cell_27', 'cell_28', 'cell_29', 'cell_3', 'cell_30', 'cell_31', 'cell_32', 'cell_33', 'cell_34', 'cell_35', 'cell_36', 'cell_37', 'cell_38', 'cell_39', 'cell_4', 'cell_40', 'cell_41', 'cell_42', 'cell_43', 'cell_44', 'cell_45', 'cell_46', 'cell_47', 'cell_48', 'cell_49', 'cell_5', 'cell_50', 'cell_51', 'cell_52', 'cell_53', 'cell_54', 'cell_55', 'cell_56', 'cell_57', 'cell_58', 'cell_59', 'cell_6', 'cell_60', 'cell_61', 'cell_62', 'cell_63', 'cell_64', 'cell_65', 'cell_66', 'cell_67', 'cell_68', 'cell_69', 'cell_7', 'cell_70', 'cell_71', 'cell_72', 'cell_73', 'cell_74', 'cell_75', 'cell_76', 'cell_77', 'cell_78', 'cell_79', 'cell_8', 'cell_9'])


Detecting plateaus in one trace:

simLabel = 'eee_net_28'
simPath = 'data'
simPath = os.path.join(simPath, simLabel, simLabel + '.json')
sim.load(simPath, createNEURONObj=False)
v_soma_0 = sim.allSimData['V_soma']['cell_0']
plt.plot(v_soma_0)

def moving_average(a, n=3) :
    ret = np.cumsum(a, dtype=float)
    ret[n:] = ret[n:] - ret[:-n]
    return ret[n - 1:] / n

20190910_075353.png
Moving average of 10, 20, and 30 ms:




* 2019-09-16 -- Looking into synchrony


** Looking at synchrony measures in pySpike

Generate and plot spike trains
Measure synchrony

	import matplotlib.pyplot as plt
	import pyspike as spk
	numCells = 20
	dur = 200
	rate = 20

	spike_trains = [spk.generate_poisson_spikes(rate, [0, dur/1000.]) for cell in range(numCells)]

	plt.eventplot(spike_trains)

	spk.spike_sync(spike_trains)

Function to generate Poisson spike times and measure synchrony:
#################

import matplotlib.pyplot as plt
plt.ion()
import pyspike as spk
import numpy as np

def sync(numCells=200, dur=200, rate=20, plot=False):

	spike_trains = [spk.generate_poisson_spikes(rate, [0, dur/1000.]) for cell in range(numCells)]

	if plot:
		plt.eventplot(spike_trains)

	return spk.spike_sync(spike_trains)


repeats = 20

# numCells
numCells = [10, 100, 200, 500, 1000]
meanSync = []
stdSync  = []

for num in numCells:

	print()
	print("numCells = " + str(num))

	syncVals = []
	
	for rep in range(repeats):

		print("  rep = " + str(rep))

		syncVals.append(sync(numCells=num))

	meanSync.append(np.mean(syncVals))
	stdSync.append(np.std(syncVals))

plt.figure()
plt.errorbar(numCells, meanSync, yerr=stdSync)
plt.title('Synchrony versus number of cells')
plt.ylabel('Synchrony')
plt.xlabel('Number of cells')
plt.xscale('log')
plt.ylim([0, 0.5])

# dur
durs = [100, 200, 500, 1000, 5000, 10000]
meanSync = []
stdSync  = []

for dur in durs:

	print()
	print("dur = " + str(dur))

	syncVals = []
	
	for rep in range(repeats):

		print("  rep = " + str(rep))

		syncVals.append(sync(dur=dur))

	meanSync.append(np.mean(syncVals))
	stdSync.append(np.std(syncVals))

plt.figure()
plt.errorbar(durs, meanSync, yerr=stdSync)
plt.title('Synchrony versus duration')
plt.ylabel('Synchrony')
plt.xlabel('Duration (ms)')
plt.xscale('log')
plt.ylim([0, 0.5])

# rate
rates = [10, 20, 50, 100, 1000]
meanSync = []
stdSync  = []

for rate in rates:

	print()
	print("rate = " + str(rate))

	syncVals = []
	
	for rep in range(repeats):

		print("  rep = " + str(rep))

		syncVals.append(sync(rate=rate))

	meanSync.append(np.mean(syncVals))
	stdSync.append(np.std(syncVals))

plt.figure()
plt.errorbar(rates, meanSync, yerr=stdSync)
plt.title('Synchrony versus firing rate')
plt.ylabel('Synchrony')
plt.xlabel('Firing rate (Hz)')
plt.xscale('log')
plt.ylim([0, 0.5])
	
# rate
rates = [0.1, 0.2, 0.5, 1, 2, 5, 10, 20, 50, 100, 200, 500]
meanSync = []
stdSync  = []

for rate in rates:

	print()
	print("rate = " + str(rate))

	syncVals = []
	
	for rep in range(repeats):

		print("  rep = " + str(rep))

		syncVals.append(sync(rate=rate))

	meanSync.append(np.mean(syncVals))
	stdSync.append(np.std(syncVals))

plt.figure()
plt.errorbar(rates, meanSync, yerr=stdSync)
plt.title('Synchrony versus firing rate')
plt.ylabel('Synchrony')
plt.xlabel('Firing rate (Hz)')
plt.xscale('log')
plt.ylim([0, 0.5])

###############

Output: 

Sync versus
number of cells    : file:gif/20190916_220545.png
duration           : file:gif/20190916_220614.png
firing rate (high) : file:gif/20190916_220656.png
firing rate (low)  : file:gif/20190916_220711.png


** Looking at different glut puff locations

Moving further out the branch in order to reduce inherent spiking

0.3, 0.5, 0.7 for synLocMiddle

batchLabel = 'v01_batch33'

batchLabel = 'v01_batch34'

batchLabel = 'v01_batch35'

Committing before running batch33

Running dev.py, then:

syncData03 = plotBatchSync(batchLabel='v01_batch33')
syncData05 = plotBatchSync(batchLabel='v01_batch34')
syncData07 = plotBatchSync(batchLabel='v01_batch35')

plt.gca().set_ylim([0,0.8])

Comparing:
file:gif/20190917_051618.png

Left (0.3), Middle (0.5), Right (0.7)

Raster plots: 
file:gif/20190917_051939.png



** IPSPs to PT5 cells

In everything I've run today, inhibitory cells are spiking. But with the noise off in PT5
cells, there is no sign of IPSPs.  Need to look into this!


** Looking into connectivity

Want to plot a morphology...

From Netpyne.org:
# syn locations (using matplotlib) of cell with gid=0
sim.analysis.plotShape(includePost=[0], showSyns=1, synStyle='.', synSiz=3)


*** Attempt one

import os
from netpyne import sim
simLabel = 'eee_net_28'
simPath = os.path.join('data', simLabel, simLabel + '.json')
sim.load(simPath, createNEURONObj=False)
sim.analysis.plotShape(includePost=[0], showSyns=1, synStyle='.', synSiz=3)

Loading file data/eee_net_28/eee_net_28.json ... 
  Done; file loading time = 0.11 s
Loading simConfig...
Loading netParams...
Loading net...
  Created 100 cells
  Created 0 connections
  Created 8640 stims
  Done; re-instantiate net time = 0.10 s
Loading simData...
Recording 0 traces of 0 types on node 0
Plotting 3D cell shape ...
There was an exception in plotShape(): 
 sec is not a Section 
(<class 'TypeError'>, TypeError('sec is not a Section'), <traceback object at 0x11c409288>)
Out[5]: -1

Will run a new sim saving sections and connections.

*** Attempt two

cfg.simLabel = 'eee_net_29'
cfg.saveCellSecs = True #False
cfg.saveCellConns = True #False

import os
from netpyne import sim
simLabel = 'eee_net_29'
simPath = os.path.join('data', simLabel, simLabel + '.json')
sim.load(simPath, createNEURONObj=True)
sim.analysis.plotShape(includePost=[0], showSyns=1, synStyle='.', synSiz=3)

Loading file data/eee_net_29/eee_net_29.json ... 
  Done; file loading time = 0.20 s
Loading simConfig...
Loading netParams...
Loading net...
  Created 100 cells
  Created 10240 connections
  Created 5920 stims
---------------------------------------------------------------------------
LookupError                               Traceback (most recent call last)
<ipython-input-1-09d4839fe776> in <module>()
      3 simLabel = 'eee_net_29'
      4 simPath = os.path.join('data', simLabel, simLabel + '.json')
----> 5 sim.load(simPath, createNEURONObj=True)
      6 sim.analysis.plotShape(includePost=[0], showSyns=1, synStyle='.', synSiz=3)

~/Applications/netpyne/netpyne/sim/wrappers.py in load(filename, simConfig, output, instantiate, createNEURONObj)
    119     sim.initialize()  # create network object and set cfg and net params
    120     sim.cfg.createNEURONObj = createNEURONObj
--> 121     sim.loadAll(filename, instantiate=instantiate, createNEURONObj=createNEURONObj)
    122     if simConfig: sim.setSimCfg(simConfig)  # set after to replace potentially loaded cfg
    123     if len(sim.net.cells) == 0 and instantiate:

~/Applications/netpyne/netpyne/sim/load.py in loadAll(filename, data, instantiate, createNEURONObj)
    284         print('Error: no connFormat provided in simConfig')
    285         sys.exit()
--> 286     loadNet(filename, data=data, instantiate=instantiate, compactConnFormat=connFormat)
    287     loadSimData(filename, data=data)
    288 

~/Applications/netpyne/netpyne/sim/load.py in loadNet(filename, data, instantiate, compactConnFormat)
    233                     for cell in sim.net.cells:
    234                         prop = {'secs': cell.secs}
--> 235                         cell.createNEURONObj(prop)  # use same syntax as when creating based on high-level specs
    236                         cell.associateGid()  # can only associate once the hSection obj has been created
    237                     # create all NEURON Netcons, NetStims, etc

~/Applications/netpyne/netpyne/cell/compartCell.py in createNEURONObj(self, prop)
    420                             pointpParamValue = self.gid
    421                         if pointpParamName not in ['mod', 'loc', 'vref', 'synList'] and not pointpParamName.startswith('_'):
--> 422                             setattr(sec['pointps'][pointpName]['hObj'], pointpParamName, pointpParamValue)
    423                     if 'params' in self.tags.keys(): # modify cell specific params
    424                       for pointpParamName,pointpParamValue in self.tags['params'].items():

LookupError: 'hObj' is not a defined hoc variable name.

*** Attempt three

import os
from netpyne import sim
simLabel = 'eee_net_29'
simPath = os.path.join('data', simLabel, simLabel + '.json')
sim.loadAll(simPath, createNEURONObj=True)
sim.analysis.plotShape(includePost=[0], showSyns=1, synStyle='.', synSiz=3)

Loading file data/eee_net_29/eee_net_29.json ... 
Loading simConfig...
Loading netParams...
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-1-ad07a6557895> in <module>()
      3 simLabel = 'eee_net_29'
      4 simPath = os.path.join('data', simLabel, simLabel + '.json')
----> 5 sim.loadAll(simPath, createNEURONObj=True)
      6 sim.analysis.plotShape(includePost=[0], showSyns=1, synStyle='.', synSiz=3)

~/Applications/netpyne/netpyne/sim/load.py in loadAll(filename, data, instantiate, createNEURONObj)
    278     loadSimCfg(filename, data=data)
    279     sim.cfg.createNEURONObj = createNEURONObj  # set based on argument
--> 280     loadNetParams(filename, data=data)
    281     if hasattr(sim.cfg, 'compactConnFormat'):
    282         connFormat = sim.cfg.compactConnFormat

~/Applications/netpyne/netpyne/sim/load.py in loadNetParams(filename, data, setLoaded)
    162     if 'net' in data and 'params' in data['net']:
    163         if setLoaded:
--> 164             setup.setNetParams(data['net']['params'])
    165         else:
    166             return specs.NetParams(data['net']['params'])

~/Applications/netpyne/netpyne/sim/setup.py in setNetParams(params)
     94     elif params and isinstance(params, dict):
     95         params = utils.replaceKeys(params, 'popLabel', 'pop')  # for backward compatibility
---> 96         sim.net.params = specs.NetParams(params)
     97     else:
     98         sim.net.params = specs.NetParams()

AttributeError: module 'netpyne.sim' has no attribute 'net'

*** Attempt four

cfg.saveDataInclude = ['simData', 'simConfig', 'netParams', 'netCells', 'netPops', 'net'] #['simData', 'simConfig', 'netParams', 'net'] 

cfg.simLabel = 'eee_net_30'
./runsim

import os
from netpyne import sim
simLabel = 'eee_net_30'
simPath = os.path.join('data', simLabel, simLabel + '.json')
sim.loadAll(simPath, createNEURONObj=True)
sim.analysis.plotShape(includePost=[0], showSyns=1, synStyle='.', synSiz=3)

AttributeError: module 'netpyne.sim' has no attribute 'net'

*** Attempt five

import os
from netpyne import sim
simLabel = 'eee_net_30'
simPath = os.path.join('data', simLabel, simLabel + '.json')
sim.load(simPath, createNEURONObj=True, instantiate=True)
sim.analysis.plotShape(includePost=[0], showSyns=1, synStyle='.', synSiz=3)

Still not working.

But, if I comment out the following line in Netpyne it works:

setattr(sec['pointps'][pointpName]['hObj'], pointpParamName, pointpParamValue)

Around line 422 in /Users/graham/Applications/netpyne/netpyne/cell/compartCell.py

Here's the shape plot
file:gif/20190917_065822.png


** Working with gfluctp

Working in eee_single.  Made some changes so Bill can play. Now committing and pushing.

Commands to set up:

git clone https://github.com/Neurosim-lab/EEE_network.git ; cd EEE_network/mod ; nrnivmodl ; cd ../eee_net ; ln -s "../mod/x86_64" x86_64 ; cd ../eee_single ; ln -s "../mod/x86_64" x86_64 ; ./runsim

Output will appear in eee_single/output

Then go into netParams.py and change the seed values.  Go into cfg.py and change
cfg.simLabel (so output trace plots don't get overwritten).  Re-run the sim.

Even with different seeds, the noise always looks the same...


** Fixing 3D layout of morphology

Before:
file:gif/20190918_175112.png


        # Set up the 3d morphology and connection of basal dendrite cylinder
        h.pt3dclear(sec = self.basal[9])
        h.pt3dadd(-53.1,14.22,-5.96,6.0, sec = self.basal[9])
        h.pt3dadd(157.2+-53.1,14.22,-5.96,6.0, sec = self.basal[9])

        # Set up the 3d morphology and connection of the axon
        h.pt3dclear(sec = self.axon[0])
        h.pt3dadd(-53.1,14.22,-5.96,1.03, sec = self.axon[0])
        h.pt3dadd(-53.1,200.0+14.22,-5.96,1.03, sec = self.axon[0])

        # Set up the 3d morphology and connection of the apical cylinder
        h.pt3dclear(sec = self.apical[0])
        h.pt3dadd(-53.1,14.22,-5.96,6.0, sec = self.apical[0])
        h.pt3dadd(-53.1,14.22,454.5-5.96,6.0, sec = self.apical[0])

cfg.simLabel = 'eee_net_31'

import os
from netpyne import sim
simLabel = 'eee_net_31'
simPath = os.path.join('data', simLabel, simLabel + '.json')
sim.load(simPath, createNEURONObj=True, instantiate=True)
sim.analysis.plotShape(includePost=[0], showSyns=1, synStyle='.', synSiz=3)

After:
file:gif/20190918_192814.png

Need to invert the axon and start it from the other end of the soma.

Need to put the apical where the axon is.

Basal is fine, but could be angled downwards (direction of axon). Leave it alone 
for now.

        # Set up the 3d morphology and connection of the axon
        h.pt3dclear(sec = self.axon[0])
        h.pt3dadd(-53.1,14.22,-5.96,1.03, sec = self.axon[0])
        h.pt3dadd(-53.1,-200.0+14.22,-5.96,1.03, sec = self.axon[0])

        # Set up the 3d morphology and connection of the apical cylinder
        h.pt3dclear(sec = self.apical[0])
        h.pt3dadd(-53.1,14.22,-5.96,6.0, sec = self.apical[0])
        h.pt3dadd(-53.1,454.5+14.22,-5.96,6.0, sec = self.apical[0])

Now it looks good!
file:gif/20190918_193700.png

Committing.



* 2019-09-19 -- gfluctp and morphology

** gfluctp

billl:
pushed with branch ran123Testing
note that just run with nrniv -python init.py since can't do mpi without multisplit (only 1 cell)
joe can you see if you still getting same each time on yours since i'm getting diff without changing

mkdir temp ; cd temp ; git clone https://github.com/Neurosim-lab/EEE_network.git ; cd EEE_network ; git checkout ran123Testing ; cd mod ; nrnivmodl ; cd ../eee_net ; ln -s "../mod/x86_64" x86_64 ; cd ../eee_single ; ln -s "../mod/x86_64" x86_64 


def myinit2(): #different seed per cell
	for i,v in enumerate(PT5):
		for c in sim.net.cells:
 				if c.tags['pop'] in v:			  		
			  		for isec,sec in c.secs.iteritems():
			  			if isec == 'soma_2':
			  				for ip, pointp in enumerate(sec.pointps.values()):
			  					if pointp['mod'] == 'Gfluctp':
			  						pointp.hPointp.noiseFromRandom123(c.gid, len(c.conns), ip)


** Changes to compartcell in order to plotShape

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git checkout -- <file>..." to discard changes in working directory)

	modified:   netpyne/.DS_Store
	modified:   netpyne/cell/compartCell.py

no changes added to commit (use "git add" and/or "git commit -a")
graham-mac:netpyne graham$ git diff
diff --git a/netpyne/.DS_Store b/netpyne/.DS_Store
index a98998be..52bf99d2 100644
Binary files a/netpyne/.DS_Store and b/netpyne/.DS_Store differ
diff --git a/netpyne/cell/compartCell.py b/netpyne/cell/compartCell.py
index 29616c2d..884bee6f 100644
--- a/netpyne/cell/compartCell.py
+++ b/netpyne/cell/compartCell.py
@@ -419,7 +419,13 @@ class CompartCell (Cell):
                         if pointpParamValue == 'gid': 
                             pointpParamValue = self.gid
                         if pointpParamName not in ['mod', 'loc', 'vref', 'synList'] and not pointpParamName.startswith('_'):
-                            setattr(sec['pointps'][pointpName]['hObj'], pointpParamName, pointpParamValue)
+                            print()
+                            print("pointpName = " + pointpName)
+                            print("pointpParams = " + str(pointpParams))
+                            print("pointpParamName = " + pointpParamName)
+                            print()
+
+                            #setattr(sec['pointps'][pointpName]['hObj'], pointpParamName, pointpParamValue)
                     if 'params' in self.tags.keys(): # modify cell specific params
                       for pointpParamName,pointpParamValue in self.tags['params'].items():
                         setattr(sec['pointps'][pointpName]['hObj'], pointpParamName, pointpParamValue)
graham-mac:netpyne graham$ 


* 2019-09-20 -- 

** To do now

Recompile mod files
Plug in Sergio's initRand code
Ensure seeds work
Switch id32 to new Netpyne implementation

** Recompile mod files

cd /u/graham/EEE_network/eee_net ; rm -rf x86_64 ; cd ../eee_single ; rm -rf x86_64 ; cd ../mod ; rm -rf x86_64

cd /u/graham/EEE_network/mod ; nrnivmodl ; cd ../eee_net ; ln -s "../mod/x86_64" x86_64 ; cd ../eee_single ; ln -s "../mod/x86_64" x86_64


** Plug in Sergio's rand init code

cfg.simLabel = 'eee_net_32'

Trying without initRand

cfg.simLabel = 'eee_net_33'

Changing seed2 to a constant and trying without initRand

cfg.simLabel = 'eee_net_34'

Still different, but looking into the Python hash function.

It turns out we were getting a different seed each time from id32('glfuctp'), 
because it uses the Python hash function which is randomised at each start up 
in order to prevent some sort of attack:

https://stackoverflow.com/questions/27522626/hash-function-in-python-3-3-returns-different-results-between-sessions

** No need for initRand code

Gfluctp seems to be working now even without a separate init.
Netpyne handles using 'gid' as a seed appropriately.  

The same seeds produce the same output, and different seeds produce different 
outputs.


* 2019-09-23 -- 

** Updating to use Netpyne hash function

 sim.utils.hashStr('gfluctp') returns the same output even between sessions

 Updating EEE repo to use this instead of Python's builtin hash

## Hash function
def id32(obj):
    return sim.utils.hashStr(obj) #hash(obj) & 0xffffffff

# PT5_1 noise
if cfg.noisePT5:
    netParams.cellParams['PT5_1']['secs']['soma']['pointps'] = {
                        'noise': {'mod': 'Gfluctp', 
                        'loc': 0.5,
                        'std_e': 0.012,
                        'g_e0' : 0.0121 * cfg.PT5_exc_noise_amp, 
                        'tau_i': 10.49 * cfg.PT5_inh_noise_tau, 
                        'tau_e': 2.728 * cfg.PT5_exc_noise_tau, 
                        'std_i': 0.0264, 
                        'g_i0' : 0.0573 * cfg.PT5_inh_noise_amp, 
                        'E_e'  : cfg.PT5_exc_noise_e, 
                        'E_i'  : cfg.PT5_inh_noise_e, 
                        'seed1': 'gid', 
                        'seed2': id32('gluctp'), 
                        'seed3': cfg.seeds['stim']}}

# PV5 noise
if cfg.noisePV5:
    netParams.cellParams['PV5']['secs']['soma']['pointps'] = {
                        'noise': {'mod': 'Gfluctp', 
                        'loc': 0.5,
                        'std_e': 0.012,
                        'g_e0' : 0.0121 * cfg.PV5_exc_noise_amp, 
                        'tau_i': 10.49 * cfg.PV5_inh_noise_tau, 
                        'tau_e': 2.728 * cfg.PV5_exc_noise_tau, 
                        'std_i': 0.0264, 
                        'g_i0' : 0.0573 * cfg.PV5_inh_noise_amp, 
                        'E_e'  : cfg.PV5_exc_noise_e, 
                        'E_i'  : cfg.PV5_inh_noise_e, 
                        'seed1': 'gid', 
                        'seed2': id32('gluctp'), 
                        'seed3': cfg.seeds['stim']}}


Now to save everything and run twice to ensure we get the same noise.

cfg.simLabel = 'eee_net_37'
cfg.simLabel = 'eee_net_38'

Okay, those are the same. Now to change the seeds and see what happens

'seed2': id32('gluctp_exc'),
'seed2': id32('gluctp_inh'),

cfg.simLabel = 'eee_net_39'

Okay, now it's different.  Looking good, moving on.


** To work on now

Run big sim
IPSPs
Connectivity numbers
Plateau detection



* 2019-09-24 -- 

** Running a batch to explore IPSPs

batchLabel = 'v01_batch36'

Changing slow GABA weight to match fast GABA weight
cfg.GABAAfastWeight = 0.0001
cfg.GABAAslowWeight = cfg.GABAAfastWeight #0.0001

params['GABAAfastWeight'] = [0.0001, 0.001, 0.01, 0.1]

Increase GABA weight and the IPSPs start to show up.

Need to determine how big IPSPs should be.

** Running a batch of full sims with noise to explore IPSPs

batchLabel = 'v01_batch37'


** Measuring connectivity

Created init_norun.py to just set up sim without running it, then can look 
at inidividual cells and measure conns

Looking into Netpyne connectivity measurements


* 2019-09-30 -- 

** Running a batch on Comet using NSG allocation

Saving conns for analysis

Looking into how long it takes for a number of cells and how much 
data is produced

batchLabel = 'v01_batch38'
runType = 'hpc_slurm' # Either 'hpc_slurm' or 'mpi_bulletin'
params['numCells'] = [10, 100, 1000, 10000, 20000]
cfg.saveCellSecs = True #False
cfg.saveCellConns = True #False
'allocation': 'csd403', 


Will commit, pull to Comet, recompile mods, and execute batch.

cd /home/jwgraham/EEE_network/eee_net ; rm -rf x86_64 ; cd ../eee_single ; rm -rf x86_64 ; cd ../mod ; rm -rf x86_64

cd /home/jwgraham/EEE_network/mod ; nrnivmodl ; cd ../eee_net ; ln -s "../mod/x86_64" x86_64 ; cd ../eee_single ; ln -s "../mod/x86_64" x86_64

Got errors:
sbatch: error: bank_limit plugin: expired user, can't submit job
sbatch: error: Batch job submission failed: Invalid account or account/partition combination specified

Subha says to run on Stampede


** Attempting to run on Stampede...

ssh tg856217@stampede2.tacc.xsede.org


** Chats

joe 6:47 AM
I’d like to start running some big sims today, but I’ve never used NSG.  Apparently I just have to change the allocation number?  Does somebody know the allocation number for NSG?
@billl @subha?
billl 7:52 AM
dk offhand.  @don?
subha 8:35 AM
csd403
salvadord 8:35 AM
‘csd403’
ah :slightly_smiling_face:
don 8:39 AM
thank you subha
joe 9:25 AM
Thanks all!
subha 11:07 AM
Please use it on Stampede2 first
joe 11:09 AM
I just tried using it on Comet and got an error
Untitled 
sbatch: error: bank_limit plugin: expired user, can't submit job
sbatch: error: Batch job submission failed: Invalid account or account/partition combination specified



I’ll try it on Stampede…
subha 11:12 AM
I will check on your access.
Joe, Don, Salva, Bill? needs access through NSG?
joe 11:12 AM
Yes please.
subha 11:13 AM
For stampede2, please use account TG-IBN140002
Joe I dont see you on stampede2 under NSG allocation. I will add you so you can submit jobs
joe 11:19 AM
Thanks Subha!
Bill, did you ever get EEE running on Stampede? Could I see your setup?
subha 11:19 AM
Actually I dont see you on Comet as well which explains the error
billl 11:24 AM
subha was working on getting stuff running on stampede
subha 11:25 AM
Yes I can send you the instructions for using Stampede2 by eot
joe 11:26 AM
Awesome, thanks Subha.



** Looking into connectivity -- distance

I notice synaptic delays are partly based on distance, which we should change
to be distance-independent unless we want to properly scale the 3D space of the
model with the number of neurons.  But will come back to this later...




** Prelim code to count connections

for pop in sim.net.pops.keys():

    print("Population: ", pop)

    popGids = sim.net.pops[pop].cellGids

    for cellGid in popGids:

        print("  Cell: ", cellGid)

        cell = sim.net.cells[cellGid]

        conns = cell.conns

        for conn in conns:

            if isinstance(conn['preGid'], int):

                print("    synMech: ", conn['synMech'])


** Looking into Netpyne connectivity measures

Would be better to use Netpyne's analysis to measure connectivity

But I get this error:

In [19]: sim.analysis.plotConn()
Plotting connectivity matrix...
There was an exception in plotConn(): 
 'Network' object has no attribute 'allCells' 
(<class 'AttributeError'>, AttributeError("'Network' object has no attribute 'allCells'"), <traceback object at 0x11ec66408>)
Out[19]: -1


It looks like I needed to uncomment saveData in my init_norun.py file

sim.initialize(
    simConfig = cfg,    
    netParams = netParams)    # create network object and set cfg and net params
sim.net.createPops()          # instantiate network populations
sim.net.createCells()         # instantiate network cells based on defined populations
sim.net.connectCells()        # create connections between cells based on params
sim.net.addStims()            # add network stimulation
sim.setupRecording()          # setup variables to record (spikes, V traces, etc)
# sim.runSim()                  # run parallel Neuron simulation  
# sim.gatherData()              # gather spiking data and cell info from each node
sim.saveData()                # save params, cell info and sim output to file
# sim.analysis.plotData()       # plot spike raster etc

That creates the allCells in Network object

Now Netpyne plotConn outputs a figure and some data.  :)

In [1]: sim.analysis.plotConn()
Plotting connectivity matrix...
Out[1]: 
(<Figure size 1000x1000 with 2 Axes>,
 {'connMatrix': array([[ 7.2000e+00,  7.2000e+00,  7.2000e+00,  7.2000e+00,  1.8000e+00,
          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
         [ 7.2000e+00,  7.2000e+00,  7.2000e+00,  7.2000e+00,  1.8000e+00,
          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
         [ 7.2000e+00,  7.2000e+00,  7.2000e+00,  7.2000e+00,  1.8000e+00,
          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
         [ 7.2000e+00,  7.2000e+00,  7.2000e+00,  7.2000e+00,  1.8000e+00,
          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
         [ 5.7600e-02,  5.7600e-02,  5.7600e-02,  5.7600e-02,  1.4400e-02,
          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
         [ 1.0368e+04,  1.0368e+04,  0.0000e+00,  0.0000e+00,  0.0000e+00,
           0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
         [ 1.0368e+04,  1.0368e+04,  0.0000e+00,  0.0000e+00,  0.0000e+00,
           0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00],
         [ 1.6000e+01,  0.0000e+00,  1.6000e+01,  0.0000e+00,  0.0000e+00,
           0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00],
         [ 1.6000e+01,  0.0000e+00,  1.6000e+01,  0.0000e+00,  0.0000e+00,
           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]),
  'feature': 'strength',
  'groupBy': 'pop',
  'includePre': ['all'],
  'includePost': ['all']})



** Convergence doesn't scale with number of cells

Convergence is number of pre-synaptic cells connected to each post-synaptic cell

Divergence is number of post-synaptic cells connected to each pre-synaptic cell

Probability is probability of connection between each pre- and postsynaptic cell (0 to 1).

Will run a batch varying number of cells and measuring convergence, divergence, 
probability, numConns and strength

with 1) constant convergence
	 2) constant divergence
	 3) constant probability

Modifying cfg and netParams to allow changing type of connectivity.

But committing first.

batchLabel = 'v01_batch41'
    params['numCells'] = [10, 100, 1000, 5000, 10000]

cfg.EEconv = 3.0
cfg.EIconv = 3.0
cfg.IEconv = 12.0
cfg.IIconv = 12.0


Using convergence for connectivity:
batchLabel = 'v01_batch42'
file:gif/20191001_000901.png

Inhibitory weights are very low, increasing from 0.0001 to 0.01

Using convergence for connectivity:
batchLabel = 'v01_batch43'
file:gif/20191001_004339.png

** Modified cfg and netParams to allow choice of connectivity type

# Connectivity variables
cfg.connType = 'convergence'  # 'convergence', 'divergence', or 'probability'
cfg.EEconn = 3.0
cfg.EIconn = 3.0
cfg.IEconn = 12.0
cfg.IIconn = 12.0

Running a batch to ensure everything looks the same for convergence...

batchLabel = 'v01_batch44'
Everything looks good.

** Using divergence to set connectivity

# Connectivity variables
cfg.connType = 'divergence'  # 'convergence', 'divergence', or 'probability'
cfg.EEconn = 3.0
cfg.EIconn = 3.0
cfg.IEconn = 12.0
cfg.IIconn = 12.0

batchLabel = 'v01_batch45'
file:gif/20191001_013204.png

Looks identical to the 'convergence' setting


** Trying probability to set connectivity

batchLabel = 'v01_batch46'

# Connectivity variables
cfg.connType = 'probability'  # 'convergence', 'divergence', or 'probability'
cfg.EEconn = 0.1 #3.0
cfg.EIconn = 0.1 #3.0
cfg.IEconn = 0.2 #12.0
cfg.IIconn = 0.2 #12.0







** Netpyne connectivity is giving a probability of connection greater than 1.0

















** Attempting to use Stampede

subha 4:01 PM
Stampede2 NEURON/netpyne installation instructions. Once we have this set up through NSG ,you can directly use through NSG portal.
Untitled 
module purge
module load gnu
module load intel
module load mvapich2
module load python3
tar xvzf nrn-7.6.7.tar.gz
cd nrn-7.6
./configure —prefix=`pwd` --with-paranrn --with-nrnpython=python3 --without-iv
make
make install
pip3 install netpyne —-user
*create nrnenv with the following contents *
export N=$HOME/nrn-7.6
export CPU=x86_64
export PATH="$N/$CPU/bin:$PATH”
*To .bashrc, add*
export PYTHONPATH=$PYTHONPATH:/yourhomedir_path/nrn-7.6/lib/python:/yourhomedir_path/.local/lib/python3.7/site-packages
source /path/to/your/nrnenv




ssh tg856217@stampede2.tacc.xsede.org
login2(10)$ pwd
/home1/06322/tg856217
module purge
module load gnu

	Lmod has detected the following error:  The following module(s) are unknown: "gnu"

	Please check the spelling or version number. Also try "module spider ..."
	It is also possible your cache file is out-of-date; it may help to try:
	  $ module --ignore-cache load "gnu"

	Also make sure that all modulefiles written in TCL start with the string #%Module

module load intel
module load mvapich2
module load python3
tar xvzf nrn-7.6.7.tar.gz

	tar (child): nrn-7.6.7.tar.gz: Cannot open: No such file or directory
	tar (child): Error is not recoverable: exiting now
	tar: Child returned status 2
	tar: Error is not recoverable: exiting now

curl -O https://neuron.yale.edu/ftp/neuron/versions/v7.6/7.6.7/nrn-7.6.7.tar.gz

tar xvzf nrn-7.6.7.tar.gz

cd nrn-7.6

./configure —prefix=`pwd` --with-paranrn --with-nrnpython=python3 --without-iv
	
	configure: error: invalid variable name: `—prefix'

./configure --prefix=`pwd` --with-paranrn --with-nrnpython=python3 --without-iv

make

make install

pip3 install netpyne —-user

	Invalid requirement: '—-user'

pip3 install netpyne --user

export N=$HOME/nrn-7.6
login2(28)$ export CPU=x86_64
login2(29)$ export PATH="$N/$CPU/bin:$PATH"

cd
nano .bashrc

	Paste:
	export PYTHONPATH=$PYTHONPATH:/home1/06322/tg856217/nrn-7.6/lib/python:/home1/06322/tg856217/.local/lib/python3.7/site-packages
	source /home1/06322/tg856217/nrnenv

touch nrnenv
nano nrnenv

	Paste:
	export N=$HOME/nrn-7.6
	export CPU=x86_64
	export PATH="$N/$CPU/bin:$PATH"

ipython
In [1]: import neuron

	---------------------------------------------------------------------------
	ImportError                               Traceback (most recent call last)
	<ipython-input-1-5a1e2e1935ff> in <module>()
	----> 1 import neuron

	/home1/06322/tg856217/nrn-7.6/lib/python/neuron/__init__.py in <module>()
	    110     import neuron.hoc
	    111   except: # mingw name strategy
	--> 112     exec("import neuron.hoc%d%d as hoc" % (sys.version_info[0], sys.version_info[1]))
	    113 
	    114 import nrn

	<string> in <module>()

	ImportError: No module named hoc27


* 2019-10-01 -- 

** Applying connectivity using probability

batchLabel = 'v01_batch47'
    params['numCells'] = [10, 100, 500, 1000] #[10, 100, 500, 1000, 5000]

# Connectivity variables
cfg.connType = 'probability'  # 'convergence', 'divergence', or 'probability'
cfg.EEconn = 0.1 #3.0
cfg.EIconn = 0.1 #3.0
cfg.IEconn = 0.2 #12.0
cfg.IIconn = 0.2 #12.0

file:gif/20191001_071156.png



batchLabel = 'v01_batch48'
    params['numCells'] = [10, 100, 500, 1000, 5000]

# Connectivity variables
cfg.connType = 'probability'  # 'convergence', 'divergence', or 'probability'
cfg.EEconn = 0.05 #3.0
cfg.EIconn = 0.05 #3.0
cfg.IEconn = 0.05 #12.0
cfg.IIconn = 0.05 #12.0





* 2019-10-02 -- 

** Setting up sims on Stampede

git clone https://github.com/Neurosim-lab/EEE_network.git ; cd EEE_network/mod ; nrnivmodl ; cd ../eee_net ; ln -s "../mod/x86_64" x86_64




* 2019-10-03 -- 

** Looking into seg fault on Stampede

Going to run init.py line by line to see when/if seg fault happens.

joe 2:26 PM
I get segmentation faults when I attempt to run EEE on Stampede.
Attempting to run a job outputs an enormous error file full of seg faults.
When I just try to run cfg.py, I get a seg fault when using Python 3.  When I try it in Python 2, I get an error “ImportError: No module named reprlib”, which seems to be because the code is for py3.
joe 7:38 AM
On Stampede I can import netpyne and from netpyne import specs just fine, but when I from netpyne import sim that’s when the seg fault happens.
Any suggestions?
billl 9:10 AM
turn off graphics in netpyne __init.py__
salvadord 9:48 AM
I merged bill’s PR ysterday which I think might fix this
can pull latest and try
billl 11:03 AM
with new version use nrniv -nogui




* 2019-10-04 -- 

** To do in Stampede

Clone Netpyne git repo and switch to dev branch
Change save location of error and output files
Get sims running
Get batches running


** Updating netpyne

Salva thinks this may solve the seg fault problem

pip3 install --upgrade netpyne

That doesn't change anything.  Looks like the fix Salva pushed is in the development
branch of Netpyne.  Need to switch to development branch...

Netpyne lives here: ~/.local/lib/python3.7/site-packages/netpyne

cd ~/.local/lib/python3.7/site-packages/
mv netpyne netpyne_pip
git clone https://github.com/Neurosim-lab/netpyne.git
Cloning into 'netpyne'...
remote: Enumerating objects: 133, done.
remote: Counting objects: 100% (133/133), done.
remote: Compressing objects: 100% (96/96), done.
fatal: write error: Disk quota exceeded

Figured it out.  The problem was the error file was enormous and ended up in my home dir.

login3(201)$ ipython cfg.py
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
~/EEE_network/eee_net/cfg.py in <module>
----> 1 from netpyne import specs, sim
      2 import numpy as np
      3 import os
      4 
      5 # Show figures? Save figures?

ImportError: cannot import name 'specs' from 'netpyne' (unknown location)

It looks like netpyne_pip doesn't have another netpyne dir inside it like netpyne 
from git.

Trying to symlink into the netpyne dir in netpyne_git:

mv netpyne netpyne_git
ln -s /home1/06322/tg856217/.local/lib/python3.7/site-packages/netpyne_git/netpyne /home1/06322/tg856217/.local/lib/python3.7/site-packages/netpyne

Now cfg.py works, but I get a seg fault in netParams.py...
login3(220)$ ipython cfg.py
login3(221)$ ipython netParams.py
Segmentation fault

** Looking into netParams seg fault

So I get the seg fault at the second cellrule definition (line 53):
cellRule = netParams.importCellParams(label='PT5_1', conds={'pop':'PT5_1'}, fileName=eeeS_path, cellName='MakeCell', cellInstance=True)

The seg fault occurs when running eeeS.py

It occurs at this line:
from matplotlib import pyplot

Commenting out that line and trying.

Now it works.  And netParams.py works.

** Running init.py

File not found error:

	Saving output as data/eee_net_41/eee_net_41.json  ... 
	---------------------------------------------------------------------------
	FileNotFoundError                         Traceback (most recent call last)
	~/EEE_network/eee_net/init.py in <module>
	     38 sim.runSim()                  # run parallel Neuron simulation
	     39 sim.gatherData()              # gather spiking data and cell info from each node
	---> 40 sim.saveData()                # save params, cell info and sim output to file
	     41 sim.analysis.plotData()       # plot spike raster etc
	     42 

	~/.local/lib/python3.7/site-packages/netpyne/sim/save.py in saveData(include, filename)
	    138                 print(('Saving output as %s ... ' % (filePath+'.json ')))
	    139                 #dataSave = utils.replaceDictODict(dataSave)  # not required since json saves as dict
	--> 140                 sim.saveJSON(filePath+'.json', dataSave)
	    141                 print('Finished saving!')
	    142 

	~/.local/lib/python3.7/site-packages/netpyne/sim/save.py in saveJSON(fileName, data)
	     34 def saveJSON(fileName, data):
	     35     import json, io
	---> 36     with io.open(fileName, 'w', encoding='utf8') as fileObj:
	     37         str_ = json.dumps(data,
	     38                           indent=4, sort_keys=True,

	FileNotFoundError: [Errno 2] No such file or directory: 'data/eee_net_41/eee_net_41.json'

Will try making a data dir and seeing if it works.

Now it works.  Should include data dir in git repo (add .dummy file to data dir).


** Include data dir in git repo

Made a .dummy file in data and batch_data and added it to repo.  Now the data 
dirs should come with the Git repo.

Committing now.


** Change save location of error and output files

From runsim_stampede:

#SBATCH -o eee_net.o%j                          # Name of stdout output file
#SBATCH -e eee_net.e%j                          # Name of stderr error file

Changing to:

#SBATCH -o $SCRATCH/eee_net_%j.out              # Name of stdout output file
#SBATCH -e $SCRATCH/eee_net_%j.err              # Name of stderr error file


** Attempting to run sim on Stampede

Will commit, push, pull, run.

login3(267)$ ./runsim_stampede
-bash: ./runsim_stampede: Permission denied

chmod +x runsim_stampede

sbatch runsim_stampede

squeue -u tg856217
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4448759     skx-dev  eee_net tg856217 PD       0:00      4 (Resources)

Waiting on that.

Slurm Job_id=4448759 Name=eee_net Failed, Run time 00:00:05, FAILED, ExitCode 1

Can't find output or error file.

Changing runsim_stampede

#SBATCH -o /scratch/06322/tg856217/eee_net_%j.out     # Name of stdout output file
#SBATCH -e /scratch/06322/tg856217/eee_net_%j.err     # Name of stderr error file

Trying again.

sbatch runsim_stampede
squeue -u tg856217
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4448803     skx-dev  eee_net tg856217 PD       0:00      4 (Resources)


Slurm Job_id=4448803 Name=eee_net Ended, Run time 00:00:20, COMPLETED, ExitCode 0

Yay!

Now to try plotting a raster and some traces.

cfg.analysis['plotRaster'] = {'orderBy': 'y', 'orderInverse': True, 'saveFig': saveFig, 'showFig': showFig}

cfg.analysis['plotTraces'] = {'include': [('PT5_1', [0, 1, 2, 3]), ('PT5_2', [0, 1, 2, 3]), ('PT5_3', [0, 1, 2, 3]), ('PT5_4', [0, 1, 2, 3]), ('PV5', [0, 1, 2, 3])], 'saveFig': saveFig, 'showFig': showFig, 'ylim': [-80, 30]}  

sbatch runsim_stampede
squeue -u tg856217
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4449086     skx-dev  eee_net tg856217 PD       0:00      4 (Resources)




* 2019-10-07 -- 

** Adding a .gitignore file to exclude data and fig dirs

eee_net/data/*
eee_net/batch_data/*
eee_net/batch_figs/*

That worked.

** Looking at last sim

4449086

There was an error 

>>> Traceback (most recent call last):
  File "init.py", line 37, in <module>
    sim.setupRecording()          # setup variables to record (spikes, V traces, etc)
  File "/home1/06322/tg856217/.local/lib/python3.7/site-packages/netpyne/sim/setup.py", line 285, in setupRecording
    cellsRecord = utils.getCellsList(sim.cfg.recordCells)+cellsPlot
  File "/home1/06322/tg856217/.local/lib/python3.7/site-packages/netpyne/sim/utils.py", line 70, in getCellsList
    cellGids.extend(list(sim.net.pops[condition].cellGids))
  File "/home1/06322/tg856217/.local/lib/python3.7/site-packages/netpyne/specs/dicts.py", line 184, in __getitem__
    return super(ODict, self).__getitem__(k)
KeyError: 'include'


Also getting the same error locally.

I had cfg.recordCells as a dict instead of a list.  Works locally now.



** Running big long sim on Stampede


cfg.connType = 'probability'  # 'convergence', 'divergence', or 'probability'
cfg.EEconn = 0.05 #3.0
cfg.EIconn = 0.05 #3.0
cfg.IEconn = 0.2 #12.0
cfg.IIconn = 0.2 #12.0

cfg.simLabel = 'eee_net_42'

cfg.duration = 2400
cfg.numCells = 10000

cfg.saveCellSecs = False
cfg.saveCellConns = True #False

#SBATCH -t 01:00:00

login3(366)$ squeue -u tg856217
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4464598     skx-dev  eee_net tg856217 PD       0:00      4 (Resources)

Submitted at 5pm.  We'll see how long it takes to run.

It only took a couple minutes to start running.

Slurm Job_id=4464598 Name=eee_net Ended, Run time 00:10:59, COMPLETED, ExitCode 0

Adding an alias to .bashrc on Stampede to make squeue easier:

alias sq='squeue -u tg856217'

Nothing in the .err file.  The .out file looks fine.

The output file is over 5 gigs, so I should set the output from sims to go to 
the scratch dir instead of my home dir.

Added this to cfg.py:

baseFolder = '/scratch/06322/tg856217'
#baseFolder = 'data'
cfg.saveFolder = os.path.join(baseFolder, cfg.simLabel)


** Running a longer sim

It took 11 minutes to run 2400 ms.

I'll try running for 10 s (10000 ms), which should complete in less than an hour

             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4464655     skx-dev  eee_net tg856217  R       0:05      4 c506-[014,053-054,064]

Seems like it completed successfully, and it only took about 15 minutes.


** Get batch sims working on Stampede

v01_batch49

batchLabel = 'v01_batch49'

params['EEconn'] = [0.05, 0.1]
params['IEconn'] = [0.1, 0.2]

Shortening duration and number of cells for first attempt

cfg.duration = 2400 #10000
cfg.numCells = 1000 #10000

Looking at Netpyne batch code:

#SBATCH --job-name=%s 				simLabel
#SBATCH -A %s 						allocation
#SBATCH -t %s 						walltime
#SBATCH --nodes=%d 					nodes
#SBATCH --ntasks-per-node=%d 		coresPerNode
#SBATCH -o %s.run 					jobName
#SBATCH -e %s.err 					jobName
#SBATCH --mail-user=%s 				email
#SBATCH --mail-type=end 			
%s 									res
%s 									custom
source ~/.bashrc
cd %s 								folder
%s 									command


It looks like it takes care of everything in the example sbatch file from 
Subha except it doesn't allow setting of the development queue...

#SBATCH -p skx-dev                               # Queue (partition) name

It also seems like the .out and .err files will end up in my home dir, but we'll
see about that.

Looking into queues on Stampede:
https://portal.tacc.utexas.edu/user-guides/stampede2

I have been using the skx development queue, but should probably switch to skx normal
queue (skx-normal)...

I'm going to try running it once before adding a queue option to Netpyne.

login3(433)$ pwd
/home1/06322/tg856217/EEE_network/eee_net
login3(434)$ 
login3(434)$ python batch.py
Traceback (most recent call last):
  File "batch.py", line 1, in <module>
    from netpyne import specs
  File "/home1/06322/tg856217/.local/lib/python3.7/site-packages/netpyne/specs/__init__.py", line 14, in <module>
    standard_library.install_aliases()
  File "/home1/06322/tg856217/.local/lib/python3.7/site-packages/future/standard_library/__init__.py", line 453, in install_aliases
    __import__(newmodname)
ImportError: No module named reprlib


Had this problem earlier and Bill said
billl 11:03 AM
with new version use nrniv -nogui

I'll try adding that to Netpyne batch code.  


/home1/06322/tg856217/.local/lib/python3.7/site-packages/netpyne/batch.py

command = '%s -np %d nrniv -nogui -python -mpi %s simConfig=%s netParams=%s' % (mpiCommand, numproc, script, cfgSavePath, netParamsSavePath)

I get the same error.

Now to try setting __gui__ = False in netpyne's __init__.py

It was alreasy fixed by Bill.

The problem was I was running the batch as `python batch.py -nogui` when it should be
`python3 batch.py -nogui`

Now all the generated code gets spit out and the input files appear, but nothing
shows up in the queue.

I'm going to modify Netpyne to include the queue
#SBATCH -p skx-dev                        # Queue (partition) name

Actually, it looks like I can use the 'custom' option:
custom = self.runCfg.get('custom', '')

Custom gets added to the bottom of the sbatch file as is.

Added the queue selection in the runCfg:

        b.runCfg = {'type': 'hpc_slurm',
                    'allocation': allocation, 
                    'walltime': '00:20:00',
                    'nodes': 4,
                    'coresPerNode': 48,
                    'email': 'joe.w.graham@gmail.com',
                    'folder': runFolder,
                    'script': 'init.py', 
                    'mpiCommand': 'ibrun',
                    'skip': True
                    'custom': '#SBATCH -p skx-normal'}

Trying to run again:
batchLabel = 'v01_batch50'

python3 batch.py -nogui

Minor bug fix in batch.py

Trying again.

login3(507)$ python3 batch.py -nogui
login3(507)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4465582  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4465584  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4465585  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)

Now there are jobs in the queue, but only three instead of the four I expected.

Waiting to see what happens with the output.

The output made it, but the final sim in the batch wasn't run...  Not even the 
.err or .run files appear for it...


** Run another batch 

Running a larger batch, checking to see if final sim gets run

batchLabel = 'v01_batch51'

   params['EEconn'] = [0.05, 0.1, 0.2]
   params['IEconn'] = [0.1, 0.2, 0.3]

Now it looks like all 9 sims are being run:

login1(382)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4465646  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4465647  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4465648  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4465649  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4465650  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4465651  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4465652  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4465653  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4465654  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)

** Running batch varying number of cells

batchLabel = 'v01_batch52'
params['numCells'] = [10, 100, 500, 1000, 5000, 10000]

login1(388)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4465654  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4465676  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4465677  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4465678  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4465679  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4465680  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4465681  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)


** Analyze individual sims

I am going to start an interactive session to look into analysis.

idev

10:09 -- 5.1G
sim.load('eee_net_43.json', createNEURONObj=False)
Loading file eee_net_43.json ... 

10:13
  Done; file loading time = 265.87 s
Loading simConfig...
Loading netParams...
Loading net...

Ran out of time.

idev -m 120

10:29
sim.load('eee_net_43.json', createNEURONObj=False) 
Loading file eee_net_43.json ...

10:33
Loading net...

10:52
  Created 10000 cells
  Created 14997259 connections
  Created 592000 stims
  Done; re-instantiate net time = 1107.23 s
Loading simData...
Recording 0 traces of 0 types on node 0


In [3]: rasterFig, rasterData = sim.analysis.plotRaster(include=['PT5_1', 'PT5_2', 'PT5_3', 'PT5_4', 'PV5' ], orderInverse=False)                                                              
Plotting raster...
There was an exception in plotRaster(): 
 name 'plt' is not defined 
(<class 'NameError'>, NameError("name 'plt' is not defined"), <traceback object at 0x2b07e88f3208>)
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-3-3404260d8832> in <module>
----> 1 rasterFig, rasterData = sim.analysis.plotRaster(include=['PT5_1', 'PT5_2', 'PT5_3', 'PT5_4', 'PV5' ], orderInverse=False)

TypeError: cannot unpack non-iterable int object

In [4]: import matplotlib.pyplot as plt                                                                                                                                                        
Segmentation fault

* 2019-10-08 -- 

** Analyze individual sims

Submitting a smaller individual sim to get analyses working

cfg.simLabel = 'eee_net_44'

#SBATCH -t 00:20:00                                             # Run time (hh:mm:ss)

login4(567)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4466400 development idv92016 tg856217  R       6:46      1 c455-082
           4466405     skx-dev  eee_net tg856217  R       0:05      4 c506-[051-054]

idev -m 120 # get interactive sessions for two hours

cd /scratch/06322/tg856217/eee_net_44
sim.load('eee_net_44.json', createNEURONObj=False)
sim.analysis.plotRaster()   

There was an exception in plotRaster(): 
 name 'plt' is not defined

import matplotlib.pyplot as plt

Segmentation fault


** Looking into seg fault with matplotlib

https://blog.richard.do/2018/03/18/how-to-debug-segmentation-fault-in-python/

In [3]: import faulthandler 
In [4]: faulthandler.enable() 
In [5]: import matplotlib.pyplot                                                                                                                                                               
Fatal Python error: Segmentation fault

Thread 0x00002b9b821c2700 (most recent call first):
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/threading.py", line 296 in wait
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/threading.py", line 552 in wait
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/site-packages/IPython/core/history.py", line 829 in run
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/site-packages/IPython/core/history.py", line 58 in needs_sqlite
  File "</opt/apps/intel18/python3/3.7.0/lib/python3.7/site-packages/decorator.py:decorator-gen-24>", line 2 in run
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/threading.py", line 917 in _bootstrap_inner
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/threading.py", line 885 in _bootstrap

Current thread 0x00002b9b70152800 (most recent call first):
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/site-packages/gi/module.py", line 120 in __getattr__
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/site-packages/gi/overrides/Gtk.py", line 416 in MessageDialog
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/site-packages/gi/overrides/Gtk.py", line 412 in <module>
  File "<frozen importlib._bootstrap>", line 219 in _call_with_frames_removed
  File "<frozen importlib._bootstrap_external>", line 728 in exec_module
  File "<frozen importlib._bootstrap>", line 677 in _load_unlocked
  File "<frozen importlib._bootstrap>", line 967 in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 983 in _find_and_load
  File "<frozen importlib._bootstrap>", line 219 in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1035 in _handle_fromlist
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/site-packages/gi/module.py", line 255 in _load
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/site-packages/gi/importer.py", line 76 in load_module
  File "<frozen importlib._bootstrap>", line 638 in _load_backward_compatible
  File "<frozen importlib._bootstrap>", line 668 in _load_unlocked
  File "<frozen importlib._bootstrap>", line 967 in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 983 in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006 in _gcd_import
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/importlib/__init__.py", line 127 in import_module
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/site-packages/matplotlib/backends/_gtk3_compat.py", line 47 in <dictcomp>
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/site-packages/matplotlib/backends/_gtk3_compat.py", line 47 in <module>
  File "<frozen importlib._bootstrap>", line 219 in _call_with_frames_removed
  File "<frozen importlib._bootstrap_external>", line 728 in exec_module
  File "<frozen importlib._bootstrap>", line 677 in _load_unlocked
  File "<frozen importlib._bootstrap>", line 967 in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 983 in _find_and_load
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/site-packages/matplotlib/backends/backend_gtk3.py", line 14 in <module>
  File "<frozen importlib._bootstrap>", line 219 in _call_with_frames_removed
  File "<frozen importlib._bootstrap_external>", line 728 in exec_module
  File "<frozen importlib._bootstrap>", line 677 in _load_unlocked
  File "<frozen importlib._bootstrap>", line 967 in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 983 in _find_and_load
  File "<frozen importlib._bootstrap>", line 219 in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1035 in _handle_fromlist
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/site-packages/matplotlib/backends/backend_gtk3agg.py", line 6 in <module>
  File "<frozen importlib._bootstrap>", line 219 in _call_with_frames_removed
  File "<frozen importlib._bootstrap_external>", line 728 in exec_module
  File "<frozen importlib._bootstrap>", line 677 in _load_unlocked
  File "<frozen importlib._bootstrap>", line 967 in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 983 in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006 in _gcd_import
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/importlib/__init__.py", line 127 in import_module
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/site-packages/matplotlib/pyplot.py", line 207 in switch_backend
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/site-packages/matplotlib/pyplot.py", line 196 in switch_backend
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/site-packages/matplotlib/__init__.py", line 892 in __getitem__
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/site-packages/matplotlib/pyplot.py", line 2374 in <module>
  File "<frozen importlib._bootstrap>", line 219 in _call_with_frames_removed
  File "<frozen importlib._bootstrap_external>", line 728 in exec_module
  File "<frozen importlib._bootstrap>", line 677 in _load_unlocked
  File "<frozen importlib._bootstrap>", line 967 in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 983 in _find_and_load
  File "<ipython-input-5-864e826dab68>", line 1 in <module>
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/site-packages/IPython/core/interactiveshell.py", line 3267 in run_code
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/site-packages/IPython/core/interactiveshell.py", line 3185 in run_ast_nodes
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/site-packages/IPython/core/interactiveshell.py", line 3020 in run_cell_async
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/site-packages/IPython/core/async_helpers.py", line 67 in _pseudo_sync_runner
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/site-packages/IPython/core/interactiveshell.py", line 2845 in _run_cell
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/site-packages/IPython/core/interactiveshell.py", line 2819 in run_cell
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/site-packages/IPython/terminal/interactiveshell.py", line 485 in interact
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/site-packages/IPython/terminal/interactiveshell.py", line 494 in mainloop
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/site-packages/IPython/terminal/ipapp.py", line 356 in start
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/site-packages/traitlets/config/application.py", line 658 in launch_instance
  File "/opt/apps/intel18/python3/3.7.0/lib/python3.7/site-packages/IPython/__init__.py", line 125 in start_ipython
  File "/opt/apps/intel18/python3/3.7.0/bin/ipython", line 10 in <module>
Segmentation fault

** Searching Slack for problems with matplotlib

And found this:

billl 11:32 AM
import matplotlib.pyplot as plt
crashes it
import matplotlib by istelf does not
import pylab # crashes since same as other

salvadord 11:41 AM
soemthing that usually do to run sims on hpc is add at beginning : import matplotlib; matplotlib.use('Agg')

Trying it out:

In [1]: import matplotlib
In [2]: matplotlib.use('Agg') 
In [3]: import matplotlib.pyplot as plt 
In [4]: 

Success!

** Analyze individual sims

from netpyne import sim
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt 
sim.load('eee_net_44.json', createNEURONObj=False)
sim.analysis.plotRaster()  

Plotting raster...
There was an exception in plotRaster(): 
 name 'plt' is not defined 
(<class 'NameError'>, NameError("name 'plt' is not defined"), <traceback object at 0x2b8aa1108d48>)
Out[7]: -1

import faulthandler
faulthandler.enable()
import netpyne
netpyne.__gui__ = True
from netpyne import sim  


** Seeing if Netpyne is up to date

/home1/06322/tg856217/.local/lib/python3.7/site-packages/



** Use Bill's .bashrc file

Paths from Subha's bashrc:

 echo $PATH
/home1/06322/tg856217/nrn-7.6/x86_64/bin:
/opt/apps/intel18/python3/3.7.0/bin:
/opt/apps/intel18/mvapich2/2.3.1/bin:
/opt/intel/compilers_and_libraries_2018.2.199/linux/bin/intel64:
/opt/apps/gcc/6.3.0/bin:
/usr/lib64/qt-3.3/bin:
/usr/local/bin:
/bin:
/usr/bin:
/opt/dell/srvadmin/bin

echo $PYTHONPATH
:/home1/06322/tg856217/.local/lib/python3.7/site-packages:
/home1/06322/tg856217/nrn-7.6/lib/python

Bill's paths:

echo $PATH
/home1/03337/wwlytton/site/scripts:
/home1/03337/wwlytton/site/nrniv/nrn/x86_64/bin:
/opt/apps/xalt/xalt/bin:
/opt/apps/intel18/python3/3.7.0/bin:
/opt/apps/git/2.9.0/bin:
/opt/apps/cmake/3.10.2/bin:
/opt/apps/autotools/1.1/bin:
/opt/apps/libfabric/1.7.0/bin:
/opt/apps/intel18/impi/18.0.2/bin:
/opt/intel/compilers_and_libraries_2018.2.199/linux/mpi/intel64/bin:
/opt/intel/compilers_and_libraries_2018.2.199/linux/bin/intel64:
/opt/apps/gcc/6.3.0/bin:
/usr/lib64/qt-3.3/bin:
/usr/local/bin:
/bin:
/usr/bin:
/opt/dell/srvadmin/bin:.

echo $PYTHONPATH
/home1/03337/wwlytton/site/python:
/home1/03337/wwlytton/site/nrniv/nrn/lib/python:
/opt/apps/intel18/impi18_0/python3/3.7.0/lib/python3.7/site-packages


** Analyze individual sims

cd /scratch/06322/tg856217/eee_net_44
ipython
from netpyne import sim
sim.load('eee_net_44.json', createNEURONObj=False)
sim.analysis.plotRaster() 

There was an exception in plotRaster(): 
 name 'plt' is not defined 
(<class 'NameError'>, NameError("name 'plt' is not defined"), <traceback object at 0x2addc539c548>)
Out[3]: -1

I can't play around with Netpyne, because it's Bill's version I'm using.

Trying to get my own setup working.


* 2019-10-09 -- 

** Setting up Stampede

Looking into Bill's setup

Bill has netpyne in /home1/03337/wwlytton/site/python

I'll set mine up the same way: 

login2(647)$ cd ~
login2(648)$ mkdir site
login2(649)$ cd site
login2(650)$ mkdir python
login2(651)$ cd python


My Python path:
:/home1/06322/tg856217/.local/lib/python3.7/site-packages:
/home1/06322/tg856217/nrn-7.6/lib/python


Bill's Python path:
/home1/03337/wwlytton/site/python:
/home1/03337/wwlytton/site/nrniv/nrn/lib/python:
/opt/apps/intel18/impi18_0/python3/3.7.0/lib/python3.7/site-packages

From Bill's bashrc:
# SECTION 2: Please set or modify any environment variables inside the if block
# below.  For example, modifying PATH or other path like variables
# (e.g LD_LIBRARY_PATH), the guard variable (__PERSONAL_PATH___) 
# prevents your PATH from having duplicate directories on sub-shells.
if [ -z "$__PERSONAL_PATH__" ]; then
  export __PERSONAL_PATH__=1
  export SITE=/home1/03337/wwlytton/site
  export PATH=$SITE/scripts:$SITE/nrniv/nrn/x86_64/bin:$PATH
  export PYTHONPATH=$SITE/python:$SITE/nrniv/nrn/lib/python:$PYTHONPATH
fi

From my old .bashrc:
export PYTHONPATH=$PYTHONPATH:/home1/06322/tg856217/.local/lib/python3.7/site-packages:/home1/06322/tg856217/nrn-7.6/lib/python

From my new .bashrc:
# SECTION 2: Please set or modify any environment variables inside the if block
# below.  For example, modifying PATH or other path like variables
# (e.g LD_LIBRARY_PATH), the guard variable (__PERSONAL_PATH___)
# prevents your PATH from having duplicate directories on sub-shells.
if [ -z "$__PERSONAL_PATH__" ]; then
  export __PERSONAL_PATH__=1
  export SITE=/home1/03337/wwlytton/site
  export PATH=$SITE/scripts:$SITE/nrniv/nrn/x86_64/bin:$PATH
  #export PYTHONPATH=$SITE/python:$SITE/nrniv/nrn/lib/python:$PYTHONPATH
  export PYTHONPATH=/home1/06322/tg856217/.local/lib/python3.7/site-packages:$SITE/nrniv/nrn/lib/python:$PYTHONPATH
fi

Trying it out:

In [3]: from netpyne import sim 
Segmentation fault

Grrr.  Doesn't work anymore.

Trying from scratch:

cd ~
rm -rf .local/lib/*
rm -rf .local/bin/*
mkdir -p .local/lib/python3.7/site-packages
cd .local/lib/python3.7/site-packages
git clone https://github.com/Neurosim-lab/netpyne.git
cd netpyne
git checkout development
pip3 install -e . --user -I

That seems to have worked, but got a warning:

  The scripts f2py, f2py3 and f2py3.7 are installed in '/home1/06322/tg856217/.local/bin' which is not on PATH.
  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.

Adding this to my .bashrc file:


# SECTION 2: Please set or modify any environment variables inside the if block
# below.  For example, modifying PATH or other path like variables
# (e.g LD_LIBRARY_PATH), the guard variable (__PERSONAL_PATH___)
# prevents your PATH from having duplicate directories on sub-shells.
if [ -z "$__PERSONAL_PATH__" ]; then
  export __PERSONAL_PATH__=1
  export SITE=/home1/03337/wwlytton/site
  export PATH=$SITE/scripts:$SITE/nrniv/nrn/x86_64/bin:$PATH
  export PATH=/home1/06322/tg856217/.local/bin:$PATH
  #export PYTHONPATH=$SITE/python:$SITE/nrniv/nrn/lib/python:$PYTHONPATH
  export PYTHONPATH=/home1/06322/tg856217/.local/lib/python3.7/site-packages:$SITE/nrniv/nrn/lib/python:$PYTHONPATH
fi





__version__ = '0.9.3.1'
import os, sys
display = os.getenv('DISPLAY')
nogui = (sys.argv.count('-nogui')>0)
import matplotlib

if not nogui and display and len(display)>0:
    matplotlib.use('TkAgg')
    __gui__ = True                                        
else:
    matplotlib.use('Agg')
    __gui__ = False


** To run Netpyne on Stampede

module purge
module load intel
module load mvapich2
module load python3

mkdir ~/neuron 
cd ~/neuron
curl -O https://neuron.yale.edu/ftp/neuron/versions/v7.6/7.6.7/nrn-7.6.7.tar.gz
tar xvzf nrn-7.6.7.tar.gz
mv nrn-7.6 nrn
cd nrn
./configure --prefix=`pwd` --with-paranrn --with-nrnpython=python3 --without-iv
make
make install

mkdir -p ~/.local/lib/python3.7/site-packages/
cd ~/.local/lib/python3.7/site-packages/
git clone https://github.com/Neurosim-lab/netpyne.git
cd netpyne
git checkout development
pip3 install -e . --user -I

cd ~
cp .bashrc .bashrc_original
nano .bashrc

  Paste the following into the appropriate sections:

	module load git
	module load python3

	export PATH=$HOME/.local/bin:$PATH
	export PATH=$HOME/neuron/nrn/x86_64/bin:$PATH
	export PYTHONPATH=$HOME/neuron/nrn/lib/python:$PYTHONPATH
	export PYTHONPATH=$HOME/.local/lib/python3.7/site-packages:$PYTHONPATH
	
	alias sq="squeue -u $USER"
	alias sst="scontrol show jobid -d"
	alias ip="ipython -i"
	alias cdn="cd /home1/06322/tg856217/.local/lib/python3.7/site-packages/netpyne/netpyne"
	alias cde="cd /home1/06322/tg856217/EEE_network/eee_net"

  Uncomment the umask
	# umask 022


cd ~
git clone https://github.com/Neurosim-lab/EEE_network.git
cd EEE_network/mod
nrnivmodl
cd ~/EEE_network/eee_net/
ln -s "../mod/x86_64" x86_64





** Running a sim

cfg.simLabel = 'eee_net_45'

sbatch runsim_stampede 
Submitted batch job 4475764

Ran out of time
Upping time request
46

Submitted batch job 4475878



* 2019-10-10 -- 

** Getting plots out of NetPyNE on Stampede

Currently, runnning a sim doesn't automatically generate the plots requested 
in cfg.py.

Removing `-nogui` from the sbatch file (runsim_stampede) and seeing if that
solves the problem.

Also reducing connectivity.

eee_net_47

# Connectivity variables
cfg.connType = 'probability'  # 'convergence', 'divergence', or 'probability'
cfg.EEconn = 0.005 #0.05 #3.0
cfg.EIconn = cfg.EEconn #0.05 #3.0
cfg.IEconn = 0.02 #0.2 #12.0
cfg.IIconn = cfg.IEconn #0.2 #12.0

Submitted batch job 4477588

Got a timeout on this sim, but looking at the output file, it looks like it 
completed successfully (although there is a problem with plotting, need to 
look into what to do with __gui__).

	Analyzing...
	  Cells: 10000
	  Connections: 807000 (80.70 per cell)
	  Synaptic contacts: 2033657 (203.37 per cell)
	  Spikes: 16317 (0.68 Hz)
	  Simulated time: 2.4 s; 192 workers
	  Run time: 76.94 s
	Saving output as /scratch/06322/tg856217/eee_net_47/eee_net_47.json  ... 
	Finished saving!
	  Done; saving time = 40.19 s.
	Plotting raster...
	There was an exception in plotRaster(): 
	 couldn't connect to display "localhost:64.0" 
	(<class '_tkinter.TclError'>, TclError('couldn\'t connect to display "localhost:64.0"'), <traceback object at 0x2adf1e18ec88>)
	Plotting recorded cell traces ... cell
	There was an exception in plotTraces(): 
	 couldn't connect to display "localhost:64.0" 
	(<class '_tkinter.TclError'>, TclError('couldn\'t connect to display "localhost:64.0"'), <traceback object at 0x2adf7d6bee48>)
	  Done; plotting time = 2.02 s

	Total time = 215.89 s

Will try hard-coding the matplotlib backend as 'Agg'

Editing netpyne/__init__.py

	__version__ = '0.9.3.1'
	import os, sys
	display = os.getenv('DISPLAY')
	nogui = (sys.argv.count('-nogui')>0)
	import matplotlib

	#if not nogui and display and len(display)>0:
	#    matplotlib.use('TkAgg')
	#    __gui__ = True
	#else:
	#    matplotlib.use('Agg')
	#    __gui__ = False

	# Hard-coding __gui__ =	True and setting matplotlib to use Agg backend
	__gui__	= True
	matplotlib.use('Agg')

eee_net_48

Submitted batch job 4478229

That worked


* 2019-10-11 -- 

** Setting ineteractive backend for matplotlib when running interactively

You can request a development node on Stampede (-m is for minutes, 120 max):
idev -m 120

I want to see the plots when doing this.

Editing netpyne/__init__.py

	__version__ = '0.9.3.1'
	import os, sys
	display = os.getenv('DISPLAY')
	nogui = (sys.argv.count('-nogui')>0)
	import matplotlib

	if not nogui and display and len(display)>0:
	    matplotlib.use('TkAgg')
	    __gui__ = True
	else:
	    matplotlib.use('Agg')
	    __gui__ = True 

Now I get TkAgg on dev node.


** Looking into connectivity

I notice it may be better to use 'conn' for synOrConn:

	synOrConn ('syn'|'conn'): Use synapses or connections; note 1 connection can have multiple synapses (default: 'syn')

There's also an option to select a specific synMech:

	synMech (['AMPA', 'GABAA',...]): Show results only for these syn mechs (default: None)

Can also save data:
	saveData (None|True|'fileName'): File name where to save the final data used to generate the figure; 
	            if set to True uses filename from simConfig (default: None)

Set to save data.

Added to bottom on init.py:

# Additional analyses

	includePre  = ['PT5_1', 'PT5_2', 'PT5_3', 'PT5_4','PV5']
	includePost = ['PT5_1', 'PT5_2', 'PT5_3', 'PT5_4','PV5']
	feature     = 'numConns' #'divergence' #'convergence' #'strength' # 
	groupBy     = 'pop' #'cell'
	orderBy     = 'gid' #'y'
	synOrConn   = 'conn' #'syn'

	sim.analysis.plotConn(saveFig=True, showFig=False, saveData=True, includePre=includePre, includePost=includePost, feature=feature, groupBy=groupBy, orderBy=orderBy, synOrConn=synOrConn)

Reduced connectivity even further.

	# Connectivity variables
	cfg.connType = 'probability'  # 'convergence', 'divergence', or 'probability'
	cfg.EEconn = 0.0005 #0.005 #0.05 #3.0
	cfg.EIconn = cfg.EEconn #0.05 #3.0
	cfg.IEconn = 0.002 #0.02 #0.2 #12.0
	cfg.IIconn = cfg.IEconn #0.2 #12.0

Will run eee_net_49

Forgot to add -nogui back into init.py

Submitted batch job 4483534


** Connectivity plotting is taking forever in interactive mode

How I'm running it:

	In [1]: from netpyne import sim
	In [4]: sim.load('eee_net_48.json', createNEURONObj=False)

	Loading file eee_net_48.json ... 
	  Done; file loading time = 43.75 s
	Loading simConfig...
	Loading netParams...
	Loading net...
	  Created 10000 cells
	  Created 2033657 connections
	  Created 592000 stims
	  Done; re-instantiate net time = 222.48 s
	Loading simData...
	Recording 0 traces of 0 types on node 0

	In [9]: sa = sim.analysis   
	In [11]: sa.plotConn()            
	Plotting connectivity matrix...

Hopefully plotting during the submitted job will be quicker.



** eee_net_49

Still running on Stampede, but it seems to have finished:

	Analyzing...
	  Cells: 10000
	  Connections: 86021 (8.60 per cell)
	  Synaptic contacts: 736253 (73.63 per cell)
	  Spikes: 105937 (4.41 Hz)
	   PT5_1 : 5.859 Hz
	   PT5_2 : 4.987 Hz
	   PT5_3 : 4.626 Hz
	   PT5_4 : 3.961 Hz
	   PV5 : 2.638 Hz
	  Simulated time: 2.4 s; 192 workers
	  Run time: 70.78 s
	Saving output as /scratch/06322/tg856217/eee_net_49/eee_net_49.json  ... 
	Finished saving!
	  Done; saving time = 20.75 s.
	Plotting connectivity matrix...
	There was an exception in plotConn(): 
	 name 'plt' is not defined 
	(<class 'NameError'>, NameError("name 'plt' is not defined"), <traceback object at 0x2b718ec05ac8>)

Also another problem shows up:

	There was an exception in plotConn(): 
	 'Network' object has no attribute 'allCells' 
	(<class 'AttributeError'>, AttributeError("'Network' object has no attribute 'allCells'"), <traceback object at 0x2af3be1a3408>)

Part of this is likely the __gui__ problem...

Adding a line to the bottom of __init__:

	__version__ = '0.9.3.1'
	import os, sys
	display = os.getenv('DISPLAY')
	nogui = (sys.argv.count('-nogui')>0)
	import matplotlib

	if not nogui and display and len(display)>0:
	    matplotlib.use('TkAgg')
	    __gui__ = True
	else:
	    matplotlib.use('Agg')
	    __gui__ = True

	import matplotlib.pyplot as plt



** Preparing eee_net_50

Need to end the previous sim:

	stampede22(41)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4483297 development idv08224 tg856217  R    1:08:54      1 c455-112
           4483534     skx-dev  eee_net tg856217  R      20:11      4 c506-[054,092-094]

scancel 4483534

Submitted batch job 4483713

Getting the same errors:

There was an exception in plotConn(): 
 'Network' object has no attribute 'allCells' 
(<class 'AttributeError'>, AttributeError("'Network' object has no attribute 'allCells'"), <traceback object at 0x2ba4ac9520c8>)

There was an exception in plotConn(): 
 name 'plt' is not defined 
(<class 'NameError'>, NameError("name 'plt' is not defined"), <traceback object at 0x2af9ced24f48>)


** eee_net_51

Commenting out extra plotConn in init.py

Added the following to Netpyne init

print('===============================')
print('   Using backend:' , matplotlib.get_backend())
print('===============================')

cfg.py:
synOrConn   = 'conn' # 'syn' 

Submitted batch job 4484062

Same errors.

** eee_net_52

Commenting out the following in netpyne/sim/__init__.py

if '-nogui' in sys.argv:
    import netpyne
    netpyne.__gui__ = False

And then running.

Submitted batch job 4484113

Now it completes and generates figures!  :)

But it still leaves Stampede running...

scancel 4484113



** Alias for downloading analysis

I need an alias to quickly download png files from Stampede.

mkdir /u/graham/EEE_network/eee_net/data/eee_net_52

scp tg856217@stampede2.tacc.xsede.org:/scratch/06322/tg856217/eee_net_52/*.png /u/graham/EEE_network/eee_net/data/eee_net_52/

alias scpe='echo $1; mkdir /u/graham/EEE_network/eee_net/data/$1; scp tg856217@stampede2.tacc.xsede.org:/scratch/06322/tg856217/$1/*.png /u/graham/EEE_network/eee_net/data/$1/'

alias doens't accept input, need a function

scpe () {
    mkdir /u/graham/EEE_network/eee_net/data/$1 && scp tg856217@stampede2.tacc.xsede.org:/scratch/06322/tg856217/$1/*.png /u/graham/EEE_network/eee_net/data/$1/
}

Added that to .bash_profile and it works.


** Netpyne only generates the first trace plot

Creates blank figs for the rest.

Posting a question about this to Slack.

joe 3:20 PM
When I try to plot traces on Stampede, there is a .png file generated for each trace, but only the first trace has a plot, the rest are all blank.  Has anybody ever run into this before?
Untitled 
cfg.analysis['plotTraces'] = {'include': [('PT5_1', [0, 1, 2, 3]), ('PT5_2', [0, 1, 2, 3]), ('PT5_3', [0, 1, 2, 3]), ('PT5_4', [0, 1, 2, 3]), ('PV5', [0, 1, 2, 3])], 'saveFig': saveFig, 'showFig': showFig, 'ylim': [-80, 30]}

salvadord 3:25 PM
hey joe, just now I noticed traces not being recorded correctly when using the format (‘pop’, indices) on multiple cores — might be a bug introduced in a recent version (was working ok before)
I added github issue, will check asap — I believe using list of gids should work ok
joe 3:29 PM
Ahh, thanks Salva.  I’ll use gids for now.


** Turning noise off to see what underlying activity looks like

eee_net_53

# Noise variables
cfg.noisePT5 = False
cfg.noisePV5 = False

Submitted batch job 4484584

Finished, but didn't end Stampede run.


** eee_net_54

Will input current pulse to PT5_1 to drive activity

Will plot traces for PT5_2 looking for EPSPs

Will plot traces for PV5

Turning off plateaus and common inputs

Submitted batch job 4485450

4000 traces is a bit much.



** cfg.simLabel = 'eee_net_55'

Adding a current injection to PV5_1

Adding PV5_2, so can give stim to one half of PV cells

Recording from 20 of each cell type

Submitted batch job 4485990

Didn't work.

Made small fix to netParams.py

eee_net_56

Submitted batch job 4486074

Bumped down to 100 cells for debugging.

Minor fix to netParams.py

Minor fix to cfg.py

Seems to work now. Bumping back up to 10000 cells.

** eee_net_57

Submitted batch job 4486116

Seems to have worked fine, according to output file:

	Creating network of 6 cell populations on 192 hosts...
	  Number of cells on node 0: 53 
	  Done; cell creation time = 0.18 s.
	Making connections...
	  Number of connections on node 0: 422 
	  Number of synaptic contacts on node 0: 751 
	  Done; cell connection time = 67.34 s.
	Adding stims...
	  Number of stims on node 0: 16 
	  Done; cell stims creation time = 0.25 s.
	Recording 1 traces of 1 types on node 0

	Running simulation for 2400.0 ms...
	  Done; run time = 59.98 s; real-time ratio: 0.04.

	Gathering data...
	  Done; gather time = 2.12 s.

	Analyzing...
	  Cells: 10000
	  Connections: 80361 (8.04 per cell)
	  Synaptic contacts: 144796 (14.48 per cell)
	  Spikes: 48981 (2.04 Hz)
	   PT5_1 : 1.940 Hz
	   PT5_2 : 0.000 Hz
	   PT5_3 : 0.000 Hz
	   PT5_4 : 0.000 Hz
	   PV5_1 : 16.529 Hz
	   PV5_2 : 0.000 Hz
	  Simulated time: 2.4 s; 192 workers
	  Run time: 59.98 s
	Saving output as /scratch/06322/tg856217/eee_net_57/eee_net_57.json  ... 
	Finished saving!
	  Done; saving time = 3.71 s.
	Plotting raster...
	Saving figure data as /scratch/06322/tg856217/eee_net_57/eee_net_57_raster.pkl ... 
	Plotting spike histogram...
	Saving figure data as /scratch/06322/tg856217/eee_net_57/eee_net_57_spikeHist.pkl ... 
	Plotting recorded cell traces ... cell
	Plotting connectivity matrix...
	Saving figure data as /scratch/06322/tg856217/eee_net_57/eee_net_57_conn.pkl ... 
	  Done; plotting time = 243.00 s

	Total time = 376.84 s

It still ran through all the time on Stampede though...

	Slurm Job_id=4486116 Name=eee_net Failed, Run time 01:00:18, TIMEOUT, ExitCode 0

Looking at figures... Looks like they all appeared.  Copying them over to local
machine.

There's a lot of depolarization block.  Need to reduce the iClamp amplitude.


* 2019-10-12 -- 

** Reducing iClamp amplitude

eee_net_58

cfg.ampIClamp1 = 0.1 #1.0
cfg.ampIClamp2 = 0.1 #1.0

Increasing ylim (prev figs gut cut off below):

cfg.analysis['plotTraces'] = {'include': include, 'saveFig': saveFig, 'showFig': showFig, 'ylim': [-100, 30]}  # 'ylim': [-80, 30] 

Submitted batch job 4487639

Sim finished, Stampede is still running.

scancel 4487639

Response too small.  Doubling iclamp amp

eee_net_58 (forgot to update to 59)

Submitted batch job 4487717

mv eee_net_58 eee_net_58_1

scpe eee_net_58

No spiking in PV cells, increasing iclamp to PV5

eee_net_59

cfg.ampIClamp2 = 0.3 #0.2 #1.0

Submitted batch job 4487842

Worked, no Stampede cancelling

scancel 4487842

Turning noise on and running the same thing.

eee_net_60

Submitted batch job 4487941

Looks like too much noise.

Running a batch to explore noise.


** Submit a batch sim

batchLabel = 'v01_batch53'

    params['PT5_noise_scaling'] = [0, 0.01, 0.1, 1.0]    

Error:

	stampede22(262)$ python3 batch.py
	===============================
	   Using backend: TkAgg
	===============================
	Saving batch to /scratch/06322/tg856217/v01_batch52/v01_batch52_batch.json ... 
	(0,) (10,)
	numCells = 10
	Skipping job /scratch/06322/tg856217/v01_batch52/v01_batch52_0 since output file already exists...
	Traceback (most recent call last):
	  File "batch.py", line 68, in <module>
	    batchRun() 
	  File "batch.py", line 64, in batchRun
	    b.run()
	  File "/home1/06322/tg856217/.local/lib/python3.7/site-packages/netpyne/netpyne/batch/batch.py", line 460, in run
	    sleep(sleepInterval) # avoid saturating scheduler
	UnboundLocalError: local variable 'sleepInterval' referenced before assignment

Also, needs -nogui to use agg instead of TkAgg

	stampede22(263)$ python3 batch.py -nogui
	===============================
	   Using backend: agg
	===============================
	Saving batch to /scratch/06322/tg856217/v01_batch52/v01_batch52_batch.json ... 
	(0,) (10,)
	numCells = 10
	Skipping job /scratch/06322/tg856217/v01_batch52/v01_batch52_0 since output file already exists...
	Traceback (most recent call last):
	  File "batch.py", line 68, in <module>
	    batchRun() 
	  File "batch.py", line 64, in batchRun
	    b.run()
	  File "/home1/06322/tg856217/.local/lib/python3.7/site-packages/netpyne/netpyne/batch/batch.py", line 460, in run
	    sleep(sleepInterval) # avoid saturating scheduler
	UnboundLocalError: local variable 'sleepInterval' referenced before assignment

Forgot to do git pull on Stampede

git pull
python3 batch.py -nogui

	stampede22(271)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4488051  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4488052  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4488053  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4488054  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)


Some batch sims use agg and some TkAgg...

Getting errors with the TkAgg ones.

Added -nogui to the netpyne's batch.py HPC-slurm command:

- command = '%s -np %d nrniv -python -mpi %s simConfig=%s netParams=%s' % (mpiCommand, numproc, script, cfgSavePath, netParamsSavePath) 
+ command = '%s -np %d nrniv -python -mpi -nogui %s simConfig=%s netParams=%s' % (mpiCommand, numproc, script, cfgSavePath, netParamsSavePath) 

Trying again.

batchLabel = 'v01_batch54'

    params['PT5_noise_scaling'] = [0, 0.01, 0.1, 1.0]    
    params['PV5_noise_scaling'] = [0, 0.01, 0.1, 1.0]

stampede23(102)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4488262  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4488263  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4488264  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4488265  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4488266  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4488267  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4488268  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4488269  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4488270  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4488271  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4488272  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4488273  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4488274  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4488275  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)


Batch sims finished.

Changing the noise amplitude has no effect on the noise in the traces.

** Setting up a new batch to vary std in noise

batchLabel = 'v01_batch55'

    params['PT5_std_scaling'] = [0, 0.01, 0.1, 1.0]
    params['PV5_std_scaling'] = [0, 0.01, 0.1, 1.0]

python3 batch.py -nogui

	stampede23(9)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4490410  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4490411  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4490412  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4490413  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4490414  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4490415  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4490416  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4490417  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4490418  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4490419  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4490420  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4490421  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4490422  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4490423  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)


* 2019-10-13 -- 

** Looking at batch varying noise std

scpe v01_batch55

Varying the std of the noise DOES affect the amplitude of the noise.

Tough to compare by looking at so many plots.

Time to get plot_batch_vtraces working again...


* 2019-10-14 -- 

** Plot batch voltage traces

Adding a return to plot_vtraces:

    return (batchname, params, data)

So that I won't have to reload the data for every figure.

ipython
In [1]: import batch_analysis as ba 
In [2]: sc = '/scratch/06322/tg856217/' 
In [3]: batchName = 'v01_batch55'
In [4]: batch55 = ba.plot_vtraces(sc + batchName)   

FileNotFoundError: [Errno 2] No such file or directory: 'batch_data//scratch/06322/tg856217/v01_batch55//scratch/06322/tg856217/v01_batch55_batch.json'

Fixed batch_analysis to allow batchdatadir specification.

import batch_analysis as ba
batchdatadir = '/scratch/06322/tg856217/'
batchname = 'v01_batch55'
batch55 = ba.plot_vtraces(batchname, batchdatadir=batchdatadir, outputdir=batchdatadir+batchname)

That worked!

import batch_analysis as ba
batchdatadir = '/scratch/06322/tg856217/'
batchname = 'v01_batch54'
batch54 = ba.plot_vtraces(batchname, batchdatadir=batchdatadir, outputdir=batchdatadir+batchname)


** End of sims doesn't end Stampede run

Chat:

	joe 2:37 PM
	Hey Subha, recently, running Netpyne sims on Stampede, the sims complete successfully and generate output, but the Stampede sbatch runs until it hits the time limit before ending…  Have you seen this before?
	subha 4:04 PM
	Yes that happened when I used intelmpi instead of mvapich while installing NEURON
	joe 4:09 PM
	I did this before installing NEURON:
	Untitled 
	module purge
	module load intel
	module load mvapich2
	module load python3

	Shouldn’t that use mvapich?
	new messages
	subha 4:53 PM
	Yes
	Make sure you are also loading the same modules while running
	joe 4:54 PM
	Ahh, when running I just module load python3
	I’ll try adding the other modules and running.
	Thanks, Subha.
	When running, should I do module purge at the beginning?
	subha 4:57 PM
	Yes you can and then load all required modules

Adding the modules to .bashrc on Stampede


** Exploring noise

Different noise levels in PT5 cell:
file:gif/20191014_174900.png

Different noise levels in PV5 cell:
file:gif/20191014_175024.png

It looks like we want the STD scaling to be between 0.1 and 1.0

Running a new batch.

batchLabel = 'v01_batch56'

    params['PT5_std_scaling'] = [0.1, 0.3, 0.5, 0.7, 0.9]
    params['PV5_std_scaling'] = [0.1, 0.3, 0.5, 0.7, 0.9]

Error:

	stampede21(4)$ python batch.py -nogui
	Traceback (most recent call last):
	  File "batch.py", line 1, in <module>
	    from netpyne import specs
	  File "/home1/06322/tg856217/.local/lib/python3.7/site-packages/netpyne/netpyne/__init__.py", line 5, in <module>
	    import matplotlib
	  File "/home1/06322/tg856217/.local/lib/python3.7/site-packages/matplotlib/__init__.py", line 272
	    nonlocal called, ret
	                  ^
	SyntaxError: invalid syntax

Ahh, it needs to be Python3.  I keep forgetting that.

I'm going to make a runbatch_stampede file with:

	python3 batch.py -nogui

stampede21(16)$ ./runbatch_stampede
-bash: ./runbatch_stampede: Permission denied

graham$ chmod +x runsim_stampede

./runsim_stampede

	stampede21(22)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4502416  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4502417  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4502418  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4502419  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4502420  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4502421  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4502422  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4502423  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4502424  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4502425  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4502426  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4502427  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4502428  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4502430  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4502431  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4502432  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4502433  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4502434  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4502435  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4502436  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4502437  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4502438  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4502439  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4502441  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)


import batch_analysis as ba
batchdatadir = '/scratch/06322/tg856217/'
batchname = 'v01_batch56'
batch56 = ba.plot_vtraces(batchname, batchdatadir=batchdatadir, outputdir=batchdatadir+batchname, cellIDs=[0, 1, 2000, 2001, 4000, 4001, 6000, 6001, 8000, 8001, 9000, 9001])


PT5 cell
file:gif/20191014_224227.png

PV5 cell:
file:gif/20191014_224305.png

Setting noise std to 0.1 for both cell types.


** Exploring connectivity: EPSPs and IPSPs

batchLabel = 'v01_batch57'

    params['PT5_std_scaling'] = [0.0, 0.1]
    params['ampIClamp2'] = [0.3, 0.5, 0.7]

./runbatch_stampede

	stampede21(90)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4503458  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4503459  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4503460  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4503461  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4503462  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4503463  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)

Forgot to turn off glutamate puff.

Re-running batch:

batchLabel = 'v01_batch58'

	stampede21(97)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4503458  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4503459  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4503460  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4503461  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4503462  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4503463  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4503495  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4503496  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4503497  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4503498  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4503499  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4503500  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)


** Back to inducing plateaus and common inputs

batchLabel = 'v01_batch59'

# Connectivity variables
cfg.connType = 'probability'  # 'convergence', 'divergence', or 'probability'
cfg.EScale = 1.0
cfg.IScale = 1.0

cfg.EEconn = 0.0005 * cfg.EScale
cfg.EIconn = cfg.EEconn
cfg.IEconn = 0.002 * cfg.IScale
cfg.IIconn = cfg.IEconn

    params['EScale'] = [0.5, 1.0, 2.0]
    params['IScale'] = [0.5, 1.0, 2.0]

stampede21(103)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4503458  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4503459  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4503460  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4503461  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4503462  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4503463  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4503495  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4503496  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4503497  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4503498  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4503499  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4503500  skx-normal v01_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4503510  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4503511  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4503512  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4503513  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4503514  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4503515  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4503516  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4503517  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)


* 2019-10-15 -- 

** Analyzing last night's batches

** v01_batch57

import batch_analysis as ba
batchdatadir = '/scratch/06322/tg856217/'
batchname = 'v01_batch57'
batch57 = ba.plot_vtraces(batchname, batchdatadir=batchdatadir, outputdir=batchdatadir+batchname, cellIDs=[0, 1, 2000, 2001, 4000, 4001, 6000, 6001, 8000, 8001, 9000, 9001])

Error:

	~/EEE_network/eee_net/batch_analysis.py in plot_vtraces(batchname, batchdatadir, cellIDs, secs, timerange, param_labels, title, filename, save, outputdir)
	   1063             if filename is None:
	   1064                 print(str(os.path.join(outputdir, batchname + "_" + cellLabel + "_vtrace_1.png")))
	-> 1065                 fig1.savefig(os.path.join(outputdir, batchname + "_" + cellLabel + "_vtrace_1.png"))
	   1066                 fig2.savefig(os.path.join(outputdir, batchname + "_" + cellLabel + "_vtrace_2.png"))
	   1067             else:

	UnboundLocalError: local variable 'fig1' referenced before assignment

Weird, this worked fine last night.

I get the output expected except there are no traces...  Maybe they didn't get
recorded for some reason?


** v01_batch58

import batch_analysis as ba
batchdatadir = '/scratch/06322/tg856217/'
batchname = 'v01_batch58'
batch58 = ba.plot_vtraces(batchname, batchdatadir=batchdatadir, outputdir=batchdatadir+batchname, cellIDs=[0, 1, 2000, 2001, 4000, 4001, 6000, 6001, 8000, 8001, 9000, 9001])

Same error with v01_batch58

It looks like it didn't even try to plot the traces:

	Analyzing...
	  Cells: 10000
	  Connections: 80361 (8.04 per cell)
	  Synaptic contacts: 144796 (14.48 per cell)
	  Spikes: 10185 (0.42 Hz)
	   PT5_1 : 2.122 Hz
	   PT5_2 : 0.000 Hz
	   PT5_3 : 0.000 Hz
	   PT5_4 : 0.000 Hz
	   PV5_1 : 0.000 Hz
	   PV5_2 : 0.000 Hz
	  Simulated time: 2.4 s; 192 workers
	  Run time: 59.78 s
	Saving output as /scratch/06322/tg856217/v01_batch58/v01_batch58_0_0.json  ... 
	Finished saving!
	  Done; saving time = 3.66 s.
	Plotting connectivity matrix...
	Saving figure data as /scratch/06322/tg856217/v01_batch58/v01_batch58_0_0_conn.pkl ... 
	Plotting raster...
	Saving figure data as /scratch/06322/tg856217/v01_batch58/v01_batch58_0_0_raster.pkl ... 
	Plotting spike histogram...
	Saving figure data as /scratch/06322/tg856217/v01_batch58/v01_batch58_0_0_spikeHist.pkl ... 
	  Done; plotting time = 238.48 s

	Total time = 371.88 s
	TACC:  Shutdown complete. Exiting. 

I'm guessing the traces didn't get recorded for some reason.

Yeah, there's no trace data in the data file.

Looking at batch59


** v01_batch59

import batch_analysis as ba
batchdatadir = '/scratch/06322/tg856217/'
batchname = 'v01_batch59'
batch59 = ba.plot_vtraces(batchname, batchdatadir=batchdatadir, outputdir=batchdatadir+batchname, cellIDs=[0, 1, 2000, 2001, 4000, 4001, 6000, 6001, 8000, 8001, 9000, 9001])

It works on batch59 for some reason...  Don't know why it didn't for 57 or 58...



** Making plots for EEE meeting

Showing current injections in raster:
file:gif/20191015_073426.png

Showing EPSPs and IPSPs in PT cells
file:gif/20191015_073253.png

Showing EPSPs and IPSPs in PV cells
file:gif/20191015_073845.png

Noise is too high
file:gif/20191015_074649.png



* 2019-10-16 -- 

** Updated scpe for Control Master

#scpe () {
#    mkdir /u/graham/EEE_network/eee_net/data/$1 && scp tg856217@stampede2.tacc.xsede.org:/scratch/06322/tg856217/$1/*.png /u/graham/EEE_network/eee_net/data/$1/
#}

scpe () {
    mkdir /u/graham/EEE_network/eee_net/data/$1 ; scp stampede:/scratch/06322/tg856217/$1/*.png /u/graham/EEE_network/eee_net/data/$1/
}


** v01_batch60

Changing e_pas in FS3.py cell to have RMP nearer threshold:

e_pas = -65.0  #-73.0  # (Kawaguchi k Kubota, 1993 --> -73+-3.9)

cfg.connType = 'probability'  # 'convergence', 'divergence', or 'probability'
cfg.EScale = 1.0
cfg.IScale = 1.0

cfg.EEconn = 0.0005 * cfg.EScale
cfg.EIconn = 0.0005 * cfg.EScale
cfg.IEconn = 0.002 * cfg.IScale
cfg.IIconn = 0.002 * cfg.IScale

batchLabel = 'v01_batch60'
params['EScale'] = [0.1, 1.0, 10.0]
params['IScale'] = [0.1, 1.0, 10.0]

stampede24(4)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4514867  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4514868  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4514869  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4514870  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4514871  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4514872  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4514873  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4514874  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)

idev -m 120
import batch_analysis as ba
batchdatadir = '/scratch/06322/tg856217/'
batchname = 'v01_batch60'
batch = ba.plot_vtraces(batchname, batchdatadir=batchdatadir, outputdir=batchdatadir + batchname)

Need to increase current amplitude to PV cells, not seeing any spiking.

Need to reduce marker size in raster plot.  Default: lw=2

Setting to 1

cfg.analysis['plotRaster'] = {'orderBy': 'gid', 'orderInverse': True, 'lw': 1, 'saveFig': saveFig, 'showFig': showFig, 'saveData': saveData}


** batchLabel = 'v01_batch61'


batchLabel = 'v01_batch61'
    params['ampIClamp1'] = [0.4, 0.6, 0.8]
    params['ampIClamp2'] = [0.4, 0.6, 0.8, 1.0]


Turning noise off to see PSPs.

stampede23(4)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4515370  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515371  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515372  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515373  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515374  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515375  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515376  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515377  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515378  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515379  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515380  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515381  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)


import batch_analysis as ba
batchdatadir = '/scratch/06322/tg856217/'
batchname = 'v01_batch61'
batch = ba.plot_vtraces(batchname, batchdatadir=batchdatadir, outputdir=batchdatadir + batchname)

It didn't vary the current amplitude...  It seems I must use cfg.ampIClamp1 in netParams
instead of pulling it from the cfg file...

Modified netParams:

        if iclabel == 'IClamp1':
            amp = cfg.ampIClamp1
        elif iclabel == 'IClamp2':
            amp = cfg.ampIClamp2


        # add stim source
        #netParams.stimSourceParams[iclabel] = {'type': 'IClamp', 'del': ic['del'], 'dur': ic['dur'], 'amp': ic['amp']}
        netParams.stimSourceParams[iclabel] = {'type': 'IClamp', 'del': ic['del'], 'dur': ic['dur'], 'amp': amp}

** batchLabel = 'v01_batch62'

stampede23(21)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4515606  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515607  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515608  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515609  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515610  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515611  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515612  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515613  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515614  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515615  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515616  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515617  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)

import batch_analysis as ba
batchdatadir = '/scratch/06322/tg856217/'
batchname = 'v01_batch62'
batch = ba.plot_vtraces(batchname, batchdatadir=batchdatadir, outputdir=batchdatadir + batchname)

That doesn't seem to have quite worked.

Doing some hardcoding.

    netParams.stimSourceParams['IClamp1']['amp'] = cfg.ampIClamp1
    netParams.stimSourceParams['IClamp2']['amp'] = cfg.ampIClamp2

** batchLabel = 'v01_batch63'

    params['ampIClamp1'] = [0.1, 0.2, 0.4, 0.6]
    params['ampIClamp2'] = [0.1, 0.2, 0.4, 0.6]

stampede23(30)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4515742  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515743  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515744  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515745  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515746  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515747  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515748  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515749  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515750  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515751  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515752  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515753  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515754  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515755  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515756  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4515757  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)





** Modifying connectivity

Need to reduce I to E connectivity
file:gif/20191016_223227.png

Need to increase E to E connectivity
file:gif/20191016_223405.png

Need to increase E to I connectivity
file:gif/20191016_223550.png

Need to decrease I to I connectivity
file:gif/20191016_223550.png

So, need to increase E--> connectivity
and need to decrease I--> connectivity


** batchLabel = 'v01_batch64'

Increasing E conn
Decreasing I conn

   params['EScale'] = [2.0, 10.0, 50.0]
   params['IScale'] = [0.5, 0.1, 0.02]

stampede23(8)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4516063  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4516064  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4516065  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4516066  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4516067  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4516068  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4516069  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4516070  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4516071  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)

That didn't seem to vary the connectivity...

Added this to netParams:

EEconn = 0.0005 * cfg.EScale
EIconn = 0.0005 * cfg.EScale
IEconn = 0.002 * cfg.IScale
IIconn = 0.002 * cfg.IScale



** batchLabel = 'v01_batch65'

stampede23(105)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4516135  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4516136  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4516137  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4516138  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4516139  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4516140  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4516141  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4516142  skx-normal v01_batc tg856217 PD       0:00      4 (Resources)
           4516143  skx-normal v01_batc tg856217 PD       0:00      4 (Resource


import batch_analysis as ba
batchdatadir = '/scratch/06322/tg856217/'
batchname = 'v01_batch65'
batch = ba.plot_vtraces(batchname, batchdatadir=batchdatadir, outputdir=batchdatadir + batchname)




** PV cells not sitting at -65 mV

I set e_pas to -65, but PV cells are sitting at about -70

Need to look into this.  Maybe the h current?

Maybe try varying e_pas to see the effect?



* 2019-10-17 -- 

** Looking at conn varyong batch65

Need to increase iClamp amp to PV5 cells
cfg.ampIClamp2 = 0.3 #0.2

Want to set EScale between 10 and 50
file:gif/20191017_083708.png

Can't see IScale (no PV5 spiking), but will decrease to between 0.1 and 0.02

batchLabel = 'v01_batch66'

    params['EScale'] = [10.0, 20.0, 30.0]
    params['IScale'] = [0.1, 0.05, 0.033]

Also throwing in a plateau induction to the sims

stampede23(109)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4517222  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4517223  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4517224  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4517226  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4517227  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4517229  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4517230  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4517231  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)



Gao PP, Graham JW, Zhou W, Jang J, Angulo S, Dura-Bernal S, Hines M, Lytton WW, & Antic SD



** v01_batch67

cfg.ampIClamp2 = 0.25 #0.3

cfg.EEconn = 0.0005 * cfg.EScale
cfg.EIconn = 0.0005 * cfg.EScale
cfg.IEconn = 0.0005 * cfg.IScale
cfg.IIconn = 0.0005 * cfg.IScale

    params['EScale'] = [0.0, 5.0, 10.0, 15.0]
    params['IScale'] = [0.0, 5.0, 10.0, 15.0]

stampede23(172)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4520177  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520178  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520179  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520180  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520181  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520182  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520184  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520185  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520186  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520187  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520188  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520189  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520190  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520191  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520192  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520194  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)

Forgot to edit conns in netParams.  Cancelling queue.

stampede23(194)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4520222  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520223  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520224  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520225  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520226  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520227  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520228  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520230  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520231  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520232  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520233  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520234  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520235  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520236  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4520237  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)



* 2019-10-18 -- 

** Setting up a batch to explore PV cells

Want to find an injected current amplitude that results in decent spiking 
in order to look at connectivity

Start by getting a frequency-current relationship for injected currents

Copying eee_net to eee_net_test and working there.

batchLabel = 'test_batch01'

    params['ampIClamp1'] = [0.2]
    params['ampIClamp2'] = [0.1, 0.2, 0.3, 0.4, 0.5]

ipython
import batch_analysis as ba
batchdatadir = 'data/'
batchname = 'test_batch01'
batch = ba.plot_vtraces(batchname, batchdatadir=batchdatadir, outputdir=batchdatadir + batchname)

file:gif/20191018_155625.png

The PV cells start spiking like crazy somehwere between 0.2 and 0.3 iclamp amp

batchLabel = 'test_batch02'

    params['ampIClamp1'] = [0.2]
    params['ampIClamp2'] = [0.2, 0.125, 0.25, 0.275, 0.3]


** Adding plot_vtraces to the end of batch.py

That way Stampede will automatically generate the figures and I won't have
to do it manually any more.

Adding to the end of batch.py:

# Main code
if __name__ == '__main__':
    b = batchRun() 

	import batch_analysis as ba
	batch = ba.plot_vtraces(batchLabel, batchdatadir=saveFolder, outputdir=saveFolder + batchLabel)

That works!  Now batch v_traces will be created right after running the batch.


** Lookint at PV current injection

batchLabel = 'test_batch04'

Good range for PV5 iclamp amplitude:
file:gif/20191018_175753.png

Running again with noise turned on:

batchLabel = 'test_batch05'

No spiking with noise on:
file:gif/20191018_180510.png

Batch with noise:

batchLabel = 'test_batch06'

    params['ampIClamp2'] = [0.2, 0.125, 0.25, 0.275, 0.3]
    params['PT5_std_scaling'] = [0.0, 0.05, 0.1]

Noise in PV cells doesn't drop to nothing at 0.0... (PT cell noise does)


Setting PV noise settings to same as PT and running again

batchLabel = 'test_batch07'

Still seeing noise in PV cells but not in PT cells at 0.0


batchLabel = 'test_batch08'
    params['ampIClamp2'] = [0.2, 0.125, 0.25, 0.275, 0.3]
    params['noisePV5'] = [True, False]


Now the noise and non-noise look about the same (i.e. good).
file:gif/20191019_102909.png



* 2019-10-19 -- 

** Looking into connectivity

Now that the noise is good, time to look at connectivity.

cfg.EEconn = 1.0 #0.0005 # Will be multiplied by cfg.EScale
cfg.EIconn = 1.0 #0.0005 # Will be multiplied by cfg.EScale
cfg.IEconn = 1.0 #0.0005 # Will be multiplied by cfg.IScale
cfg.IIconn = 1.0 #0.0005 # Will be multiplied by cfg.IScale

cfg.ampIClamp2 = 0.25

cfg.simLabel = 'eee_net_test_01'

Too noisy to see much.  

** Looking into noise

Running a batch:

batchLabel = 'test_batch09'

    params['ampIClamp2'] = [0.24, 0.25, 0.26] 
    params['noisePV5'] = [True, False]

Reducing noise in PV cells.

First I will reset noise settings to Gfluctp.mod defaults.

std_e: 0.0120 --> 0.0030
std_i: 0.0264 --> 0.0066

cfg.PT5_exc_noise_amp = 1.0     # g_e0        : 0.0121 * cfg.PT5_exc_noise_amp
cfg.PT5_exc_noise_std = 1.0     # std_e       : 0.0030 * cfg.PT5_exc_noise_std
cfg.PT5_exc_noise_e   = 0.0     # Default E_e : 0.0
cfg.PT5_exc_noise_tau = 1.0     # tau_e       : 2.728 * cfg.PT5_exc_noise_tau
cfg.PT5_inh_noise_amp = 1.0     # g_i0        : 0.0573 * cfg.PT5_inh_noise_amp
cfg.PT5_inh_noise_std = 1.0     # std_i       : 0.0066 * cfg.PT5_inh_noise_std
cfg.PT5_inh_noise_e   = -75.0   # Default E_i : -75.0
cfg.PT5_inh_noise_tau = 1.0     # tau_i       : 10.49 * cfg.PT5_inh_noise_tau

cfg.PV5_exc_noise_amp = 1.0     # g_e0        : 0.0121 * cfg.PV5_exc_noise_amp
cfg.PV5_exc_noise_std = 1.0     # std_e       : 0.0030 * cfg.PV5_exc_noise_std
cfg.PV5_exc_noise_e   = 0.0     # Default E_e : 0.0
cfg.PV5_exc_noise_tau = 1.0     # tau_e       : 2.728 * cfg.PV5_exc_noise_tau
cfg.PV5_inh_noise_amp = 1.0     # g_i0        : 0.0573 * cfg.PV5_inh_noise_amp
cfg.PV5_inh_noise_std = 1.0     # std_i       : 0.0066 * cfg.PV5_inh_noise_std
cfg.PV5_inh_noise_e   = -75.0   # Default E_i : -75.0
cfg.PV5_inh_noise_tau = 1.0     # tau_i       : 10.49 * cfg.PV5_inh_noise_tau

Running a sim.

cfg.simLabel = 'eee_net_test_02'

Noise looks good, but PV5 noise is larger (because PV5 cells are smaller?)
file:gif/20191019_121324.png

Running a batch to explore reducing PV5 noise.

batchLabel = 'test_batch10'

    params['PV5_exc_noise_amp'] = [0.0, 0.5, 1.0, 2.0, 10.0]
    params['PV5_exc_noise_std'] = [0.0, 0.5, 1.0, 2.0, 10.0]

Added a scaling factor for both exc and inh noise amp and std:

batchLabel = 'test_batch11'

    params['PV5_noise_amp'] = [0.25, 0.5, 0.75, 1.0, 10.0]
    params['PV5_noise_std'] = [0.25, 0.5, 0.75, 1.0, 10.0]

file:gif/20191019_124434.png

Zooming in on lower values for another batch

batchLabel = 'test_batch12'

    params['PV5_noise_amp'] = [0.1, 0.2, 0.3, 10.0]
    params['PV5_noise_std'] = [0.1, 0.2, 0.3, 10.0]

file:gif/20191019_125218.png

Will scale PV5 amp and std by 0.1:

cfg.PV5_noise_amp = 0.1 #1.0
cfg.PV5_noise_std = 0.1 #1.0

** Looking into connectivity

First to find good values for iClamp amplitude to get some PV5 spiking

batchLabel = 'test_batch13'

    params['ampIClamp2'] = [0.25, 0.275, 0.30, 0.3125, 0.325]
    params['noisePV5'] = [False, True]

file:gif/20191019_130208.png

iClamp amps between 0.3125 and 0.325 should be good.

Not seeing iClamp response in PT5 cells...

Looking into it.

batchLabel = 'test_batch14'

    params['ampIClamp1'] = [0.2, 0.4, 0.6, 0.8]
    params['ampIClamp2'] = [0.3125, 0.325]

Comparing PT and PV cell:
file:gif/20191019_130850.png

** I think I want to reduce PT noise a bit.

Running a batch to explore.

batchLabel = 'test_batch15'

    params['PT5_noise_amp'] = [0.1, 0.25, 0.5, 0.75, 1.0]
    params['PT5_noise_std'] = [0.1, 0.25, 0.5, 0.75, 1.0]

file:gif/20191019_135359.png

Will scale PT5 amp and std by 0.25:

cfg.PT5_noise_amp = 0.25 #1.0
cfg.PT5_noise_std = 0.25 #1.0


** Running a batch varying iClamp amps

batchLabel = 'test_batch16'

    params['ampIClamp1'] = [0.3, 0.4, 0.5, 0.6]
    params['ampIClamp2'] = [0.3, 0.3125, 0.325, 0.375]

Noise is looking good!
file:gif/20191019_140525.png

Will set PT5 iclamp at 0.3
Will set PV5 iclamp at 0.3125

Running a single sim:
cfg.simLabel = 'eee_net_test_03'
file:gif/20191019_141148.png

Running the same thing with noise off:
cfg.simLabel = 'eee_net_test_04'
file:gif/20191019_141659.png

Need to reduce I-->I
Need to increase E-->E

But these are all single connections, so need to reduce weight of synapses...

But that may affect the plateau.

Turning on plateaus for a sim.

With noise:
cfg.simLabel = 'eee_net_test_05'
file:gif/20191019_143319.png

Without noise:
cfg.simLabel = 'eee_net_test_06'
file:gif/20191019_143431.png


** Exc Connectivity

Running a batch to explore NMDA weight

batchLabel = 'test_batch17'

    params['NMDAweight'] = [0.2, 0.3, 0.4, 0.5]
    params['noise'] = [False, True]

Need to crank the weight way higher

batchLabel = 'test_batch18'

    params['NMDAweight'] = [0.2, 1.0, 2.0, 10.0, 20.0]
    params['noise'] = [False, True]

Looks like we need an NMDA weight between 1.0 and 2.0 for no noise
Looks like we need an NMDA weight between 2.0 and 10.0 for no noise

file:gif/20191019_145628.png

batchLabel = 'test_batch19'

    params['NMDAweight'] = [1.0, 1.25, 1.5, 2.0, 4.0, 6.0, 8.0]
    params['noise'] = [False, True]

file:gif/20191019_153059.png

Setting NMDAweight = 1.5 and exploring inhibitory weight

** Inh Connectivity

batchLabel = 'test_batch20'

    params['GABAAfastWeight'] = [0.01, 0.001, 0.0001 0.00001]
    params['noise'] = [False, True]

file:gif/20191019_161100.png

Setting GABAAfastWeight to 0.0001 and then getting this back into the main
directory for running large sims on Stampede.

Running one sim to make sure it works, then committing to save this stuff.

cfg.simLabel = 'eee_net_test_07'

It works, committing now.

** Getting changes into main repo

Replacing old cfg.py with new one.
Same with netParams.py and batch.py

Committing, then setting back up for Stampede.


** Running a batch on Stampede

batchLabel = 'v01_batch68'

    params['GABAAfastWeight'] = [0.001, 0.0001, 0.00001]
    params['NMDAweight'] = [0.02, 0.2, 2.0]

When trying to run the batch on Stampede, I immediately got this error:

Plotting voltage traces...
Reading data...
9 files missing
Traceback (most recent call last):
  File "batch.py", line 89, in <module>
    batch = ba.plot_vtraces(batchLabel, batchdatadir=saveFolder, outputdir=saveFolder + batchLabel)
  File "/home1/06322/tg856217/EEE_network/eee_net/batch_analysis.py", line 1026, in plot_vtraces
    sim_data = data[list(data.keys())[0]]['simData']
IndexError: list index out of range

I guess auto-analyzing after the batch won't work on Stampede.

Commenting that out.

stampede21(17)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4528560  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4528561  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4528562  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4528563  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4528564  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4528565  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4528566  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)
           4528567  skx-normal v01_batc tg856217 PD       0:00      4 (Priority)


import batch_analysis as ba
batchdatadir = '/scratch/06322/tg856217/'
batchname = 'v01_batch68'
batch = ba.plot_vtraces(batchname, batchdatadir=batchdatadir, outputdir=batchdatadir + batchname)

Output looks okay.  Now to explore synaptic connectivity

** Scaling synaptic connectivity

Made so many changes to netParams I am bumping it up to v 2

batchLabel = 'v02_batch01'

    params['EScale'] = [0.1, 0.5, 1.0, 5.0, 10.0]
    params['IScale'] = [0.1, 0.5, 1.0, 5.0, 10.0]

Committing and running on Stampede.

stampede21(33)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4528711  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4528712  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4528713  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4528714  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4528715  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4528716  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4528717  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4528718  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4528719  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4528720  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4528721  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4528722  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4528723  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4528724  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4528725  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4528726  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4528727  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4528728  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4528729  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4528730  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4528732  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4528733  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4528734  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4528735  skx-normal v02_batc tg856217 PD       0:00      4 (Resources)
           4528736  skx-normal v02_batc tg856217 PD       0:00      4 (Resources)

import batch_analysis as ba
batchdatadir = '/scratch/06322/tg856217/'
batchname = 'v02_batch01'
batch = ba.plot_vtraces(batchname, batchdatadir=batchdatadir, outputdir=batchdatadir + batchname)

Scaling the synaptic connectivity doesn't seem to have much of an effect.

I'm going to set the connectivity scaling at 1.0 and run a batch varying synaptic
weights.

batchLabel = 'v02_batch02'

    params['GABAAfastWeight'] = [0.01, 0.001, 0.0001, 0.00001]
    params['NMDAweight'] = [0.02, 0.2, 2.0, 10.0]

stampede21(9)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4529226  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4529227  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4529228  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4529229  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4529230  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4529231  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4529232  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4529233  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4529234  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4529235  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4529236  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4529237  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4529239  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4529240  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4529241  skx-normal v02_batc tg856217 PD       0:00      4 (Resources)

This one is taking awhile:
4529236  skx-normal v02_batc tg856217  R      27:57      4 c502-[083,114],c503-[133-134]

Barely made it!
4529236  skx-normal v02_batc tg856217 CG      29:56      1 c503-134


** Setting up batch sim to create sync bar plots

batchLabel = 'v02_batch03'

    params['glutAmp'] = [1.5, 2.0, 2.5]
    params['noise_scale'] = [0.25, 1.0, 4.0]

stampede21(37)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4529660  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4529661  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4529662  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4529663  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4529664  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4529665  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4529666  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4529667  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4529668  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)

import batch_analysis as ba
batchdatadir = '/scratch/06322/tg856217/'
batchname = 'v02_batch03'
batch = ba.plot_vtraces(batchname, batchdatadir=batchdatadir, outputdir=batchdatadir + batchname)

import dev
dev.plotBatchSync(batchPath='/scratch/06322/tg856217/', batchLabel='v02_batch03')

** Install PySpike

Error: plotSpikeStats() requires the PySpike python package                             to calculate synchrony (try: pip install pyspike)

Installing PySpike:
cd /home1/06322/tg856217/.local/lib/python3.7/site-packages/
git clone https://github.com/mariomulansky/PySpike.git
cd PySpike
python3 setup.py build_ext --inplace

export PYTHONPATH=$HOME/.local/lib/python3.7/site-packages/PySpike:$PYTHONPATH

** Plot sync

batchLabel = 'v02_batch04'

    seeds['stim'] = [1234, 2345, 3456, 4567, 5678]

Traceback (most recent call last):
  File "batch.py", line 96, in <module>
    batchRun() 
  File "batch.py", line 54, in batchRun
    seeds['stim'] = [1234, 2345, 3456, 4567, 5678]
NameError: name 'seeds' is not defined

    params['seeds['stim']'] = [1234, 2345, 3456, 4567, 5678]

File "batch.py", line 54
    params['seeds['stim']'] = [1234, 2345, 3456, 4567, 5678]
                      ^
SyntaxError: invalid syntax


    params["seeds['stim']"] = [1234, 2345, 3456, 4567, 5678]


stampede21(85)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4529962  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4529963  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4529964  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4529965  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4529967  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)


import dev
dev.plotBatchSync(batchPath='/scratch/06322/tg856217/', batchLabel='v02_batch04')


Didn't vary the noise.

cfg.seeds = {'conn': 4123, 'stim': 1234, 'loc' : 3214}

batchLabel = 'v02_batch05'

    params['seeds'] = [{'conn': 4123, 'stim': 1234, 'loc' : 3214}, 
                        {'conn': 4123, 'stim': 2345, 'loc' : 3214}, 
                        {'conn': 4123, 'stim': 3456, 'loc' : 3214}, 
                        {'conn': 4123, 'stim': 4567, 'loc' : 3214}, 
                        {'conn': 4123, 'stim': 5678, 'loc' : 3214}]

stampede21(107)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4530042  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530043  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530044  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530045  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530046  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)

That worked.  Now noise is different in each sim.

import dev
dev.plotBatchSync(batchPath='/scratch/06322/tg856217/', batchLabel='v02_batch05')



** Looking into noise and glutAmp

batchLabel = 'v02_batch06'

    params['glutAmp'] = [2.0, 3.0, 5.0, 10.0]
    params['noise_std_scale'] = [1.0, 2.0, 4.0, 10.0]

Forgot to save the batch file before committing.

batchLabel = 'v02_batch07'

    params['glutAmp'] = [2.0, 3.0, 5.0, 10.0]
    params['noise_std_scale'] = [1.0, 2.0, 4.0, 10.0]

stampede21(151)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4530167  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530168  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530169  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530170  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530171  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530172  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530173  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530174  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530175  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530176  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530177  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530178  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530179  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530180  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530181  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)


import batch_analysis as ba
batchdatadir = '/scratch/06322/tg856217/'
batchname = 'v02_batch07'
batch = ba.plot_vtraces(batchname, batchdatadir=batchdatadir, outputdir=batchdatadir + batchname)

Need more spiking: higher noise is good for PT cells, but no spiking even at high
noise in PV cells...






** synsPerConn

The default value is one.  If cells are connected, there is only one synapse between
them...

I guess this is why Sergio used convergence...

Adding synsPerConn option to cfg and netParams

batchLabel = 'v02_batch08'

    params['EIspc'] = [1, 3, 5]
    params['EEspc'] = [1, 3, 5]

stampede21(167)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4530691  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530692  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530695  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530696  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530697  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530700  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530705  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530709  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530714  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)

Error:

	Traceback (most recent call last):
	  File "init.py", line 32, in <module>
	    sim.net.connectCells()        # create connections between cells based on params
	  File "/home1/06322/tg856217/.local/lib/python3.7/site-packages/netpyne/netpyne/network/conn.py", line 78, in connectCells
	    connFunc(preCellsTags, postCellsTags, connParam)  # call specific conn function
	  File "/home1/06322/tg856217/.local/lib/python3.7/site-packages/netpyne/netpyne/network/conn.py", line 404, in probConn
	    self._addCellConn(connParam, preCellGid, postCellGid) # add connection
	  File "/home1/06322/tg856217/.local/lib/python3.7/site-packages/netpyne/netpyne/network/conn.py", line 613, in _addCellConn
	    postCell.addConn(params=params)
	  File "/home1/06322/tg856217/.local/lib/python3.7/site-packages/netpyne/netpyne/cell/compartCell.py", line 677, in addConn
	    weights = self._setConnWeights(params, netStimParams, secLabels)
	  File "/home1/06322/tg856217/.local/lib/python3.7/site-packages/netpyne/netpyne/cell/compartCell.py", line 1105, in _setConnWeights
	    weights = [scaleFactor * params['weight']] * params['synsPerConn']
	TypeError: can't multiply sequence by non-int of type 'float'






'synsPerConn': 'uniform(1,' + str(cfg.EEspc) + ')'}
-->
'synsPerConn': 'int(uniform(1,' + str(cfg.EEspc) + '))'}

Trying again 

batchLabel = 'v02_batch09'

stampede21(173)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4530839  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530840  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530841  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530842  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530843  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530844  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530845  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530846  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530847  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)



** batchLabel = 'v02_batch10'

Cranking up the noise
cfg.noise_std_scale = 10.0

    params['EIspc'] = [1, 10, 20]
    params['EEspc'] = [1, 10, 20]

stampede21(187)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4530893  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530894  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530895  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530896  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530897  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530898  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530899  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530900  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4530901  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)




** batchLabel = 'v02_batch11'

    params['IIspc'] = [1, 10, 20]
    params['IEspc'] = [1, 10, 20]



** cfg.simLabel = 'eee_net_62'

cfg.noise_std_scale = 5.0


cfg.EEspc = 10
cfg.EIspc = 10
cfg.IEspc = 1
cfg.IIspc = 1

Needs more inh spiking


** cfg.simLabel = 'eee_net_63'


cfg.EEconn = 0.0005 # Will be multiplied by cfg.EScale
cfg.EIconn = 0.005 #0.0005 # Will be multiplied by cfg.EScale
cfg.IEconn = 0.0005 # Will be multiplied by cfg.IScale
cfg.IIconn = 0.0005 # Will be multiplied by cfg.IScale

cfg.EEspc = 10
cfg.EIspc = 10
cfg.IEspc = 1
cfg.IIspc = 1

This sim looks pretty good.

Will leave out PV5 cells to focus on PT.

** batchLabel = 'v02_batch12'

    params['seeds'] = [{'conn': 4123, 'stim': 1234, 'loc' : 3214}, 
                        {'conn': 4123, 'stim': 2345, 'loc' : 3214}, 
                        {'conn': 4123, 'stim': 3456, 'loc' : 3214}]

stampede21(256)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4531473  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4531474  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)
           4531475  skx-normal v02_batc tg856217 PD       0:00      4 (Nodes required for job are DOWN, DRAINED or reserved for jobs in higher priority partitions)


* 2019-10-28 -- exploring convergence


** Running a batch exploring convergence

Sergio originally had the connectivity using convergence.  I recently switched to using
probability, but will now switch back to convergence and explore varying values.

These were the original convergence settings:
# Connectivity variables
cfg.EEconv = 3.0
cfg.EIconv = 3.0
cfg.IEconv = 12.0
cfg.IIconv = 12.0


batchLabel = 'v02_batch13'

cfg.connType = 'convergence'  # 'convergence', 'divergence', or 'probability'

I'll use the original settings, and then vary EScale and IScale

    params['EScale'] = [1, 10, 100, 1000]
    params['IScale'] = [1, 10, 100, 1000]


	stampede22(4)$ sq
             JOBID   PARTITION     NAME     USER ST 
           4593489  skx-normal v02_batc tg856217 PD   
           4593490  skx-normal v02_batc tg856217 PD   
           4593491  skx-normal v02_batc tg856217 PD   
           4593492  skx-normal v02_batc tg856217 PD   
           4593493  skx-normal v02_batc tg856217 PD   
           4593494  skx-normal v02_batc tg856217 PD   
           4593495  skx-normal v02_batc tg856217 PD   
           4593496  skx-normal v02_batc tg856217 PD   
           4593497  skx-normal v02_batc tg856217 PD   
           4593498  skx-normal v02_batc tg856217 PD   
           4593499  skx-normal v02_batc tg856217 PD   
           4593500  skx-normal v02_batc tg856217 PD   
           4593501  skx-normal v02_batc tg856217 PD   
           4593502  skx-normal v02_batc tg856217 PD   
           4593503  skx-normal v02_batc tg856217 PD   

Got some time outs.  Bumping up to 1 hour and running again as batch14

stampede22(21)$ sq
             JOBID   PARTITION     NAME     USER ST  
           4593827  skx-normal v02_batc tg856217 PD  
           4593828  skx-normal v02_batc tg856217 PD  
           4593829  skx-normal v02_batc tg856217 PD  
           4593831  skx-normal v02_batc tg856217 PD  
           4593832  skx-normal v02_batc tg856217 PD  
           4593833  skx-normal v02_batc tg856217 PD  
           4593834  skx-normal v02_batc tg856217 PD  
           4593835  skx-normal v02_batc tg856217 PD  
           4593837  skx-normal v02_batc tg856217 PD  
           4593838  skx-normal v02_batc tg856217 PD  
           4593839  skx-normal v02_batc tg856217 PD  
           4593840  skx-normal v02_batc tg856217 PD  
           4593841  skx-normal v02_batc tg856217 PD  
           4593843  skx-normal v02_batc tg856217 PD  
           4593844  skx-normal v02_batc tg856217 PD  
           4593846  skx-normal v02_batc tg856217 PD  


It looks like there's a ton of connectivity even at the lowest convergence setting...

file:gif/20191028_174801.png

Cancelling remainging jobs and reducing connectivity.

scancel -u $USER

** Reducing connectivity

batchLabel = 'v02_batch15'

cfg.EEconn = 1 #3 #0.0005 # Will be multiplied by cfg.EScale
cfg.EIconn = 1 #3 #0.005 #0.0005 # Will be multiplied by cfg.EScale
cfg.IEconn = 1 #12 #0.0005 # Will be multiplied by cfg.IScale
cfg.IIconn = 1 #12 #0.0005 # Will be multiplied by cfg.IScale

    params['EScale'] = [1, 2, 5, 10]
    params['IScale'] = [1, 2, 5, 10]

Reducing time to 30 minutes

stampede22(56)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4594695  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4594696  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4594697  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4594698  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4594699  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4594700  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4594701  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4594702  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4594703  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4594704  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4594705  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4594707  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4594708  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4594709  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4594710  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4594711  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)

Waiting for it to run.

** Running a single sim on dev queue

cfg.simLabel = 'eee_net_65'

4594993     skx-dev  eee_net tg856217 PD

Quite a bit of connectivity, but no spiking in PV cells.

file:gif/20191028_191834.png

Doubling AMPA weight 

cfg.AMPAweight      = 0.4 #cfg.NMDAweight

cfg.simLabel = 'eee_net_66'

             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4595099     skx-dev  eee_net tg856217 PD       0:00      4 (Resources)

Still no spiking in PV cells.

Removing dist3D distance-based delays from conns -- we're not modeling spatially

Increasing E->I connectivity and increasing AMPA weight again.

cfg.EIconn = 5 #1 #0.005 #0.0005 # Will be multiplied by cfg.EScale
cfg.AMPAweight      = 1.0 #0.4 #cfg.NMDAweight

cfg.simLabel = 'eee_net_67'

Submitted batch job 4595273

cfg.py crashes

stampede22(28)$ python cfg.py 
Traceback (most recent call last):
  File "cfg.py", line 1, in <module>
    from netpyne import specs, sim
  File "/home1/06322/tg856217/.local/lib/python3.7/site-packages/netpyne/netpyne/__init__.py", line 5, in <module>
    import matplotlib
  File "/home1/06322/tg856217/.local/lib/python3.7/site-packages/matplotlib/__init__.py", line 272
    nonlocal called, ret
                  ^
SyntaxError: invalid syntax


adding to top of cfg.py:
import netpyne

cfg.simLabel = 'eee_net_68'

Submitted batch job 4595537

There was a bug in netParams

Ugh.  Even with the changes in connectivity, the PV traces look identical. No 
visible EPSPs.

I don't think I'm seeing any connectivity, despite the thousands in the heatplot...

** Cranking up NMDA and thus AMPA gmax

cfg.NMDAgmax        = 0.5 #0.005

cfg.simLabel = 'eee_net_69'

Submitted batch job 4596094

Definitely seeing conns now!

** Need to reduce gmax to more reasonable level.

cfg.NMDAgmax        = 0.05 #0.5 #0.005
cfg.simLabel = 'eee_net_70'

Reducing EI conn back to 1.0

Submitted batch job 4596247

file:gif/20191028_223122.png

Starting to look better:
I want to reduce gmax further, but increase E->I 

cfg.NMDAgmax        = 0.01 #0.05 #0.5 #0.005
cfg.EIconn = 4 #0.005 #0.0005 # Will be multiplied by cfg.EScale

eee_net_71

Submitted batch job 4596273

Looking good, need more PV spiking, slightly more PT spiking.

Increasing gmax slightly.

cfg.NMDAgmax        = 0.02 #0.01 

eee_net_72

Submitted batch job 4596329



cfg.simLabel = 'eee_net_73'

** Increasing AMPA gmax via its ratio with NMDA

In order to increase PV5 spiking

cfg.AMPANMDAratio   = 15.0 #10.0

Submitted batch job 4596378

AMPA is a bit too strong.  Better to increase E->I conv to increase I spiking

cfg.EIconn = 6 #4 #0.005 #0.0005 # Will be multiplied by cfg.EScale

cfg.simLabel = 'eee_net_74'

Submitted batch job 4596423

** Still want to see more PV spiking. Will increase noise to PV

eee_net_75

cfg.PV5_noise_amp = 0.2 #0.1 #1.0
cfg.PV5_noise_std = 0.2 #0.1 #1.0

Submitted batch job 4596455

Getting more spiking out of I cells:
file:gif/20191029_000640.png

Would like still a bit more.

Increasing noise slightly.

** Setting up a batch to run overnight.

    params['EScale'] = [0.5, 1.0, 1.5, 2.0]
    params['IScale'] = [0.5, 1.0, 1.5, 2.0]

batchLabel = 'v02_batch16'

stampede22(134)$ sq
             JOBID   PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           4596551  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4596552  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4596553  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4596554  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4596555  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4596556  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4596557  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4596558  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4596560  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4596561  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4596562  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4596563  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4596564  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4596565  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4596566  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)
           4596567  skx-normal v02_batc tg856217 PD       0:00      4 (Priority)


* 2019-10-29 -- 

** Analyzing batch from last night

sshs
idev -m 120
ipython
import batch_analysis as ba
batchdatadir = '/scratch/06322/tg856217/'
batchname = 'v02_batch16'
batch = ba.plot_vtraces(batchname, batchdatadir=batchdatadir, outputdir=batchdatadir + batchname)

Raster plots:
file:gif/20191029_065810.png

Connectivity numbers:
file:gif/20191029_070320.png

Connectivity strength:
file:gif/20191029_070613.png

Spike histogram:
file:gif/20191029_070934.png

PT5_4 voltage traces:
file:gif/20191029_073248.png

PT5_2 voltage traces:
file:gif/20191029_073438.png

Analyzing batch sync:

import dev
dev.plotBatchSync(batchPath='/scratch/06322/tg856217/', batchLabel='v02_batch16')

** EEE meeting

Action items 

Find larger somatic plateaus
Run four cases individually instead of all in one pop


* 2019-10-30 -- Exploring plateaus

** Exploring plateaus

Using single cell model, exploring effects of noise, glutamate puff location




* 2019-11-05 -- EEE meeting, exploring plateaus

** Exploring plateaus

*** Plateaus and glut puff location

With and without noise

cfg.numCells = 5 #10000 

Turning off connectivity:
cfg.EScale = 0.0 #1.0
cfg.IScale = 0.0 #1.0

batchLabel = 'platExp_01' #'v02_batch16'

    params['synLocMiddle'] = [0.3, 0.5, 0.7]
    params['noise'] = [False, True]












